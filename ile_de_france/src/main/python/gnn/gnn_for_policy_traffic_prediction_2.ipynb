{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import tqdm\n",
    "import wandb\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "from torch.utils.data import DataLoader, Dataset, Subset\n",
    "\n",
    "import torch_geometric\n",
    "from torch_geometric.data import Data, Batch\n",
    "from torch_geometric.transforms import LineGraph\n",
    "\n",
    "from shapely.geometry import LineString\n",
    "\n",
    "import gnn_io as gio"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abstract\n",
    "\n",
    "Here we investigate the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33menatterer\u001b[0m (\u001b[33mtum-traffic-engineering\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define parameters\n",
    "num_epochs = 20\n",
    "batch_size = 20\n",
    "lr = 0.001\n",
    "wandb_name = 'gnn_decrease_model_for_one_batch'\n",
    "train_ratio = 0.8\n",
    "wandb.login()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load data and create the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GnnModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        torch.manual_seed(12345)\n",
    "        self.conv1 = torch_geometric.nn.GATConv(1, 16)\n",
    "        # self.conv2 = torch_geometric.nn.GATConv(16, 16)\n",
    "        self.conv3 = torch_geometric.nn.GATConv(16, 1)\n",
    "        # self.conv3 = torch_geometric.nn.GCNConv(16, 1)\n",
    "        # self.gat1 = torch_geometric.nn.GATConv(16, 16)\n",
    "        # self.conv4 = torch_geometric.nn.GCNConv(16, 1)\n",
    "                \n",
    "        # self.convWithPos = torch_geometric.nn.conv.PointNetConv(1, 16, 3)\n",
    "        \n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.conv1(x, edge_index)\n",
    "        # x = F.relu(x)\n",
    "        # x = F.dropout(x, training=self.training)\n",
    "        # x = self.conv2(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv3(x, edge_index)\n",
    "        # x = F.relu(x)\n",
    "        # x = F.dropout(x, training=self.training)\n",
    "        # x = self.conv3(x, edge_index)\n",
    "        # x = F.relu(x)\n",
    "        # x = F.dropout(x, training=self.training)\n",
    "        # x = self.gat1(x, edge_index)\n",
    "        # x = F.relu(x)\n",
    "        # x = F.dropout(x, training=self.training)\n",
    "        # x = self.conv4(x, edge_index)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the list of dictionaries\n",
    "data_dict_list = torch.load('../results/dataset_1pm_0-1382.pt')\n",
    "\n",
    "# Reconstruct the Data objects\n",
    "datalist = [Data(x=d['x'], edge_index=d['edge_index'], pos=d['pos'], y=d['y']) for d in data_dict_list]\n",
    "\n",
    "# Recreate the dataset\n",
    "dataset = gio.MyGeometricDataset(datalist)\n",
    "\n",
    "# Apply normalization to your dataset\n",
    "dataset_normalized = gio.normalize_dataset(dataset)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approximate MSE - baseline error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of y: 0.030937498435378075\n",
      "Standard Deviation of y: 0.074600949883461\n",
      "Baseline error is: 0.005565311759710312\n"
     ]
    }
   ],
   "source": [
    "y_values_normalized = np.concatenate([data.normalized_y for data in dataset_normalized.data_list])\n",
    "\n",
    "# Compute the mean and standard deviation\n",
    "mean_y_normalized = np.mean(y_values_normalized)\n",
    "std_y_normalized = np.std(y_values_normalized)\n",
    "\n",
    "print(f\"Mean of y: {mean_y_normalized}\")\n",
    "print(f\"Standard Deviation of y: {std_y_normalized}\")\n",
    "\n",
    "# Plot the distribution of y values\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# n, bins, patches = plt.hist(y_values_normalized, bins=30, edgecolor='k', alpha=0.7)\n",
    "\n",
    "# # Add bin labels\n",
    "# bin_centers = 0.5 * (bins[:-1] + bins[1:])\n",
    "# # for count, x in zip(n, bin_centers):\n",
    "# #     plt.text(x, count, str(int(count)), ha='center', va='bottom')\n",
    "\n",
    "# # Set the x-axis ticks and labels\n",
    "# plt.xticks(bins, rotation=45)\n",
    "# plt.title('Distribution of Normalized y Values')\n",
    "# plt.xlabel('Normalized y')\n",
    "# plt.ylabel('Frequency')\n",
    "# plt.grid(True)\n",
    "# plt.show()\n",
    "\n",
    "mean_y_normalized = np.mean(y_values_normalized)\n",
    "\n",
    "# Convert numpy arrays to torch tensors\n",
    "y_values_normalized_tensor = torch.tensor(y_values_normalized, dtype=torch.float32)\n",
    "mean_y_normalized_tensor = torch.tensor(mean_y_normalized, dtype=torch.float32)\n",
    "\n",
    "# Create the target tensor with the same shape as y_values_normalized_tensor\n",
    "target_tensor = mean_y_normalized_tensor * torch.ones_like(y_values_normalized_tensor)\n",
    "\n",
    "# Instantiate the MSELoss function\n",
    "mse_loss = torch.nn.MSELoss()\n",
    "\n",
    "# Compute the MSE \n",
    "mse = mse_loss(y_values_normalized_tensor, target_tensor)\n",
    "\n",
    "# Print the MSE value\n",
    "print(\"Baseline error is: \" + str(mse.item()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load model and loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "wandb version 0.17.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/elenanatterer/Development/MATSim/eqasim-java/ile_de_france/src/main/python/gnn/wandb/run-20240704_084808-2ofs3u2s</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/tum-traffic-engineering/check_errors/runs/2ofs3u2s' target=\"_blank\">lucky-haze-12</a></strong> to <a href='https://wandb.ai/tum-traffic-engineering/check_errors' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/tum-traffic-engineering/check_errors' target=\"_blank\">https://wandb.ai/tum-traffic-engineering/check_errors</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/tum-traffic-engineering/check_errors/runs/2ofs3u2s' target=\"_blank\">https://wandb.ai/tum-traffic-engineering/check_errors/runs/2ofs3u2s</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "wandb.init(\n",
    "        project=\"check_errors\",\n",
    "        config={\n",
    "            \"epochs\": num_epochs,\n",
    "            \"batch_size\": batch_size,\n",
    "            \"lr\": lr,\n",
    "            'early_stopping_patience': 10,\n",
    "            # \"dropout\": 0.15,\n",
    "            })\n",
    "config = wandb.config\n",
    "model = GnnModel().to(device)\n",
    "\n",
    "# Define loss and optimizer\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=5e-4)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "loss_fct = torch.nn.MSELoss()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Split into train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'create_dataloader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_dl \u001b[39m=\u001b[39m create_dataloader(dataset\u001b[39m=\u001b[39mdataset_normalized, is_train\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, batch_size\u001b[39m=\u001b[39mconfig\u001b[39m.\u001b[39mbatch_size, train_ratio\u001b[39m=\u001b[39mtrain_ratio)\n\u001b[1;32m      2\u001b[0m valid_dl \u001b[39m=\u001b[39m create_dataloader(dataset\u001b[39m=\u001b[39mdataset_normalized, is_train\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, batch_size\u001b[39m=\u001b[39mconfig\u001b[39m.\u001b[39mbatch_size, train_ratio\u001b[39m=\u001b[39mtrain_ratio)\n\u001b[1;32m      3\u001b[0m n_steps_per_epoch \u001b[39m=\u001b[39m math\u001b[39m.\u001b[39mceil(\u001b[39mlen\u001b[39m(train_dl\u001b[39m.\u001b[39mdataset) \u001b[39m/\u001b[39m config\u001b[39m.\u001b[39mbatch_size)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'create_dataloader' is not defined"
     ]
    }
   ],
   "source": [
    "train_dl = create_dataloader(dataset=dataset_normalized, is_train=True, batch_size=config.batch_size, train_ratio=train_ratio)\n",
    "valid_dl = create_dataloader(dataset=dataset_normalized, is_train=False, batch_size=config.batch_size, train_ratio=train_ratio)\n",
    "n_steps_per_epoch = math.ceil(len(train_dl.dataset) / config.batch_size)\n",
    "print(n_steps_per_epoch)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train the model\n",
    "\n",
    "We first find a good model for one batch. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5, verbose=False):\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_loss = None\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, val_loss):\n",
    "        if self.best_loss is None:\n",
    "            self.best_loss = val_loss\n",
    "        elif val_loss > self.best_loss:\n",
    "            self.counter += 1\n",
    "            if self.verbose:\n",
    "                print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, val_loss: 36074.207331730766\n",
      "epoch: 1, val_loss: 24183.85486778846\n",
      "epoch: 2, val_loss: 78698.20673076923\n",
      "epoch: 3, val_loss: 102636.74699519231\n",
      "epoch: 4, val_loss: 101859.34975961539\n",
      "epoch: 5, val_loss: 90070.79627403847\n",
      "epoch: 6, val_loss: 76151.65204326923\n",
      "epoch: 7, val_loss: 63441.45823317308\n",
      "epoch: 8, val_loss: 52378.12319711538\n",
      "epoch: 9, val_loss: 61294.62319711538\n",
      "epoch: 10, val_loss: 45354.18028846154\n",
      "epoch: 11, val_loss: 34868.485877403844\n",
      "epoch: 12, val_loss: 27600.67022235577\n",
      "epoch: 13, val_loss: 22172.89287860577\n",
      "epoch: 14, val_loss: 18098.572415865383\n",
      "epoch: 15, val_loss: 14953.845552884615\n",
      "epoch: 16, val_loss: 12339.248422475961\n",
      "epoch: 17, val_loss: 10288.269756610576\n",
      "epoch: 18, val_loss: 8633.09990985577\n",
      "epoch: 19, val_loss: 7207.927396334135\n",
      "epoch: 20, val_loss: 6059.212552584135\n",
      "epoch: 21, val_loss: 5042.471529447115\n",
      "epoch: 22, val_loss: 4238.04052734375\n",
      "epoch: 23, val_loss: 3513.580866887019\n",
      "epoch: 24, val_loss: 2917.111328125\n",
      "epoch: 25, val_loss: 2395.1782977764424\n",
      "epoch: 26, val_loss: 1996.188467172476\n",
      "epoch: 27, val_loss: 1645.7814565805288\n",
      "epoch: 28, val_loss: 1367.5493727463943\n",
      "epoch: 29, val_loss: 1114.3700796274038\n",
      "epoch: 30, val_loss: 909.6910729041466\n",
      "epoch: 31, val_loss: 744.250967172476\n",
      "epoch: 32, val_loss: 605.9917461688702\n",
      "epoch: 33, val_loss: 492.4725388746995\n",
      "epoch: 34, val_loss: 399.4517798790565\n",
      "epoch: 35, val_loss: 322.77161818284253\n",
      "epoch: 36, val_loss: 257.79306851900543\n",
      "epoch: 37, val_loss: 201.17213205190805\n",
      "epoch: 38, val_loss: 151.0250478891226\n",
      "epoch: 39, val_loss: 62.706585517296425\n",
      "epoch: 40, val_loss: 11.995806987469013\n",
      "epoch: 41, val_loss: 2.7076124411362867\n",
      "epoch: 42, val_loss: 0.2723096517416147\n",
      "epoch: 43, val_loss: 0.05389326696212475\n",
      "epoch: 44, val_loss: 0.05754974341163269\n",
      "epoch: 45, val_loss: 0.05400111812811632\n",
      "epoch: 46, val_loss: 0.05149300654347126\n",
      "epoch: 47, val_loss: 0.04093703484305969\n",
      "epoch: 48, val_loss: 0.0897179778951865\n",
      "epoch: 49, val_loss: 0.14470658279382265\n",
      "epoch: 50, val_loss: 0.12164562367475949\n",
      "epoch: 51, val_loss: 0.10831875812548858\n",
      "epoch: 52, val_loss: 0.10214515145008381\n",
      "epoch: 53, val_loss: 0.09119648257127175\n",
      "epoch: 54, val_loss: 0.08125185393370114\n",
      "epoch: 55, val_loss: 0.07274800768265358\n",
      "epoch: 56, val_loss: 0.06538441204107724\n",
      "epoch: 57, val_loss: 0.057595846171562486\n",
      "epoch: 58, val_loss: 0.05185538816910524\n",
      "epoch: 59, val_loss: 0.0449722558259964\n",
      "epoch: 60, val_loss: 0.0406866712638965\n",
      "epoch: 61, val_loss: 0.036375803443101734\n",
      "epoch: 62, val_loss: 0.03290931593913298\n",
      "epoch: 63, val_loss: 0.029879839947590463\n",
      "epoch: 64, val_loss: 0.027485031777849563\n",
      "epoch: 65, val_loss: 0.02550844633235381\n",
      "epoch: 66, val_loss: 0.024370592230787642\n",
      "epoch: 67, val_loss: 0.023678268377597515\n",
      "epoch: 68, val_loss: 0.023108003947597284\n",
      "epoch: 69, val_loss: 0.022893223768243424\n",
      "epoch: 70, val_loss: 0.022851333738519594\n",
      "epoch: 71, val_loss: 0.022959051080621205\n",
      "epoch: 72, val_loss: 0.023200125075303592\n",
      "epoch: 73, val_loss: 0.023561480813301526\n",
      "epoch: 74, val_loss: 0.023939108189481955\n",
      "epoch: 75, val_loss: 0.024356197709074386\n",
      "epoch: 76, val_loss: 0.024773007688614037\n",
      "epoch: 77, val_loss: 0.02514733947240389\n",
      "epoch: 78, val_loss: 0.02550469869031356\n",
      "epoch: 79, val_loss: 0.02578137069940567\n",
      "epoch: 80, val_loss: 0.02604360033113223\n",
      "epoch: 81, val_loss: 0.026298929292422075\n",
      "epoch: 82, val_loss: 0.02648829038326557\n",
      "epoch: 83, val_loss: 0.026658937621575136\n",
      "epoch: 84, val_loss: 0.02679152858371918\n",
      "epoch: 85, val_loss: 0.026907165749714926\n",
      "epoch: 86, val_loss: 0.026992271582667645\n",
      "epoch: 87, val_loss: 0.027007513751204196\n",
      "epoch: 88, val_loss: 0.027039175280011617\n",
      "epoch: 89, val_loss: 0.027067540070185296\n",
      "epoch: 90, val_loss: 0.02707447870992697\n",
      "epoch: 91, val_loss: 0.0270849707034918\n",
      "epoch: 92, val_loss: 0.02708453584748965\n",
      "epoch: 93, val_loss: 0.027068783314182207\n",
      "epoch: 94, val_loss: 0.027036570728971407\n",
      "epoch: 95, val_loss: 0.026992950015343152\n",
      "epoch: 96, val_loss: 0.026935986458108976\n",
      "epoch: 97, val_loss: 0.026905516592355874\n",
      "epoch: 98, val_loss: 0.026856692221302252\n",
      "epoch: 99, val_loss: 0.026803030704076473\n",
      "epoch: 100, val_loss: 0.026744732203391883\n",
      "epoch: 101, val_loss: 0.026670027810793657\n",
      "epoch: 102, val_loss: 0.02661051142674226\n",
      "epoch: 103, val_loss: 0.026535832967895728\n",
      "epoch: 104, val_loss: 0.026492003781291153\n",
      "epoch: 105, val_loss: 0.026424251783352632\n",
      "epoch: 106, val_loss: 0.02633155409533244\n",
      "epoch: 107, val_loss: 0.02626253951054353\n",
      "epoch: 108, val_loss: 0.026189693607963048\n",
      "epoch: 109, val_loss: 0.026115547865629196\n",
      "epoch: 110, val_loss: 0.026035406555120762\n",
      "epoch: 111, val_loss: 0.025956846200502835\n",
      "epoch: 112, val_loss: 0.025876989158300254\n",
      "epoch: 113, val_loss: 0.02579029105030573\n",
      "epoch: 114, val_loss: 0.025695320075521104\n",
      "epoch: 115, val_loss: 0.025602423800871923\n",
      "epoch: 116, val_loss: 0.025514578733306665\n",
      "epoch: 117, val_loss: 0.02542317959551628\n",
      "epoch: 118, val_loss: 0.025334414954368886\n",
      "epoch: 119, val_loss: 0.025233966656602345\n",
      "epoch: 120, val_loss: 0.025135702955035064\n",
      "epoch: 121, val_loss: 0.025015645302259006\n",
      "epoch: 122, val_loss: 0.024918954389599655\n",
      "epoch: 123, val_loss: 0.024818567129281852\n",
      "epoch: 124, val_loss: 0.02470968635036395\n",
      "epoch: 125, val_loss: 0.024615669909578104\n",
      "epoch: 126, val_loss: 0.02448670781002595\n",
      "epoch: 127, val_loss: 0.024356675835756156\n",
      "epoch: 128, val_loss: 0.02423779064646134\n",
      "epoch: 129, val_loss: 0.024123439135459755\n",
      "epoch: 130, val_loss: 0.024005792032067593\n",
      "epoch: 131, val_loss: 0.023849074370585956\n",
      "epoch: 132, val_loss: 0.023738584409539517\n",
      "epoch: 133, val_loss: 0.023587185602921706\n",
      "epoch: 134, val_loss: 0.023473196734602634\n",
      "epoch: 135, val_loss: 0.023334756780129213\n",
      "epoch: 136, val_loss: 0.023189129021305304\n",
      "epoch: 137, val_loss: 0.023051192410863362\n",
      "epoch: 138, val_loss: 0.02290289892027011\n",
      "epoch: 139, val_loss: 0.02275485244507973\n",
      "epoch: 140, val_loss: 0.022601122609697856\n",
      "epoch: 141, val_loss: 0.02244930900633335\n",
      "epoch: 142, val_loss: 0.02228535468188616\n",
      "epoch: 143, val_loss: 0.022116533408944424\n",
      "epoch: 144, val_loss: 0.021982684158361875\n",
      "epoch: 145, val_loss: 0.021804579748557165\n",
      "epoch: 146, val_loss: 0.021613665354939606\n",
      "epoch: 147, val_loss: 0.021460931175030194\n",
      "epoch: 148, val_loss: 0.021267179829569962\n",
      "epoch: 149, val_loss: 0.021120838820934296\n",
      "epoch: 150, val_loss: 0.02094075083732605\n",
      "epoch: 151, val_loss: 0.020744615879196387\n",
      "epoch: 152, val_loss: 0.02054806913320835\n",
      "epoch: 153, val_loss: 0.02035195824618523\n",
      "epoch: 154, val_loss: 0.020152868846288093\n",
      "epoch: 155, val_loss: 0.019977830063838225\n",
      "epoch: 156, val_loss: 0.019764860948691003\n",
      "epoch: 157, val_loss: 0.01957704800252731\n",
      "epoch: 158, val_loss: 0.01936234189913823\n",
      "epoch: 159, val_loss: 0.01916599689194789\n",
      "epoch: 160, val_loss: 0.018940809827584486\n",
      "epoch: 161, val_loss: 0.018724154107845746\n",
      "epoch: 162, val_loss: 0.01851567210486302\n",
      "epoch: 163, val_loss: 0.018294737889216497\n",
      "epoch: 164, val_loss: 0.018082271974820357\n",
      "epoch: 165, val_loss: 0.017864828786024682\n",
      "epoch: 166, val_loss: 0.017632373250447787\n",
      "epoch: 167, val_loss: 0.017430996379027\n",
      "epoch: 168, val_loss: 0.017188060025756177\n",
      "epoch: 169, val_loss: 0.01698611848629438\n",
      "epoch: 170, val_loss: 0.01675634258068525\n",
      "epoch: 171, val_loss: 0.016514404748494808\n",
      "epoch: 172, val_loss: 0.01628577780838196\n",
      "epoch: 173, val_loss: 0.0160582079910315\n",
      "epoch: 174, val_loss: 0.015816417164527453\n",
      "epoch: 175, val_loss: 0.015587502732299842\n",
      "epoch: 176, val_loss: 0.015342890141675105\n",
      "epoch: 177, val_loss: 0.015120669411352048\n",
      "epoch: 178, val_loss: 0.014900992481181255\n",
      "epoch: 179, val_loss: 0.014667325939696569\n",
      "epoch: 180, val_loss: 0.014434722896951895\n",
      "epoch: 181, val_loss: 0.014181354584602209\n",
      "epoch: 182, val_loss: 0.013962849043309689\n",
      "epoch: 183, val_loss: 0.013719834458942596\n",
      "epoch: 184, val_loss: 0.013483579270541668\n",
      "epoch: 185, val_loss: 0.01324877544091298\n",
      "epoch: 186, val_loss: 0.01300504280684086\n",
      "epoch: 187, val_loss: 0.012766782409296585\n",
      "epoch: 188, val_loss: 0.012547455154932462\n",
      "epoch: 189, val_loss: 0.012311166582199244\n",
      "epoch: 190, val_loss: 0.012088733510329174\n",
      "epoch: 191, val_loss: 0.011847592388781218\n",
      "epoch: 192, val_loss: 0.01161836782613626\n",
      "epoch: 193, val_loss: 0.01141076090817268\n",
      "epoch: 194, val_loss: 0.011185213780173888\n",
      "epoch: 195, val_loss: 0.010964479225759324\n",
      "epoch: 196, val_loss: 0.010750170295628218\n",
      "epoch: 197, val_loss: 0.0105294376038588\n",
      "epoch: 198, val_loss: 0.01033203647686885\n",
      "epoch: 199, val_loss: 0.010120001406623768\n",
      "epoch: 200, val_loss: 0.009913503478925962\n",
      "epoch: 201, val_loss: 0.009711156026102029\n",
      "epoch: 202, val_loss: 0.009516798031444732\n",
      "epoch: 203, val_loss: 0.009330820435514817\n",
      "epoch: 204, val_loss: 0.009139845720850505\n",
      "epoch: 205, val_loss: 0.008961919623498734\n",
      "epoch: 206, val_loss: 0.008783554013531942\n",
      "epoch: 207, val_loss: 0.00860957235384446\n",
      "epoch: 208, val_loss: 0.00844179717107461\n",
      "epoch: 209, val_loss: 0.00828085639155828\n",
      "epoch: 210, val_loss: 0.00812799920542882\n",
      "epoch: 211, val_loss: 0.007983128970059065\n",
      "epoch: 212, val_loss: 0.007833377887996344\n",
      "epoch: 213, val_loss: 0.0076880804263055325\n",
      "epoch: 214, val_loss: 0.00759605522482441\n",
      "epoch: 215, val_loss: 0.007460158640662065\n",
      "epoch: 216, val_loss: 0.00732349855108903\n",
      "epoch: 217, val_loss: 0.007194131791878205\n",
      "epoch: 218, val_loss: 0.007071476537161148\n",
      "epoch: 219, val_loss: 0.00695626727806834\n",
      "epoch: 220, val_loss: 0.006846623387760841\n",
      "epoch: 221, val_loss: 0.006740790863449757\n",
      "epoch: 222, val_loss: 0.006642978960791459\n",
      "epoch: 223, val_loss: 0.006552450430507843\n",
      "epoch: 224, val_loss: 0.006465158496911709\n",
      "epoch: 225, val_loss: 0.0063854948474237555\n",
      "epoch: 226, val_loss: 0.006307393133353729\n",
      "epoch: 227, val_loss: 0.006236207635643391\n",
      "epoch: 228, val_loss: 0.00617012417373749\n",
      "epoch: 229, val_loss: 0.00610804776302897\n",
      "epoch: 230, val_loss: 0.00605235997444162\n",
      "epoch: 231, val_loss: 0.006000243127346039\n",
      "epoch: 232, val_loss: 0.005952198452387865\n",
      "epoch: 233, val_loss: 0.005908435461326287\n",
      "epoch: 234, val_loss: 0.005868361080781772\n",
      "epoch: 235, val_loss: 0.005832461067117178\n",
      "epoch: 236, val_loss: 0.005798775845995316\n",
      "epoch: 237, val_loss: 0.005768464555820594\n",
      "epoch: 238, val_loss: 0.005741182714700699\n",
      "epoch: 239, val_loss: 0.005716251030277748\n",
      "epoch: 240, val_loss: 0.005695471325172828\n",
      "epoch: 241, val_loss: 0.005675346375657962\n",
      "epoch: 242, val_loss: 0.0056584577004496865\n",
      "epoch: 243, val_loss: 0.0056428095110907005\n",
      "epoch: 244, val_loss: 0.005628739376194202\n",
      "epoch: 245, val_loss: 0.005616925083673918\n",
      "epoch: 246, val_loss: 0.005606558747016466\n",
      "epoch: 247, val_loss: 0.005597578863111826\n",
      "epoch: 248, val_loss: 0.005589630705519364\n",
      "epoch: 249, val_loss: 0.0055825102071349435\n",
      "epoch: 250, val_loss: 0.005576508657003825\n",
      "epoch: 251, val_loss: 0.005571632001262445\n",
      "epoch: 252, val_loss: 0.005567279930871267\n",
      "epoch: 253, val_loss: 0.005563675855787901\n",
      "epoch: 254, val_loss: 0.00556064432916733\n",
      "epoch: 255, val_loss: 0.005558069329708815\n",
      "epoch: 256, val_loss: 0.005555936923393836\n",
      "epoch: 257, val_loss: 0.005554153798864438\n",
      "epoch: 258, val_loss: 0.005552676398880207\n",
      "epoch: 259, val_loss: 0.005551388451399712\n",
      "epoch: 260, val_loss: 0.005550452006550936\n",
      "epoch: 261, val_loss: 0.0055495898167674355\n",
      "epoch: 262, val_loss: 0.005548873343146765\n",
      "epoch: 263, val_loss: 0.00554844020650937\n",
      "epoch: 264, val_loss: 0.005547876075769846\n",
      "epoch: 265, val_loss: 0.005547724485110778\n",
      "epoch: 266, val_loss: 0.00554726580874278\n",
      "epoch: 267, val_loss: 0.0055470961289337045\n",
      "epoch: 268, val_loss: 0.005546971797369993\n",
      "epoch: 269, val_loss: 0.005547038852595366\n",
      "epoch: 270, val_loss: 0.005546887261936298\n",
      "epoch: 271, val_loss: 0.005546720519375343\n",
      "epoch: 272, val_loss: 0.0055464323466786975\n",
      "epoch: 273, val_loss: 0.005546447140379594\n",
      "epoch: 274, val_loss: 0.00554657276146687\n",
      "epoch: 275, val_loss: 0.0055462469776662495\n",
      "epoch: 276, val_loss: 0.005546226810950499\n",
      "epoch: 277, val_loss: 0.005547323192541416\n",
      "epoch: 278, val_loss: 0.005546180961223749\n",
      "epoch: 279, val_loss: 0.005546260195282789\n",
      "epoch: 280, val_loss: 0.005546322844635982\n",
      "epoch: 281, val_loss: 0.005546960621499098\n",
      "epoch: 282, val_loss: 0.005546188375984247\n",
      "epoch: 283, val_loss: 0.00554633355484559\n",
      "epoch: 284, val_loss: 0.005547344218939543\n",
      "epoch: 285, val_loss: 0.005546101082402926\n",
      "epoch: 286, val_loss: 0.005546268827926654\n",
      "epoch: 287, val_loss: 0.0055462273482519845\n",
      "epoch: 288, val_loss: 0.005547663304381645\n",
      "epoch: 289, val_loss: 0.005546663063936508\n",
      "epoch: 290, val_loss: 0.005546068378652518\n",
      "epoch: 291, val_loss: 0.00554655406337518\n",
      "epoch: 292, val_loss: 0.0055481038915996365\n",
      "epoch: 293, val_loss: 0.00554618386265177\n",
      "epoch: 294, val_loss: 0.006250716101091642\n",
      "epoch: 295, val_loss: 0.008106230185008965\n",
      "epoch: 296, val_loss: 0.005558449989901139\n",
      "epoch: 297, val_loss: 0.005546465659370789\n",
      "epoch: 298, val_loss: 0.0056275063767456095\n",
      "epoch: 299, val_loss: 0.009813936283955207\n",
      "epoch: 300, val_loss: 0.0055672808621938415\n",
      "epoch: 301, val_loss: 0.013074760181972614\n",
      "epoch: 302, val_loss: 0.0072093604920575255\n",
      "epoch: 303, val_loss: 0.005548828460562687\n",
      "epoch: 304, val_loss: 0.005626102013943287\n",
      "epoch: 305, val_loss: 0.010523849381850315\n",
      "epoch: 306, val_loss: 0.005564745981246233\n",
      "epoch: 307, val_loss: 0.005547329102857755\n",
      "epoch: 308, val_loss: 0.005827908117610674\n",
      "epoch: 309, val_loss: 0.0061616057243484715\n",
      "epoch: 310, val_loss: 0.00633757346524642\n",
      "epoch: 311, val_loss: 0.03943545944415606\n",
      "epoch: 312, val_loss: 0.03790965217810411\n",
      "epoch: 313, val_loss: 0.006498803312961872\n",
      "epoch: 314, val_loss: 0.00671832596596617\n",
      "epoch: 315, val_loss: 0.007626325823366642\n",
      "epoch: 316, val_loss: 0.005588051182432816\n",
      "epoch: 317, val_loss: 0.005551215010480239\n",
      "epoch: 318, val_loss: 0.018421782180666924\n",
      "epoch: 319, val_loss: 0.01765626697586133\n",
      "epoch: 320, val_loss: 0.005828735669358418\n",
      "epoch: 321, val_loss: 0.007884912622662691\n",
      "epoch: 322, val_loss: 0.005565257277339697\n",
      "epoch: 323, val_loss: 0.01272489596158266\n",
      "epoch: 324, val_loss: 0.008519699797034264\n",
      "epoch: 325, val_loss: 0.01572708090623984\n",
      "epoch: 326, val_loss: 0.019679230279647388\n",
      "epoch: 327, val_loss: 0.039523681482443444\n",
      "epoch: 328, val_loss: 0.016363719048408363\n",
      "epoch: 329, val_loss: 0.04296012939168857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[E thread_pool.cpp:130] Exception in thread pool task: mutex lock failed: Invalid argument\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 22\u001b[0m\n\u001b[1;32m     12\u001b[0m input_node_features, targets \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mnormalized_x\u001b[39m.\u001b[39mto(device), data\u001b[39m.\u001b[39mnormalized_y\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     13\u001b[0m \u001b[39m# y_values_normalized = np.concatenate([data.normalized_y])\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[39m# y_mean_per_batch = np.mean(y_values_normalized)\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[39m# n = len(data.normalized_y)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[39m# counter += 1\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[39m# y_mean_per_batch_tensor = torch.tensor(y_mean_per_batch)\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m predicted \u001b[39m=\u001b[39m model(data)\n\u001b[1;32m     23\u001b[0m train_loss \u001b[39m=\u001b[39m loss_fct(predicted, targets)\n\u001b[1;32m     24\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n",
      "File \u001b[0;32m~/anaconda3/envs/Paris_Analysis/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/Paris_Analysis/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[27], line 16\u001b[0m, in \u001b[0;36mGnnModel.forward\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, data):\n\u001b[1;32m     15\u001b[0m     x, edge_index \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mx, data\u001b[39m.\u001b[39medge_index\n\u001b[0;32m---> 16\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv1(x, edge_index)\n\u001b[1;32m     17\u001b[0m     \u001b[39m# x = F.relu(x)\u001b[39;00m\n\u001b[1;32m     18\u001b[0m     \u001b[39m# x = F.dropout(x, training=self.training)\u001b[39;00m\n\u001b[1;32m     19\u001b[0m     \u001b[39m# x = self.conv2(x, edge_index)\u001b[39;00m\n\u001b[1;32m     20\u001b[0m     x \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mrelu(x)\n",
      "File \u001b[0;32m~/anaconda3/envs/Paris_Analysis/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/Paris_Analysis/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/Paris_Analysis/lib/python3.10/site-packages/torch_geometric/nn/conv/gat_conv.py:255\u001b[0m, in \u001b[0;36mGATConv.forward\u001b[0;34m(self, x, edge_index, edge_attr, size, return_attention_weights)\u001b[0m\n\u001b[1;32m    252\u001b[0m alpha \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39medge_updater(edge_index, alpha\u001b[39m=\u001b[39malpha, edge_attr\u001b[39m=\u001b[39medge_attr)\n\u001b[1;32m    254\u001b[0m \u001b[39m# propagate_type: (x: OptPairTensor, alpha: Tensor)\u001b[39;00m\n\u001b[0;32m--> 255\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpropagate(edge_index, x\u001b[39m=\u001b[39;49mx, alpha\u001b[39m=\u001b[39;49malpha, size\u001b[39m=\u001b[39;49msize)\n\u001b[1;32m    257\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconcat:\n\u001b[1;32m    258\u001b[0m     out \u001b[39m=\u001b[39m out\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mheads \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mout_channels)\n",
      "File \u001b[0;32m~/anaconda3/envs/Paris_Analysis/lib/python3.10/site-packages/torch_geometric/nn/conv/message_passing.py:480\u001b[0m, in \u001b[0;36mMessagePassing.propagate\u001b[0;34m(self, edge_index, size, **kwargs)\u001b[0m\n\u001b[1;32m    477\u001b[0m     \u001b[39mif\u001b[39;00m res \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    478\u001b[0m         aggr_kwargs \u001b[39m=\u001b[39m res[\u001b[39m0\u001b[39m] \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(res, \u001b[39mtuple\u001b[39m) \u001b[39melse\u001b[39;00m res\n\u001b[0;32m--> 480\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49maggregate(out, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49maggr_kwargs)\n\u001b[1;32m    482\u001b[0m \u001b[39mfor\u001b[39;00m hook \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_aggregate_forward_hooks\u001b[39m.\u001b[39mvalues():\n\u001b[1;32m    483\u001b[0m     res \u001b[39m=\u001b[39m hook(\u001b[39mself\u001b[39m, (aggr_kwargs, ), out)\n",
      "File \u001b[0;32m~/anaconda3/envs/Paris_Analysis/lib/python3.10/site-packages/torch_geometric/nn/conv/message_passing.py:604\u001b[0m, in \u001b[0;36mMessagePassing.aggregate\u001b[0;34m(self, inputs, index, ptr, dim_size)\u001b[0m\n\u001b[1;32m    591\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39maggregate\u001b[39m(\u001b[39mself\u001b[39m, inputs: Tensor, index: Tensor,\n\u001b[1;32m    592\u001b[0m               ptr: Optional[Tensor] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    593\u001b[0m               dim_size: Optional[\u001b[39mint\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m    594\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Aggregates messages from neighbors as\u001b[39;00m\n\u001b[1;32m    595\u001b[0m \u001b[39m    :math:`\\bigoplus_{j \\in \\mathcal{N}(i)}`.\u001b[39;00m\n\u001b[1;32m    596\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    602\u001b[0m \u001b[39m    as specified in :meth:`__init__` by the :obj:`aggr` argument.\u001b[39;00m\n\u001b[1;32m    603\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 604\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49maggr_module(inputs, index, ptr\u001b[39m=\u001b[39;49mptr, dim_size\u001b[39m=\u001b[39;49mdim_size,\n\u001b[1;32m    605\u001b[0m                             dim\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnode_dim)\n",
      "File \u001b[0;32m~/anaconda3/envs/Paris_Analysis/lib/python3.10/site-packages/torch_geometric/experimental.py:115\u001b[0m, in \u001b[0;36mdisable_dynamic_shapes.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapper\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_experimental_mode_enabled(\u001b[39m'\u001b[39m\u001b[39mdisable_dynamic_shapes\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m--> 115\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    117\u001b[0m     \u001b[39mfor\u001b[39;00m required_arg \u001b[39min\u001b[39;00m required_args:\n\u001b[1;32m    118\u001b[0m         index \u001b[39m=\u001b[39m required_args_pos[required_arg]\n",
      "File \u001b[0;32m~/anaconda3/envs/Paris_Analysis/lib/python3.10/site-packages/torch_geometric/nn/aggr/base.py:125\u001b[0m, in \u001b[0;36mAggregation.__call__\u001b[0;34m(self, x, index, ptr, dim_size, dim, **kwargs)\u001b[0m\n\u001b[1;32m    122\u001b[0m     dim_size \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(index\u001b[39m.\u001b[39mmax()) \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m \u001b[39mif\u001b[39;00m index\u001b[39m.\u001b[39mnumel() \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39m0\u001b[39m\n\u001b[1;32m    124\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 125\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(x, index\u001b[39m=\u001b[39;49mindex, ptr\u001b[39m=\u001b[39;49mptr, dim_size\u001b[39m=\u001b[39;49mdim_size,\n\u001b[1;32m    126\u001b[0m                             dim\u001b[39m=\u001b[39;49mdim, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    127\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mIndexError\u001b[39;00m, \u001b[39mRuntimeError\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    128\u001b[0m     \u001b[39mif\u001b[39;00m index \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/Paris_Analysis/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/Paris_Analysis/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/Paris_Analysis/lib/python3.10/site-packages/torch_geometric/nn/aggr/basic.py:22\u001b[0m, in \u001b[0;36mSumAggregation.forward\u001b[0;34m(self, x, index, ptr, dim_size, dim)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x: Tensor, index: Optional[Tensor] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m     20\u001b[0m             ptr: Optional[Tensor] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m, dim_size: Optional[\u001b[39mint\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m     21\u001b[0m             dim: \u001b[39mint\u001b[39m \u001b[39m=\u001b[39m \u001b[39m-\u001b[39m\u001b[39m2\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m---> 22\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreduce(x, index, ptr, dim_size, dim, reduce\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39msum\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[0;32m~/anaconda3/envs/Paris_Analysis/lib/python3.10/site-packages/torch_geometric/nn/aggr/base.py:176\u001b[0m, in \u001b[0;36mAggregation.reduce\u001b[0;34m(self, x, index, ptr, dim_size, dim, reduce)\u001b[0m\n\u001b[1;32m    173\u001b[0m     \u001b[39mreturn\u001b[39;00m segment(x, ptr, reduce\u001b[39m=\u001b[39mreduce)\n\u001b[1;32m    175\u001b[0m \u001b[39massert\u001b[39;00m index \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 176\u001b[0m \u001b[39mreturn\u001b[39;00m scatter(x, index, dim, dim_size, reduce)\n",
      "File \u001b[0;32m~/anaconda3/envs/Paris_Analysis/lib/python3.10/site-packages/torch_geometric/utils/scatter.py:70\u001b[0m, in \u001b[0;36mscatter\u001b[0;34m(src, index, dim, dim_size, reduce)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[39mif\u001b[39;00m reduce \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39msum\u001b[39m\u001b[39m'\u001b[39m \u001b[39mor\u001b[39;00m reduce \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39madd\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m     69\u001b[0m     index \u001b[39m=\u001b[39m broadcast(index, src, dim)\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mreturn\u001b[39;00m src\u001b[39m.\u001b[39;49mnew_zeros(size)\u001b[39m.\u001b[39;49mscatter_add_(dim, index, src)\n\u001b[1;32m     72\u001b[0m \u001b[39mif\u001b[39;00m reduce \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mmean\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m     73\u001b[0m     count \u001b[39m=\u001b[39m src\u001b[39m.\u001b[39mnew_zeros(dim_size)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# find the average per batch\n",
    "\n",
    "# Train the model\n",
    "# mse_loss = 0\n",
    "# counter = 0\n",
    "early_stopping = EarlyStopping(patience=5, verbose=True)\n",
    "\n",
    "for epoch in range(config.epochs):\n",
    "    model.train()\n",
    "    data = next(iter(train_dl))\n",
    "    for idx in range(len(train_dl)):\n",
    "        \n",
    "    # for idx, data in enumerate(train_dl):\n",
    "        input_node_features, targets = data.normalized_x.to(device), data.normalized_y.to(device)\n",
    "        predicted = model(data)\n",
    "        train_loss = loss_fct(predicted, targets)\n",
    "        optimizer.zero_grad()\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "        wandb.log({\"train_loss\": train_loss.item(), \"epoch\": epoch, \"step\": idx})\n",
    "        # print(f\"epoch: {epoch}, step: {idx}, loss: {train_loss.item()}\")\n",
    "        \n",
    "        \n",
    "    val_loss = validate_model(model, valid_dl, loss_fct, device)\n",
    "    early_stopping(val_loss)\n",
    "    if early_stopping.early_stop:\n",
    "        print(\"Early stopping triggered. Stopping training.\")\n",
    "        break\n",
    "    \n",
    "    wandb.log({\"val_loss\": val_loss})\n",
    "    print(f\"epoch: {epoch}, val_loss: {val_loss}\")\n",
    "        \n",
    "wandb.summary[\"val_loss\"] = val_loss\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Paris_Analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
