{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import math\n",
    "import random\n",
    "import torch, torchvision\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as T\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "import gnn_io\n",
    "\n",
    "import torch_geometric\n",
    "from torch_geometric.data import Data\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch_geometric.transforms import LineGraph\n",
    "\n",
    "from torch_geometric.data import Batch\n",
    "from torch_geometric.data import Data, Batch\n",
    "\n",
    "from shapely.geometry import LineString\n",
    "import tqdm \n",
    "import torch.nn.functional as F\n",
    "\n",
    "def collate_fn(data_list):\n",
    "    return Batch.from_data_list(data_list)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abstract\n",
    "\n",
    "This is the current working version.\n",
    "The steps are the following:\n",
    "\n",
    "1. Load data\n",
    "2. Pick a loss function\n",
    "3. Split into train and test data\n",
    "4. Training loop"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load data and create the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../results/results_pop_1pct_toy_example.pkl', 'rb') as f:\n",
    "    results_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyGeometricDataset(Dataset):\n",
    "    def __init__(self, data_list):\n",
    "        self.data_list = data_list\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data_list[idx]\n",
    "\n",
    "# Create your data objects\n",
    "datalist = []\n",
    "for key, df in results_dict.items():\n",
    "    if isinstance(df, pd.DataFrame):\n",
    "        gdf = gpd.GeoDataFrame(df, geometry='geometry')\n",
    "        gdf.crs = \"EPSG:2154\"  # Assuming the original CRS is EPSG:2154\n",
    "        gdf.to_crs(\"EPSG:4326\", inplace=True)\n",
    "        \n",
    "        nodes = []\n",
    "        edges = []\n",
    "        edge_car_volumes = []\n",
    "        node_to_idx = {}\n",
    "        capacities = {}\n",
    "        edge_positions = []\n",
    "\n",
    "        # Iterate through the rows of the GeoDataFrame\n",
    "        for idx, row in gdf.iterrows():\n",
    "            from_node = row['from_node']\n",
    "            to_node = row['to_node']\n",
    "            car_volume = row['vol_car']\n",
    "            capacity = row['capacity']\n",
    "            \n",
    "            # Get coordinates from the LINESTRING geometry\n",
    "            coords = list(row.geometry.coords)\n",
    "            from_position = coords[0]\n",
    "            to_position = coords[-1]\n",
    "            \n",
    "            # Assign unique indices to nodes\n",
    "            if from_node not in node_to_idx:\n",
    "                node_to_idx[from_node] = len(nodes)\n",
    "                nodes.append(from_node)\n",
    "                capacities[node_to_idx[from_node]] = capacity\n",
    "\n",
    "            if to_node not in node_to_idx:\n",
    "                node_to_idx[to_node] = len(nodes)\n",
    "                nodes.append(to_node)\n",
    "                capacities[node_to_idx[to_node]] = capacity\n",
    "            \n",
    "            # Append edge index and attributes\n",
    "            edge = (node_to_idx[from_node], node_to_idx[to_node])\n",
    "            if edge not in edges:\n",
    "                edges.append(edge)\n",
    "                edge_car_volumes.append(car_volume)  # Target values\n",
    "                \n",
    "                # Compute edge position (e.g., midpoint)\n",
    "                edge_position = ((from_position[0] + to_position[0]) / 2, (from_position[1] + to_position[1]) / 2)\n",
    "                edge_positions.append(edge_position)\n",
    "\n",
    "        # Convert lists to tensors\n",
    "        edge_index = torch.tensor(edges, dtype=torch.long).t().contiguous()\n",
    "        edge_positions_tensor = torch.tensor(edge_positions, dtype=torch.float)\n",
    "        \n",
    "        x = torch.tensor([[capacities[i]] for i in range(len(nodes))], dtype=torch.float)\n",
    "        \n",
    "        # Create Data object\n",
    "        data = Data(edge_index=edge_index, x=x)\n",
    "        \n",
    "        # Transform to line graph\n",
    "        linegraph_transformation = LineGraph()\n",
    "        linegraph_data = linegraph_transformation(data)\n",
    "        \n",
    "        # Prepare the x for line graph: index and capacity\n",
    "        linegraph_x = torch.zeros((linegraph_data.num_nodes, 2), dtype=torch.float)\n",
    "        \n",
    "        for i, (from_idx, to_idx) in enumerate(edges):\n",
    "            capacity = capacities[from_idx]  # Assuming capacity is the same for from and to node\n",
    "            linegraph_x[i, 0] = i  # Index\n",
    "            linegraph_x[i, 1] = capacity\n",
    "        \n",
    "        linegraph_data.x = linegraph_x\n",
    "        \n",
    "        # Target tensor for car volumes\n",
    "        linegraph_data.y = torch.tensor(edge_car_volumes, dtype=torch.float).unsqueeze(1)\n",
    "        \n",
    "        if linegraph_data.validate(raise_on_error=True):\n",
    "            datalist.append(linegraph_data)\n",
    "        else:\n",
    "            print(\"Invalid line graph data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataBatch(edge_index=[2, 59851], num_nodes=31559, x=[31559, 2], y=[31559, 1], batch=[31559], ptr=[2])\n",
      "tensor([[  0., 480.],\n",
      "        [  1., 480.],\n",
      "        [  2., 480.],\n",
      "        [  3., 960.],\n",
      "        [  4., 960.],\n",
      "        [  5., 480.],\n",
      "        [  6., 480.],\n",
      "        [  7., 240.],\n",
      "        [  8., 480.],\n",
      "        [  9., 480.]])\n",
      "tensor([[ 55.],\n",
      "        [ 54.],\n",
      "        [ 22.],\n",
      "        [ 60.],\n",
      "        [ 68.],\n",
      "        [ 61.],\n",
      "        [ 61.],\n",
      "        [  2.],\n",
      "        [135.],\n",
      "        [ 42.]])\n",
      "tensor([[    0,     1,     1,  ..., 31557, 31558, 31558],\n",
      "        [    2, 13470, 13471,  ..., 31555, 31557, 31558]])\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the dataset\n",
    "dataset = MyGeometricDataset(datalist)\n",
    "\n",
    "# Usage with DataLoader\n",
    "dataloader = DataLoader(dataset, batch_size=1, shuffle=True, collate_fn=collate_fn)\n",
    "\n",
    "# Example of iterating through the DataLoader\n",
    "for data in dataloader:\n",
    "    print(data)\n",
    "    print(data.x[0:10])\n",
    "    print(data.y[0:10])\n",
    "    print(data.edge_index[0:10])\n",
    "    break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GnnModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = torch_geometric.nn.GCNConv(2, 16)\n",
    "        self.conv2 = torch_geometric.nn.GCNConv(16, 1)\n",
    "        # self.layers = nn.Sequential(\n",
    "        # nn.Linear(3, 64),\n",
    "        # nn.ReLU(),\n",
    "        # nn.Linear(64, 32),\n",
    "        # nn.ReLU(),\n",
    "        # nn.Linear(32, 1)\n",
    "        # )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 20835.3457\n"
     ]
    }
   ],
   "source": [
    "# Initalize the model\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = GnnModel().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "\n",
    "# Train the model\n",
    "model.train()\n",
    "for epoch in range(10):\n",
    "    for data in dataloader:\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data)\n",
    "        loss = F.mse_loss(out, data.y.view(-1, 1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "# Evaluate the model\n",
    "model.eval()\n",
    "pred = model(data)\n",
    "mse = F.mse_loss(pred, data.y.view(-1, 1)).item()\n",
    "print(f'Mean Squared Error: {mse:.4f}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 20835.3457\n",
      "Root Mean Squared Error: 144.3445\n",
      "Mean of target values: 51.4052\n",
      "Standard deviation of target values: 134.8809\n",
      "Minimum target value: 0.0000\n",
      "Maximum target value: 1593.0000\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    pred = model(data).cpu()\n",
    "    target = data.y.view(-1, 1).cpu()\n",
    "    mse = F.mse_loss(pred, target).item()\n",
    "    rmse = torch.sqrt(torch.tensor(mse)).item()\n",
    "    print(f'Mean Squared Error: {mse:.4f}')\n",
    "    print(f'Root Mean Squared Error: {rmse:.4f}')\n",
    "\n",
    "# Calculate target value statistics for comparison\n",
    "target_values = target.numpy()\n",
    "mean_target = target_values.mean()\n",
    "std_target = target_values.std()\n",
    "min_target = target_values.min()\n",
    "max_target = target_values.max()\n",
    "\n",
    "print(f'Mean of target values: {mean_target:.4f}')\n",
    "print(f'Standard deviation of target values: {std_target:.4f}')\n",
    "print(f'Minimum target value: {min_target:.4f}')\n",
    "print(f'Maximum target value: {max_target:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6602029754784688"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse/len(data.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Paris_Analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
