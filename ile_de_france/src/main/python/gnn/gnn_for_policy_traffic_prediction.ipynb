{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import math\n",
    "import random\n",
    "import torch, torchvision\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as T\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "import torch_geometric\n",
    "from torch_geometric.data import Data\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch_geometric.transforms import LineGraph\n",
    "\n",
    "from torch_geometric.data import Batch\n",
    "from torch_geometric.data import Data, Batch\n",
    "\n",
    "from shapely.geometry import LineString\n",
    "import tqdm \n",
    "import torch.nn.functional as F\n",
    "\n",
    "def collate_fn(data_list):\n",
    "    return Batch.from_data_list(data_list)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abstract\n",
    "\n",
    "This is the current working version.\n",
    "The steps are the following:\n",
    "\n",
    "1. Load data\n",
    "2. Pick a loss function\n",
    "3. Split into train and test data\n",
    "4. Training loop"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load data and create the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33menatterer\u001b[0m (\u001b[33mtum-traffic-engineering\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('../results/results_pop_1pm_first_1400.pkl', 'rb') as f:\n",
    "    results_dict = pickle.load(f)\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyGeometricDataset(Dataset):\n",
    "    def __init__(self, data_list):\n",
    "        self.data_list = data_list\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data_list[idx]\n",
    "\n",
    "# Create your data objects\n",
    "datalist = []\n",
    "counter = 0\n",
    "for key, df in results_dict.items():\n",
    "    counter +=1\n",
    "    if counter > 10:\n",
    "        break\n",
    "    if isinstance(df, pd.DataFrame):\n",
    "        gdf = gpd.GeoDataFrame(df, geometry='geometry')\n",
    "        gdf.crs = \"EPSG:2154\"  # Assuming the original CRS is EPSG:2154\n",
    "        gdf.to_crs(\"EPSG:4326\", inplace=True)\n",
    "        \n",
    "        nodes = []\n",
    "        edges = []\n",
    "        edge_car_volumes = []\n",
    "        node_to_idx = {}\n",
    "        capacities = {}\n",
    "        edge_positions = []\n",
    "\n",
    "        # Iterate through the rows of the GeoDataFrame\n",
    "        for idx, row in gdf.iterrows():\n",
    "            from_node = row['from_node']\n",
    "            to_node = row['to_node']\n",
    "            car_volume = row['vol_car']\n",
    "            capacity = row['capacity']\n",
    "            \n",
    "            # Get coordinates from the LINESTRING geometry\n",
    "            coords = list(row.geometry.coords)\n",
    "            from_position = coords[0]\n",
    "            to_position = coords[-1]\n",
    "            \n",
    "            # Assign unique indices to nodes\n",
    "            if from_node not in node_to_idx:\n",
    "                node_to_idx[from_node] = len(nodes)\n",
    "                nodes.append(from_node)\n",
    "                # capacities[node_to_idx[from_node]] = capacity\n",
    "\n",
    "            if to_node not in node_to_idx:\n",
    "                node_to_idx[to_node] = len(nodes)\n",
    "                nodes.append(to_node)\n",
    "                # capacities[node_to_idx[to_node]] = capacity\n",
    "            \n",
    "            # Append edge index and attributes\n",
    "            edge = (node_to_idx[from_node], node_to_idx[to_node])\n",
    "            if edge not in edges:\n",
    "                edges.append(edge)\n",
    "                edge_car_volumes.append(car_volume)  # Target values\n",
    "                capacities[edge] = capacity\n",
    "                \n",
    "                # Compute edge position (e.g., midpoint)\n",
    "                edge_position = ((from_position[0] + to_position[0]) / 2, (from_position[1] + to_position[1]) / 2)\n",
    "                edge_positions.append(edge_position)\n",
    "\n",
    "        # Convert lists to tensors\n",
    "        edge_index = torch.tensor(edges, dtype=torch.long).t().contiguous()\n",
    "        edge_positions_tensor = torch.tensor(edge_positions, dtype=torch.float)\n",
    "        \n",
    "        # x = torch.tensor([[capacities[i]] for i in range(len(nodes))], dtype=torch.float)\n",
    "        x = torch.tensor([[0] for i in range(len(nodes))], dtype=torch.float)\n",
    "        \n",
    "        # Create Data object\n",
    "        target_values = torch.tensor(edge_car_volumes, dtype=torch.float).unsqueeze(1)\n",
    "        data = Data(edge_index=edge_index, x=x, pos=edge_positions_tensor)\n",
    "        \n",
    "        # Transform to line graph\n",
    "        linegraph_transformation = LineGraph()\n",
    "        linegraph_data = linegraph_transformation(data)\n",
    "        \n",
    "        # Prepare the x for line graph: index and capacity\n",
    "        linegraph_x = torch.zeros((linegraph_data.num_nodes, 1), dtype=torch.float)\n",
    "        for i, edge in enumerate(edges):\n",
    "            capacity = capacities[edge]  \n",
    "            linegraph_x[i] = capacity\n",
    "        \n",
    "        linegraph_data.x = linegraph_x\n",
    "        \n",
    "        # Target tensor for car volumes\n",
    "        linegraph_data.y = torch.tensor(edge_car_volumes, dtype=torch.float).unsqueeze(1)\n",
    "        \n",
    "        if linegraph_data.validate(raise_on_error=True):\n",
    "            datalist.append(linegraph_data)\n",
    "        else:\n",
    "            print(\"Invalid line graph data\")\n",
    "            \n",
    "dataset = MyGeometricDataset(datalist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.3386, 48.8518],\n",
       "        [ 2.3387, 48.8524],\n",
       "        [ 2.3387, 48.8524],\n",
       "        ...,\n",
       "        [ 2.3143, 48.8912],\n",
       "        [ 2.2712, 48.8380],\n",
       "        [ 2.2750, 48.8370]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linegraph_data.pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MyGeometricDataset(datalist)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GnnModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        torch.manual_seed(12345)\n",
    "        self.conv1 = torch_geometric.nn.GCNConv(1, 16)\n",
    "        self.conv2 = torch_geometric.nn.GCNConv(16, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "    \n",
    "# def get_data_from_dataloader(is_train, batch_size, dataset):\n",
    "#     # sub_dataset = torch.utils.data.Subset(dataset, range(0,  10))\n",
    "#     # sub_dataset = torch.utils.data.Subset(dataset, range(0, int(len(dataset) * 0.8)) if is_train else range(int(len(dataset) * 0.2), len(dataset)))\n",
    "#     sub_dataset = torch.utils.data.Subset(dataset, range(0, 50) if is_train else range(50, 100))\n",
    "#     return DataLoader(dataset=sub_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "\n",
    "\n",
    "def get_data_from_dataloader(is_train, batch_size, dataset):\n",
    "    dataset_length = len(dataset)\n",
    "    print(f\"Total dataset length: {dataset_length}\")\n",
    "    mid_point = dataset_length // 2  # Use integer division to get an integer midpoint\n",
    "\n",
    "    # Adjust indices based on the actual length of the dataset\n",
    "    if is_train:\n",
    "        indices = range(0, mid_point)\n",
    "    else:\n",
    "        indices = range(mid_point, dataset_length)\n",
    "    \n",
    "    sub_dataset = torch.utils.data.Subset(dataset, indices)\n",
    "    print(f\"{'Training' if is_train else 'Validation'} subset length: {len(sub_dataset)}\")\n",
    "    \n",
    "    return DataLoader(dataset=sub_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "\n",
    "\n",
    "def validate_model(model, valid_dl, loss_func, device):\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.inference_mode():\n",
    "        for idx, data in enumerate(valid_dl):\n",
    "            input_node_feats, targets = data.x.to(device), data.y.to(device)\n",
    "            predicted = model(data)\n",
    "            print(data.x.shape)\n",
    "            print(data.y.shape)\n",
    "            print(predicted.shape)\n",
    "            print(targets.shape)\n",
    "            val_loss += loss_func(predicted, targets)*targets.size(0)\n",
    "    return val_loss "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:9nef0nj9) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62fe9ce5bcdc414792bc7ce1b9552dc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train_loss</td><td>█▅▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train_loss</td><td>81287.53906</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">dazzling-haze-7</strong> at: <a href='https://wandb.ai/tum-traffic-engineering/gnn_3/runs/9nef0nj9' target=\"_blank\">https://wandb.ai/tum-traffic-engineering/gnn_3/runs/9nef0nj9</a><br/> View project at: <a href='https://wandb.ai/tum-traffic-engineering/gnn_3' target=\"_blank\">https://wandb.ai/tum-traffic-engineering/gnn_3</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240702_063741-9nef0nj9/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:9nef0nj9). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d69d26ae9114b988b60af0c84d135d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011167714355461713, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/elenanatterer/Development/MATSim/eqasim-java/ile_de_france/src/main/python/gnn/wandb/run-20240702_064731-05qswge6</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/tum-traffic-engineering/gnn_3/runs/05qswge6' target=\"_blank\">youthful-rain-8</a></strong> to <a href='https://wandb.ai/tum-traffic-engineering/gnn_3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/tum-traffic-engineering/gnn_3' target=\"_blank\">https://wandb.ai/tum-traffic-engineering/gnn_3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/tum-traffic-engineering/gnn_3/runs/05qswge6' target=\"_blank\">https://wandb.ai/tum-traffic-engineering/gnn_3/runs/05qswge6</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "wandb.init(\n",
    "        project=\"gnn_3\",\n",
    "        config={\n",
    "            \"epochs\": 10,\n",
    "            \"batch_size\": 1,\n",
    "            \"lr\": 0.001,\n",
    "            \"dropout\": random.uniform(0.01, 0.80),\n",
    "            })\n",
    "config = wandb.config\n",
    "\n",
    "# Get the model\n",
    "model = GnnModel().to(device)\n",
    "\n",
    "# Define loss and optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "loss_fct = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total dataset length: 10\n",
      "Training subset length: 5\n",
      "Total dataset length: 10\n",
      "Validation subset length: 5\n"
     ]
    }
   ],
   "source": [
    "train_dl = get_data_from_dataloader(dataset  = dataset, is_train=True, batch_size=config.batch_size)\n",
    "valid_dl = get_data_from_dataloader(dataset  = dataset, is_train=False, batch_size=config.batch_size)\n",
    "n_steps_per_epoch = math.ceil(len(train_dl.dataset) / config.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n"
     ]
    }
   ],
   "source": [
    "for data in valid_dl:\n",
    "    print(data.y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(valid_dl.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, step: 0, loss: 105376.6015625\n",
      "epoch: 0, step: 1, loss: 93920.28125\n",
      "epoch: 0, step: 2, loss: 87478.40625\n",
      "epoch: 0, step: 3, loss: 72379.4453125\n",
      "epoch: 0, step: 4, loss: 65660.2578125\n",
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n",
      "epoch: 0, val_loss: 54064980.0\n",
      "epoch: 1, step: 0, loss: 53334.87109375\n",
      "epoch: 1, step: 1, loss: 45111.171875\n",
      "epoch: 1, step: 2, loss: 40740.68359375\n",
      "epoch: 1, step: 3, loss: 33738.48828125\n",
      "epoch: 1, step: 4, loss: 30149.044921875\n",
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n",
      "epoch: 1, val_loss: 37609352.0\n",
      "epoch: 2, step: 0, loss: 24775.1484375\n",
      "epoch: 2, step: 1, loss: 22731.912109375\n",
      "epoch: 2, step: 2, loss: 17997.5390625\n",
      "epoch: 2, step: 3, loss: 15433.5693359375\n",
      "epoch: 2, step: 4, loss: 13482.9443359375\n",
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n",
      "epoch: 2, val_loss: 37228512.0\n",
      "epoch: 3, step: 0, loss: 11307.189453125\n",
      "epoch: 3, step: 1, loss: 9644.5458984375\n",
      "epoch: 3, step: 2, loss: 8257.599609375\n",
      "epoch: 3, step: 3, loss: 6685.4970703125\n",
      "epoch: 3, step: 4, loss: 5342.43359375\n",
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n",
      "epoch: 3, val_loss: 43578256.0\n",
      "epoch: 4, step: 0, loss: 4777.24072265625\n",
      "epoch: 4, step: 1, loss: 3875.189208984375\n",
      "epoch: 4, step: 2, loss: 3311.5068359375\n",
      "epoch: 4, step: 3, loss: 2914.81787109375\n",
      "epoch: 4, step: 4, loss: 2453.402099609375\n",
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n",
      "epoch: 4, val_loss: 38907124.0\n",
      "epoch: 5, step: 0, loss: 2144.955322265625\n",
      "epoch: 5, step: 1, loss: 1797.74462890625\n",
      "epoch: 5, step: 2, loss: 1525.2291259765625\n",
      "epoch: 5, step: 3, loss: 1320.0408935546875\n",
      "epoch: 5, step: 4, loss: 1156.6407470703125\n",
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n",
      "epoch: 5, val_loss: 35728052.0\n",
      "epoch: 6, step: 0, loss: 999.1768798828125\n",
      "epoch: 6, step: 1, loss: 826.418212890625\n",
      "epoch: 6, step: 2, loss: 767.2623291015625\n",
      "epoch: 6, step: 3, loss: 657.3275146484375\n",
      "epoch: 6, step: 4, loss: 612.0831909179688\n",
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n",
      "epoch: 6, val_loss: 35964680.0\n",
      "epoch: 7, step: 0, loss: 546.8956909179688\n",
      "epoch: 7, step: 1, loss: 495.63555908203125\n",
      "epoch: 7, step: 2, loss: 436.9505310058594\n",
      "epoch: 7, step: 3, loss: 395.43505859375\n",
      "epoch: 7, step: 4, loss: 372.2814025878906\n",
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n",
      "epoch: 7, val_loss: 36094704.0\n",
      "epoch: 8, step: 0, loss: 350.0804443359375\n",
      "epoch: 8, step: 1, loss: 321.5212707519531\n",
      "epoch: 8, step: 2, loss: 300.34722900390625\n",
      "epoch: 8, step: 3, loss: 290.031982421875\n",
      "epoch: 8, step: 4, loss: 277.8705139160156\n",
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n",
      "epoch: 8, val_loss: 35752940.0\n",
      "epoch: 9, step: 0, loss: 265.3388671875\n",
      "epoch: 9, step: 1, loss: 261.8065490722656\n",
      "epoch: 9, step: 2, loss: 255.87652587890625\n",
      "epoch: 9, step: 3, loss: 245.38487243652344\n",
      "epoch: 9, step: 4, loss: 246.91741943359375\n",
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n",
      "torch.Size([31140, 1])\n",
      "epoch: 9, val_loss: 35798748.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7230dfddfa1e4ac29779b5c53a2fa790",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train_loss</td><td>█▇▇▆▅▄▄▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>█▂▂▄▂▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train_loss</td><td>246.91742</td></tr><tr><td>val_loss</td><td>35798748.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">youthful-rain-8</strong> at: <a href='https://wandb.ai/tum-traffic-engineering/gnn_3/runs/05qswge6' target=\"_blank\">https://wandb.ai/tum-traffic-engineering/gnn_3/runs/05qswge6</a><br/> View project at: <a href='https://wandb.ai/tum-traffic-engineering/gnn_3' target=\"_blank\">https://wandb.ai/tum-traffic-engineering/gnn_3</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240702_064731-05qswge6/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train the model\n",
    "for epoch in range(config.epochs):\n",
    "    model.train()\n",
    "    for step, data in enumerate(train_dl):\n",
    "        input_node_features, targets = data.x.to(device), data.y.to(device)\n",
    "        predicted = model(data)\n",
    "        train_loss = loss_fct(predicted, targets)\n",
    "        optimizer.zero_grad()\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "        wandb.log({\"train_loss\": train_loss.item()})\n",
    "        print(f\"epoch: {epoch}, step: {step}, loss: {train_loss.item()}\")\n",
    "        \n",
    "    val_loss = validate_model(model, valid_dl, loss_fct, device)\n",
    "    wandb.log({\"val_loss\": val_loss})\n",
    "    print(f\"epoch: {epoch}, val_loss: {val_loss}\")\n",
    "        \n",
    "wandb.summary[\"val_loss\"] = val_loss\n",
    "wandb.finish()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "# model.eval()\n",
    "# with torch.no_grad():\n",
    "#     pred = model(data).cpu()\n",
    "#     target = data.y.view(-1, 1).cpu()\n",
    "#     mse = F.mse_loss(pred, target).item()\n",
    "#     rmse = torch.sqrt(torch.tensor(mse)).item()\n",
    "#     print(f'Mean Squared Error: {mse:.4f}')\n",
    "#     print(f'Root Mean Squared Error: {rmse:.4f}')\n",
    "\n",
    "# # Calculate target value statistics for comparison\n",
    "# target_values = target.numpy()\n",
    "# mean_target = target_values.mean()\n",
    "# std_target = target_values.std()\n",
    "# min_target = target_values.min()\n",
    "# max_target = target_values.max()\n",
    "\n",
    "# print(f'Mean of target values: {mean_target:.4f}')\n",
    "# print(f'Standard deviation of target values: {std_target:.4f}')\n",
    "# print(f'Minimum target value: {min_target:.4f}')\n",
    "# print(f'Maximum target value: {max_target:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Paris_Analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
