{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import math\n",
    "import random\n",
    "import torch, torchvision\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as T\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "import torch_geometric\n",
    "from torch_geometric.data import Data\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch_geometric.transforms import LineGraph\n",
    "\n",
    "from torch_geometric.data import Batch\n",
    "from torch_geometric.data import Data, Batch\n",
    "\n",
    "from shapely.geometry import LineString\n",
    "import tqdm \n",
    "import torch.nn.functional as F\n",
    "\n",
    "def collate_fn(data_list):\n",
    "    return Batch.from_data_list(data_list)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abstract\n",
    "\n",
    "This is the current working version.\n",
    "The steps are the following:\n",
    "\n",
    "1. Load data\n",
    "2. Pick a loss function\n",
    "3. Split into train and test data\n",
    "4. Training loop"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load data and create the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33menatterer\u001b[0m (\u001b[33mtum-traffic-engineering\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('../results/results_pop_1pct_toy_example.pkl', 'rb') as f:\n",
    "    results_dict = pickle.load(f)\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyGeometricDataset(Dataset):\n",
    "    def __init__(self, data_list):\n",
    "        self.data_list = data_list\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data_list[idx]\n",
    "\n",
    "# Create your data objects\n",
    "datalist = []\n",
    "for key, df in results_dict.items():\n",
    "    if isinstance(df, pd.DataFrame):\n",
    "        gdf = gpd.GeoDataFrame(df, geometry='geometry')\n",
    "        gdf.crs = \"EPSG:2154\"  # Assuming the original CRS is EPSG:2154\n",
    "        gdf.to_crs(\"EPSG:4326\", inplace=True)\n",
    "        \n",
    "        nodes = []\n",
    "        edges = []\n",
    "        edge_car_volumes = []\n",
    "        node_to_idx = {}\n",
    "        capacities = {}\n",
    "        edge_positions = []\n",
    "\n",
    "        # Iterate through the rows of the GeoDataFrame\n",
    "        for idx, row in gdf.iterrows():\n",
    "            from_node = row['from_node']\n",
    "            to_node = row['to_node']\n",
    "            car_volume = row['vol_car']\n",
    "            capacity = row['capacity']\n",
    "            \n",
    "            # Get coordinates from the LINESTRING geometry\n",
    "            coords = list(row.geometry.coords)\n",
    "            from_position = coords[0]\n",
    "            to_position = coords[-1]\n",
    "            \n",
    "            # Assign unique indices to nodes\n",
    "            if from_node not in node_to_idx:\n",
    "                node_to_idx[from_node] = len(nodes)\n",
    "                nodes.append(from_node)\n",
    "                capacities[node_to_idx[from_node]] = capacity\n",
    "\n",
    "            if to_node not in node_to_idx:\n",
    "                node_to_idx[to_node] = len(nodes)\n",
    "                nodes.append(to_node)\n",
    "                capacities[node_to_idx[to_node]] = capacity\n",
    "            \n",
    "            # Append edge index and attributes\n",
    "            edge = (node_to_idx[from_node], node_to_idx[to_node])\n",
    "            if edge not in edges:\n",
    "                edges.append(edge)\n",
    "                edge_car_volumes.append(car_volume)  # Target values\n",
    "                \n",
    "                # Compute edge position (e.g., midpoint)\n",
    "                edge_position = ((from_position[0] + to_position[0]) / 2, (from_position[1] + to_position[1]) / 2)\n",
    "                edge_positions.append(edge_position)\n",
    "\n",
    "        # Convert lists to tensors\n",
    "        edge_index = torch.tensor(edges, dtype=torch.long).t().contiguous()\n",
    "        edge_positions_tensor = torch.tensor(edge_positions, dtype=torch.float)\n",
    "        \n",
    "        x = torch.tensor([[capacities[i]] for i in range(len(nodes))], dtype=torch.float)\n",
    "        \n",
    "        # Create Data object\n",
    "        data = Data(edge_index=edge_index, x=x)\n",
    "        \n",
    "        # Transform to line graph\n",
    "        linegraph_transformation = LineGraph()\n",
    "        linegraph_data = linegraph_transformation(data)\n",
    "        \n",
    "        # Prepare the x for line graph: index and capacity\n",
    "        linegraph_x = torch.zeros((linegraph_data.num_nodes, 2), dtype=torch.float)\n",
    "        \n",
    "        for i, (from_idx, to_idx) in enumerate(edges):\n",
    "            capacity = capacities[from_idx]  # Assuming capacity is the same for from and to node\n",
    "            linegraph_x[i, 0] = i  # Index\n",
    "            linegraph_x[i, 1] = capacity\n",
    "        \n",
    "        linegraph_data.x = linegraph_x\n",
    "        \n",
    "        # Target tensor for car volumes\n",
    "        linegraph_data.y = torch.tensor(edge_car_volumes, dtype=torch.float).unsqueeze(1)\n",
    "        \n",
    "        if linegraph_data.validate(raise_on_error=True):\n",
    "            datalist.append(linegraph_data)\n",
    "        else:\n",
    "            print(\"Invalid line graph data\")\n",
    "            \n",
    "dataset = MyGeometricDataset(datalist)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GnnModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = torch_geometric.nn.GCNConv(2, 16)\n",
    "        self.conv2 = torch_geometric.nn.GCNConv(16, 1)\n",
    "        # self.layers = nn.Sequential(\n",
    "        # nn.Linear(3, 64),\n",
    "        # nn.ReLU(),\n",
    "        # nn.Linear(64, 32),\n",
    "        # nn.ReLU(),\n",
    "        # nn.Linear(32, 1)\n",
    "        # )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "    \n",
    "def get_data_from_dataloader(is_train, batch_size, dataset):\n",
    "    sub_dataset = torch.utils.data.Subset(dataset, range(0, int(len(dataset) * 0.8)) if is_train else range(int(len(dataset) * 0.2), len(dataset)))\n",
    "    return DataLoader(dataset=sub_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "\n",
    "def validate_model(model, valid_dl, loss_func, device):\n",
    "    \"Compute performance of the model on the validation dataset and log a wandb.Table\"\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.inference_mode():\n",
    "        for data in valid_dl:\n",
    "            data, expected = data.x.to(device), data.y.to(device)\n",
    "            predicted = model(data)\n",
    "            val_loss += loss_func(predicted, expected)*expected.size(0)\n",
    "    return val_loss "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:dt1co93c) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0d07e75392c4fc7becd9d5b779c7cb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>step</td><td>▁▂▃▅▆▇█</td></tr><tr><td>train_loss</td><td>▄▇▅▆▇█▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>step</td><td>6</td></tr><tr><td>train_loss</td><td>21002.53906</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">clean-firebrand-5</strong> at: <a href='https://wandb.ai/tum-traffic-engineering/gnn_1/runs/dt1co93c' target=\"_blank\">https://wandb.ai/tum-traffic-engineering/gnn_1/runs/dt1co93c</a><br/> View project at: <a href='https://wandb.ai/tum-traffic-engineering/gnn_1' target=\"_blank\">https://wandb.ai/tum-traffic-engineering/gnn_1</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240701_133429-dt1co93c/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:dt1co93c). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7832dce4ee1048cd9110cfbbeebbcaac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011167530099757843, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/elenanatterer/Development/MATSim/eqasim-java/ile_de_france/src/main/python/gnn/wandb/run-20240701_133529-vxim0fim</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/tum-traffic-engineering/gnn_1/runs/vxim0fim' target=\"_blank\">twilight-wind-6</a></strong> to <a href='https://wandb.ai/tum-traffic-engineering/gnn_1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/tum-traffic-engineering/gnn_1' target=\"_blank\">https://wandb.ai/tum-traffic-engineering/gnn_1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/tum-traffic-engineering/gnn_1/runs/vxim0fim' target=\"_blank\">https://wandb.ai/tum-traffic-engineering/gnn_1/runs/vxim0fim</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x1688183a0>\n",
      "epoch: 0, step: 0, loss: 21002.5390625\n",
      "epoch: 0, step: 1, loss: 21086.25\n",
      "epoch: 0, step: 2, loss: 21170.69921875\n",
      "epoch: 0, step: 3, loss: 21187.080078125\n",
      "epoch: 0, step: 4, loss: 21163.212890625\n",
      "epoch: 0, step: 5, loss: 21110.92578125\n",
      "epoch: 0, step: 6, loss: 21147.349609375\n",
      "epoch: 0, val_loss: 5321844224.0\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x1688183a0>\n",
      "epoch: 1, step: 0, loss: 21170.69921875\n",
      "epoch: 1, step: 1, loss: 21110.92578125\n",
      "epoch: 1, step: 2, loss: 21163.212890625\n",
      "epoch: 1, step: 3, loss: 21086.25\n",
      "epoch: 1, step: 4, loss: 21187.080078125\n",
      "epoch: 1, step: 5, loss: 21002.5390625\n",
      "epoch: 1, step: 6, loss: 21147.349609375\n",
      "epoch: 1, val_loss: 5321844224.0\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x1688183a0>\n",
      "epoch: 2, step: 0, loss: 21163.212890625\n",
      "epoch: 2, step: 1, loss: 21002.5390625\n",
      "epoch: 2, step: 2, loss: 21086.25\n",
      "epoch: 2, step: 3, loss: 21147.349609375\n",
      "epoch: 2, step: 4, loss: 21187.080078125\n",
      "epoch: 2, step: 5, loss: 21170.69921875\n",
      "epoch: 2, step: 6, loss: 21110.92578125\n",
      "epoch: 2, val_loss: 5321844224.0\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x1688183a0>\n",
      "epoch: 3, step: 0, loss: 21187.080078125\n",
      "epoch: 3, step: 1, loss: 21147.349609375\n",
      "epoch: 3, step: 2, loss: 21170.69921875\n",
      "epoch: 3, step: 3, loss: 21163.212890625\n",
      "epoch: 3, step: 4, loss: 21002.5390625\n",
      "epoch: 3, step: 5, loss: 21110.92578125\n",
      "epoch: 3, step: 6, loss: 21086.25\n",
      "epoch: 3, val_loss: 5321843712.0\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x1688183a0>\n",
      "epoch: 4, step: 0, loss: 21002.5390625\n",
      "epoch: 4, step: 1, loss: 21170.69921875\n",
      "epoch: 4, step: 2, loss: 21187.080078125\n",
      "epoch: 4, step: 3, loss: 21110.92578125\n",
      "epoch: 4, step: 4, loss: 21147.349609375\n",
      "epoch: 4, step: 5, loss: 21163.212890625\n",
      "epoch: 4, step: 6, loss: 21086.25\n",
      "epoch: 4, val_loss: 5321844224.0\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x1688183a0>\n",
      "epoch: 5, step: 0, loss: 21163.212890625\n",
      "epoch: 5, step: 1, loss: 21170.69921875\n",
      "epoch: 5, step: 2, loss: 21147.349609375\n",
      "epoch: 5, step: 3, loss: 21110.92578125\n",
      "epoch: 5, step: 4, loss: 21002.5390625\n",
      "epoch: 5, step: 5, loss: 21086.25\n",
      "epoch: 5, step: 6, loss: 21187.080078125\n",
      "epoch: 5, val_loss: 5321844224.0\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x1688183a0>\n",
      "epoch: 6, step: 0, loss: 21163.212890625\n",
      "epoch: 6, step: 1, loss: 21110.92578125\n",
      "epoch: 6, step: 2, loss: 21187.080078125\n",
      "epoch: 6, step: 3, loss: 21147.349609375\n",
      "epoch: 6, step: 4, loss: 21170.69921875\n",
      "epoch: 6, step: 5, loss: 21086.25\n",
      "epoch: 6, step: 6, loss: 21002.5390625\n",
      "epoch: 6, val_loss: 5321843712.0\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x1688183a0>\n",
      "epoch: 7, step: 0, loss: 21187.080078125\n",
      "epoch: 7, step: 1, loss: 21086.25\n",
      "epoch: 7, step: 2, loss: 21147.349609375\n",
      "epoch: 7, step: 3, loss: 21170.69921875\n",
      "epoch: 7, step: 4, loss: 21002.5390625\n",
      "epoch: 7, step: 5, loss: 21163.212890625\n",
      "epoch: 7, step: 6, loss: 21110.92578125\n",
      "epoch: 7, val_loss: 5321844736.0\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x1688183a0>\n",
      "epoch: 8, step: 0, loss: 21110.92578125\n",
      "epoch: 8, step: 1, loss: 21086.25\n",
      "epoch: 8, step: 2, loss: 21163.212890625\n",
      "epoch: 8, step: 3, loss: 21147.349609375\n",
      "epoch: 8, step: 4, loss: 21170.69921875\n",
      "epoch: 8, step: 5, loss: 21002.5390625\n",
      "epoch: 8, step: 6, loss: 21187.080078125\n",
      "epoch: 8, val_loss: 5321844736.0\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x1688183a0>\n",
      "epoch: 9, step: 0, loss: 21002.5390625\n",
      "epoch: 9, step: 1, loss: 21163.212890625\n",
      "epoch: 9, step: 2, loss: 21110.92578125\n",
      "epoch: 9, step: 3, loss: 21086.25\n",
      "epoch: 9, step: 4, loss: 21187.080078125\n",
      "epoch: 9, step: 5, loss: 21147.349609375\n",
      "epoch: 9, step: 6, loss: 21170.69921875\n",
      "epoch: 9, val_loss: 5321843712.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:vxim0fim) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23f2d6703e1e44c9bcff88e7d0b53320",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.020 MB of 0.020 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇██</td></tr><tr><td>train_loss</td><td>▁▄█▅▇▅▄▁▇▁▆▇█▇▇▅▁█▅▇▇▆▅▄▇█▇▄█▆▁▇▅▇▇▁▁▅█▇</td></tr><tr><td>val_loss</td><td>▅▅▅▁▅▅▁██▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>step</td><td>70</td></tr><tr><td>train_loss</td><td>21170.69922</td></tr><tr><td>val_loss</td><td>5321843712.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">twilight-wind-6</strong> at: <a href='https://wandb.ai/tum-traffic-engineering/gnn_1/runs/vxim0fim' target=\"_blank\">https://wandb.ai/tum-traffic-engineering/gnn_1/runs/vxim0fim</a><br/> View project at: <a href='https://wandb.ai/tum-traffic-engineering/gnn_1' target=\"_blank\">https://wandb.ai/tum-traffic-engineering/gnn_1</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240701_133529-vxim0fim/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:vxim0fim). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a83e1f1430a44d0aa32bdb0a94810bbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011112055100319493, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/elenanatterer/Development/MATSim/eqasim-java/ile_de_france/src/main/python/gnn/wandb/run-20240701_133538-xm8r56o9</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/tum-traffic-engineering/gnn_1/runs/xm8r56o9' target=\"_blank\">sleek-aardvark-7</a></strong> to <a href='https://wandb.ai/tum-traffic-engineering/gnn_1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/tum-traffic-engineering/gnn_1' target=\"_blank\">https://wandb.ai/tum-traffic-engineering/gnn_1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/tum-traffic-engineering/gnn_1/runs/xm8r56o9' target=\"_blank\">https://wandb.ai/tum-traffic-engineering/gnn_1/runs/xm8r56o9</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x168c80cd0>\n",
      "epoch: 0, step: 0, loss: 21147.349609375\n",
      "epoch: 0, step: 1, loss: 21170.69921875\n",
      "epoch: 0, step: 2, loss: 21163.212890625\n",
      "epoch: 0, step: 3, loss: 21110.92578125\n",
      "epoch: 0, step: 4, loss: 21187.080078125\n",
      "epoch: 0, step: 5, loss: 21002.5390625\n",
      "epoch: 0, step: 6, loss: 21086.25\n",
      "epoch: 0, val_loss: 5321844224.0\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x168c80cd0>\n",
      "epoch: 1, step: 0, loss: 21147.349609375\n",
      "epoch: 1, step: 1, loss: 21110.92578125\n",
      "epoch: 1, step: 2, loss: 21002.5390625\n",
      "epoch: 1, step: 3, loss: 21187.080078125\n",
      "epoch: 1, step: 4, loss: 21086.25\n",
      "epoch: 1, step: 5, loss: 21170.69921875\n",
      "epoch: 1, step: 6, loss: 21163.212890625\n",
      "epoch: 1, val_loss: 5321844224.0\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x168c80cd0>\n",
      "epoch: 2, step: 0, loss: 21187.080078125\n",
      "epoch: 2, step: 1, loss: 21147.349609375\n",
      "epoch: 2, step: 2, loss: 21002.5390625\n",
      "epoch: 2, step: 3, loss: 21086.25\n",
      "epoch: 2, step: 4, loss: 21110.92578125\n",
      "epoch: 2, step: 5, loss: 21170.69921875\n",
      "epoch: 2, step: 6, loss: 21163.212890625\n",
      "epoch: 2, val_loss: 5321844224.0\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x168c80cd0>\n",
      "epoch: 3, step: 0, loss: 21086.25\n",
      "epoch: 3, step: 1, loss: 21170.69921875\n",
      "epoch: 3, step: 2, loss: 21147.349609375\n",
      "epoch: 3, step: 3, loss: 21163.212890625\n",
      "epoch: 3, step: 4, loss: 21110.92578125\n",
      "epoch: 3, step: 5, loss: 21002.5390625\n",
      "epoch: 3, step: 6, loss: 21187.080078125\n",
      "epoch: 3, val_loss: 5321844224.0\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x168c80cd0>\n",
      "epoch: 4, step: 0, loss: 21002.5390625\n",
      "epoch: 4, step: 1, loss: 21147.349609375\n",
      "epoch: 4, step: 2, loss: 21086.25\n",
      "epoch: 4, step: 3, loss: 21170.69921875\n",
      "epoch: 4, step: 4, loss: 21110.92578125\n",
      "epoch: 4, step: 5, loss: 21163.212890625\n",
      "epoch: 4, step: 6, loss: 21187.080078125\n",
      "epoch: 4, val_loss: 5321844736.0\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x168c80cd0>\n",
      "epoch: 5, step: 0, loss: 21086.25\n",
      "epoch: 5, step: 1, loss: 21147.349609375\n",
      "epoch: 5, step: 2, loss: 21110.92578125\n",
      "epoch: 5, step: 3, loss: 21170.69921875\n",
      "epoch: 5, step: 4, loss: 21002.5390625\n",
      "epoch: 5, step: 5, loss: 21187.080078125\n",
      "epoch: 5, step: 6, loss: 21163.212890625\n",
      "epoch: 5, val_loss: 5321843712.0\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x168c80cd0>\n",
      "epoch: 6, step: 0, loss: 21110.92578125\n",
      "epoch: 6, step: 1, loss: 21187.080078125\n",
      "epoch: 6, step: 2, loss: 21163.212890625\n",
      "epoch: 6, step: 3, loss: 21086.25\n",
      "epoch: 6, step: 4, loss: 21147.349609375\n",
      "epoch: 6, step: 5, loss: 21002.5390625\n",
      "epoch: 6, step: 6, loss: 21170.69921875\n",
      "epoch: 6, val_loss: 5321844736.0\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x168c80cd0>\n",
      "epoch: 7, step: 0, loss: 21002.5390625\n",
      "epoch: 7, step: 1, loss: 21147.349609375\n",
      "epoch: 7, step: 2, loss: 21163.212890625\n",
      "epoch: 7, step: 3, loss: 21187.080078125\n",
      "epoch: 7, step: 4, loss: 21086.25\n",
      "epoch: 7, step: 5, loss: 21110.92578125\n",
      "epoch: 7, step: 6, loss: 21170.69921875\n",
      "epoch: 7, val_loss: 5321843712.0\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x168c80cd0>\n",
      "epoch: 8, step: 0, loss: 21187.080078125\n",
      "epoch: 8, step: 1, loss: 21147.349609375\n",
      "epoch: 8, step: 2, loss: 21170.69921875\n",
      "epoch: 8, step: 3, loss: 21002.5390625\n",
      "epoch: 8, step: 4, loss: 21086.25\n",
      "epoch: 8, step: 5, loss: 21163.212890625\n",
      "epoch: 8, step: 6, loss: 21110.92578125\n",
      "epoch: 8, val_loss: 5321844224.0\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x168c80cd0>\n",
      "epoch: 9, step: 0, loss: 21002.5390625\n",
      "epoch: 9, step: 1, loss: 21187.080078125\n",
      "epoch: 9, step: 2, loss: 21086.25\n",
      "epoch: 9, step: 3, loss: 21147.349609375\n",
      "epoch: 9, step: 4, loss: 21163.212890625\n",
      "epoch: 9, step: 5, loss: 21170.69921875\n",
      "epoch: 9, step: 6, loss: 21110.92578125\n",
      "epoch: 9, val_loss: 5321844736.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:xm8r56o9) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cf9d81d9990429192677dfb20d0fa57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.020 MB of 0.020 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇██</td></tr><tr><td>train_loss</td><td>▆▇▅▁▆▅█▇█▆▄▇▄▆▇▁▁▄▇▇▄▅▇█▅▇▆▁▁▇▄▅█▇▄▇▁▄▇▅</td></tr><tr><td>val_loss</td><td>▅▅▅▅█▁█▁▅█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>step</td><td>70</td></tr><tr><td>train_loss</td><td>21110.92578</td></tr><tr><td>val_loss</td><td>5321844736.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">sleek-aardvark-7</strong> at: <a href='https://wandb.ai/tum-traffic-engineering/gnn_1/runs/xm8r56o9' target=\"_blank\">https://wandb.ai/tum-traffic-engineering/gnn_1/runs/xm8r56o9</a><br/> View project at: <a href='https://wandb.ai/tum-traffic-engineering/gnn_1' target=\"_blank\">https://wandb.ai/tum-traffic-engineering/gnn_1</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240701_133538-xm8r56o9/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:xm8r56o9). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efc95fdd507a410586951d7138359309",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011143871300090622, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/elenanatterer/Development/MATSim/eqasim-java/ile_de_france/src/main/python/gnn/wandb/run-20240701_133546-8lbq20am</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/tum-traffic-engineering/gnn_1/runs/8lbq20am' target=\"_blank\">morning-dream-8</a></strong> to <a href='https://wandb.ai/tum-traffic-engineering/gnn_1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/tum-traffic-engineering/gnn_1' target=\"_blank\">https://wandb.ai/tum-traffic-engineering/gnn_1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/tum-traffic-engineering/gnn_1/runs/8lbq20am' target=\"_blank\">https://wandb.ai/tum-traffic-engineering/gnn_1/runs/8lbq20am</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x168cff1f0>\n",
      "epoch: 0, step: 0, loss: 21187.080078125\n",
      "epoch: 0, step: 1, loss: 21110.92578125\n",
      "epoch: 0, step: 2, loss: 21147.349609375\n",
      "epoch: 0, step: 3, loss: 21170.69921875\n",
      "epoch: 0, step: 4, loss: 21002.5390625\n",
      "epoch: 0, step: 5, loss: 21086.25\n",
      "epoch: 0, step: 6, loss: 21163.212890625\n",
      "epoch: 0, val_loss: 5321844224.0\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x168cff1f0>\n",
      "epoch: 1, step: 0, loss: 21163.212890625\n",
      "epoch: 1, step: 1, loss: 21147.349609375\n",
      "epoch: 1, step: 2, loss: 21086.25\n",
      "epoch: 1, step: 3, loss: 21187.080078125\n",
      "epoch: 1, step: 4, loss: 21170.69921875\n",
      "epoch: 1, step: 5, loss: 21002.5390625\n",
      "epoch: 1, step: 6, loss: 21110.92578125\n",
      "epoch: 1, val_loss: 5321844224.0\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x168cff1f0>\n",
      "epoch: 2, step: 0, loss: 21170.69921875\n",
      "epoch: 2, step: 1, loss: 21147.349609375\n",
      "epoch: 2, step: 2, loss: 21086.25\n",
      "epoch: 2, step: 3, loss: 21187.080078125\n",
      "epoch: 2, step: 4, loss: 21002.5390625\n",
      "epoch: 2, step: 5, loss: 21110.92578125\n",
      "epoch: 2, step: 6, loss: 21163.212890625\n",
      "epoch: 2, val_loss: 5321844224.0\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x168cff1f0>\n",
      "epoch: 3, step: 0, loss: 21002.5390625\n",
      "epoch: 3, step: 1, loss: 21110.92578125\n",
      "epoch: 3, step: 2, loss: 21163.212890625\n",
      "epoch: 3, step: 3, loss: 21187.080078125\n",
      "epoch: 3, step: 4, loss: 21147.349609375\n",
      "epoch: 3, step: 5, loss: 21086.25\n",
      "epoch: 3, step: 6, loss: 21170.69921875\n",
      "epoch: 3, val_loss: 5321844224.0\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x168cff1f0>\n",
      "epoch: 4, step: 0, loss: 21086.25\n",
      "epoch: 4, step: 1, loss: 21110.92578125\n",
      "epoch: 4, step: 2, loss: 21187.080078125\n",
      "epoch: 4, step: 3, loss: 21147.349609375\n",
      "epoch: 4, step: 4, loss: 21170.69921875\n",
      "epoch: 4, step: 5, loss: 21163.212890625\n",
      "epoch: 4, step: 6, loss: 21002.5390625\n",
      "epoch: 4, val_loss: 5321844224.0\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x168cff1f0>\n",
      "epoch: 5, step: 0, loss: 21147.349609375\n",
      "epoch: 5, step: 1, loss: 21170.69921875\n",
      "epoch: 5, step: 2, loss: 21163.212890625\n",
      "epoch: 5, step: 3, loss: 21002.5390625\n",
      "epoch: 5, step: 4, loss: 21187.080078125\n",
      "epoch: 5, step: 5, loss: 21086.25\n",
      "epoch: 5, step: 6, loss: 21110.92578125\n",
      "epoch: 5, val_loss: 5321843712.0\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x168cff1f0>\n",
      "epoch: 6, step: 0, loss: 21187.080078125\n",
      "epoch: 6, step: 1, loss: 21163.212890625\n",
      "epoch: 6, step: 2, loss: 21170.69921875\n",
      "epoch: 6, step: 3, loss: 21110.92578125\n",
      "epoch: 6, step: 4, loss: 21002.5390625\n",
      "epoch: 6, step: 5, loss: 21147.349609375\n",
      "epoch: 6, step: 6, loss: 21086.25\n",
      "epoch: 6, val_loss: 5321844736.0\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x168cff1f0>\n",
      "epoch: 7, step: 0, loss: 21086.25\n",
      "epoch: 7, step: 1, loss: 21147.349609375\n",
      "epoch: 7, step: 2, loss: 21110.92578125\n",
      "epoch: 7, step: 3, loss: 21170.69921875\n",
      "epoch: 7, step: 4, loss: 21163.212890625\n",
      "epoch: 7, step: 5, loss: 21002.5390625\n",
      "epoch: 7, step: 6, loss: 21187.080078125\n",
      "epoch: 7, val_loss: 5321844224.0\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x168cff1f0>\n",
      "epoch: 8, step: 0, loss: 21147.349609375\n",
      "epoch: 8, step: 1, loss: 21110.92578125\n",
      "epoch: 8, step: 2, loss: 21163.212890625\n",
      "epoch: 8, step: 3, loss: 21170.69921875\n",
      "epoch: 8, step: 4, loss: 21086.25\n",
      "epoch: 8, step: 5, loss: 21002.5390625\n",
      "epoch: 8, step: 6, loss: 21187.080078125\n",
      "epoch: 8, val_loss: 5321844224.0\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x168cff1f0>\n",
      "epoch: 9, step: 0, loss: 21086.25\n",
      "epoch: 9, step: 1, loss: 21002.5390625\n",
      "epoch: 9, step: 2, loss: 21147.349609375\n",
      "epoch: 9, step: 3, loss: 21187.080078125\n",
      "epoch: 9, step: 4, loss: 21163.212890625\n",
      "epoch: 9, step: 5, loss: 21170.69921875\n",
      "epoch: 9, step: 6, loss: 21110.92578125\n",
      "epoch: 9, val_loss: 5321844224.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:8lbq20am) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24d73b1ef43c4738a55fa77b3014a4fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇██</td></tr><tr><td>train_loss</td><td>█▅▇▄▇▆█▁▇▆█▅▁▇█▄▄█▆▇▆▇▁▄█▇▁▆▄▅▇▁▆▇▄▁▄▆▇▅</td></tr><tr><td>val_loss</td><td>▅▅▅▅▅▁█▅▅▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>step</td><td>70</td></tr><tr><td>train_loss</td><td>21110.92578</td></tr><tr><td>val_loss</td><td>5321844224.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">morning-dream-8</strong> at: <a href='https://wandb.ai/tum-traffic-engineering/gnn_1/runs/8lbq20am' target=\"_blank\">https://wandb.ai/tum-traffic-engineering/gnn_1/runs/8lbq20am</a><br/> View project at: <a href='https://wandb.ai/tum-traffic-engineering/gnn_1' target=\"_blank\">https://wandb.ai/tum-traffic-engineering/gnn_1</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240701_133546-8lbq20am/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:8lbq20am). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd8d2c5d85db473e9a9d97b2fbd6126b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011167389355574011, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/elenanatterer/Development/MATSim/eqasim-java/ile_de_france/src/main/python/gnn/wandb/run-20240701_133556-n0gnlaor</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/tum-traffic-engineering/gnn_1/runs/n0gnlaor' target=\"_blank\">eager-deluge-9</a></strong> to <a href='https://wandb.ai/tum-traffic-engineering/gnn_1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/tum-traffic-engineering/gnn_1' target=\"_blank\">https://wandb.ai/tum-traffic-engineering/gnn_1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/tum-traffic-engineering/gnn_1/runs/n0gnlaor' target=\"_blank\">https://wandb.ai/tum-traffic-engineering/gnn_1/runs/n0gnlaor</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x168c18970>\n",
      "epoch: 0, step: 0, loss: 21147.349609375\n",
      "epoch: 0, step: 1, loss: 21086.25\n",
      "epoch: 0, step: 2, loss: 21187.080078125\n",
      "epoch: 0, step: 3, loss: 21163.212890625\n",
      "epoch: 0, step: 4, loss: 21002.5390625\n",
      "epoch: 0, step: 5, loss: 21170.69921875\n",
      "epoch: 0, step: 6, loss: 21110.92578125\n",
      "epoch: 0, val_loss: 5321843712.0\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x168c18970>\n",
      "epoch: 1, step: 0, loss: 21163.212890625\n",
      "epoch: 1, step: 1, loss: 21147.349609375\n",
      "epoch: 1, step: 2, loss: 21002.5390625\n",
      "epoch: 1, step: 3, loss: 21187.080078125\n",
      "epoch: 1, step: 4, loss: 21170.69921875\n",
      "epoch: 1, step: 5, loss: 21110.92578125\n",
      "epoch: 1, step: 6, loss: 21086.25\n",
      "epoch: 1, val_loss: 5321844224.0\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x168c18970>\n",
      "epoch: 2, step: 0, loss: 21110.92578125\n",
      "epoch: 2, step: 1, loss: 21147.349609375\n",
      "epoch: 2, step: 2, loss: 21002.5390625\n",
      "epoch: 2, step: 3, loss: 21187.080078125\n",
      "epoch: 2, step: 4, loss: 21163.212890625\n",
      "epoch: 2, step: 5, loss: 21086.25\n",
      "epoch: 2, step: 6, loss: 21170.69921875\n",
      "epoch: 2, val_loss: 5321844224.0\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x168c18970>\n",
      "epoch: 3, step: 0, loss: 21110.92578125\n",
      "epoch: 3, step: 1, loss: 21163.212890625\n",
      "epoch: 3, step: 2, loss: 21170.69921875\n",
      "epoch: 3, step: 3, loss: 21002.5390625\n",
      "epoch: 3, step: 4, loss: 21147.349609375\n",
      "epoch: 3, step: 5, loss: 21187.080078125\n",
      "epoch: 3, step: 6, loss: 21086.25\n",
      "epoch: 3, val_loss: 5321843712.0\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x168c18970>\n",
      "epoch: 4, step: 0, loss: 21187.080078125\n",
      "epoch: 4, step: 1, loss: 21170.69921875\n",
      "epoch: 4, step: 2, loss: 21002.5390625\n",
      "epoch: 4, step: 3, loss: 21147.349609375\n",
      "epoch: 4, step: 4, loss: 21110.92578125\n",
      "epoch: 4, step: 5, loss: 21086.25\n",
      "epoch: 4, step: 6, loss: 21163.212890625\n",
      "epoch: 4, val_loss: 5321844224.0\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x168c18970>\n",
      "epoch: 5, step: 0, loss: 21163.212890625\n",
      "epoch: 5, step: 1, loss: 21086.25\n",
      "epoch: 5, step: 2, loss: 21187.080078125\n",
      "epoch: 5, step: 3, loss: 21110.92578125\n",
      "epoch: 5, step: 4, loss: 21147.349609375\n",
      "epoch: 5, step: 5, loss: 21170.69921875\n",
      "epoch: 5, step: 6, loss: 21002.5390625\n",
      "epoch: 5, val_loss: 5321843712.0\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x168c18970>\n",
      "epoch: 6, step: 0, loss: 21086.25\n",
      "epoch: 6, step: 1, loss: 21147.349609375\n",
      "epoch: 6, step: 2, loss: 21110.92578125\n",
      "epoch: 6, step: 3, loss: 21163.212890625\n",
      "epoch: 6, step: 4, loss: 21002.5390625\n",
      "epoch: 6, step: 5, loss: 21187.080078125\n",
      "epoch: 6, step: 6, loss: 21170.69921875\n",
      "epoch: 6, val_loss: 5321844224.0\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x168c18970>\n",
      "epoch: 7, step: 0, loss: 21110.92578125\n",
      "epoch: 7, step: 1, loss: 21170.69921875\n",
      "epoch: 7, step: 2, loss: 21002.5390625\n",
      "epoch: 7, step: 3, loss: 21147.349609375\n",
      "epoch: 7, step: 4, loss: 21163.212890625\n",
      "epoch: 7, step: 5, loss: 21086.25\n",
      "epoch: 7, step: 6, loss: 21187.080078125\n",
      "epoch: 7, val_loss: 5321844224.0\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x168c18970>\n",
      "epoch: 8, step: 0, loss: 21086.25\n",
      "epoch: 8, step: 1, loss: 21147.349609375\n",
      "epoch: 8, step: 2, loss: 21163.212890625\n",
      "epoch: 8, step: 3, loss: 21187.080078125\n",
      "epoch: 8, step: 4, loss: 21110.92578125\n",
      "epoch: 8, step: 5, loss: 21002.5390625\n",
      "epoch: 8, step: 6, loss: 21170.69921875\n",
      "epoch: 8, val_loss: 5321844736.0\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x168c18970>\n",
      "epoch: 9, step: 0, loss: 21110.92578125\n",
      "epoch: 9, step: 1, loss: 21002.5390625\n",
      "epoch: 9, step: 2, loss: 21147.349609375\n",
      "epoch: 9, step: 3, loss: 21086.25\n",
      "epoch: 9, step: 4, loss: 21187.080078125\n",
      "epoch: 9, step: 5, loss: 21163.212890625\n",
      "epoch: 9, step: 6, loss: 21170.69921875\n",
      "epoch: 9, val_loss: 5321844224.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:n0gnlaor) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4d94d728b02483eae5c41f0853cb319",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.020 MB of 0.020 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇██</td></tr><tr><td>train_loss</td><td>▆▄▇▇▇▆█▅▅▆█▄▅▇▁██▁▆▄▇█▅▇▄▅▁█▅▁▇▄▄▇▅▁▅▆█▇</td></tr><tr><td>val_loss</td><td>▁▅▅▁▅▁▅▅█▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>step</td><td>70</td></tr><tr><td>train_loss</td><td>21170.69922</td></tr><tr><td>val_loss</td><td>5321844224.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">eager-deluge-9</strong> at: <a href='https://wandb.ai/tum-traffic-engineering/gnn_1/runs/n0gnlaor' target=\"_blank\">https://wandb.ai/tum-traffic-engineering/gnn_1/runs/n0gnlaor</a><br/> View project at: <a href='https://wandb.ai/tum-traffic-engineering/gnn_1' target=\"_blank\">https://wandb.ai/tum-traffic-engineering/gnn_1</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240701_133556-n0gnlaor/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:n0gnlaor). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34875d82114c4d84aa642e292ee25f2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011167503244359977, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/elenanatterer/Development/MATSim/eqasim-java/ile_de_france/src/main/python/gnn/wandb/run-20240701_133605-i4zwry3w</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/tum-traffic-engineering/gnn_1/runs/i4zwry3w' target=\"_blank\">different-totem-10</a></strong> to <a href='https://wandb.ai/tum-traffic-engineering/gnn_1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/tum-traffic-engineering/gnn_1' target=\"_blank\">https://wandb.ai/tum-traffic-engineering/gnn_1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/tum-traffic-engineering/gnn_1/runs/i4zwry3w' target=\"_blank\">https://wandb.ai/tum-traffic-engineering/gnn_1/runs/i4zwry3w</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x168c8e380>\n",
      "epoch: 0, step: 0, loss: 21147.349609375\n",
      "epoch: 0, step: 1, loss: 21002.5390625\n",
      "epoch: 0, step: 2, loss: 21163.212890625\n",
      "epoch: 0, step: 3, loss: 21086.25\n",
      "epoch: 0, step: 4, loss: 21170.69921875\n",
      "epoch: 0, step: 5, loss: 21110.92578125\n",
      "epoch: 0, step: 6, loss: 21187.080078125\n",
      "epoch: 0, val_loss: 5321844224.0\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x168c8e380>\n",
      "epoch: 1, step: 0, loss: 21110.92578125\n",
      "epoch: 1, step: 1, loss: 21170.69921875\n",
      "epoch: 1, step: 2, loss: 21163.212890625\n",
      "epoch: 1, step: 3, loss: 21086.25\n",
      "epoch: 1, step: 4, loss: 21147.349609375\n",
      "epoch: 1, step: 5, loss: 21187.080078125\n",
      "epoch: 1, step: 6, loss: 21002.5390625\n",
      "epoch: 1, val_loss: 5321844736.0\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x168c8e380>\n",
      "epoch: 2, step: 0, loss: 21147.349609375\n",
      "epoch: 2, step: 1, loss: 21170.69921875\n",
      "epoch: 2, step: 2, loss: 21086.25\n",
      "epoch: 2, step: 3, loss: 21187.080078125\n",
      "epoch: 2, step: 4, loss: 21002.5390625\n",
      "epoch: 2, step: 5, loss: 21163.212890625\n",
      "epoch: 2, step: 6, loss: 21110.92578125\n",
      "epoch: 2, val_loss: 5321844224.0\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x168c8e380>\n",
      "epoch: 3, step: 0, loss: 21187.080078125\n",
      "epoch: 3, step: 1, loss: 21147.349609375\n",
      "epoch: 3, step: 2, loss: 21110.92578125\n",
      "epoch: 3, step: 3, loss: 21163.212890625\n",
      "epoch: 3, step: 4, loss: 21002.5390625\n",
      "epoch: 3, step: 5, loss: 21086.25\n",
      "epoch: 3, step: 6, loss: 21170.69921875\n",
      "epoch: 3, val_loss: 5321844736.0\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x168c8e380>\n",
      "epoch: 4, step: 0, loss: 21187.080078125\n",
      "epoch: 4, step: 1, loss: 21147.349609375\n",
      "epoch: 4, step: 2, loss: 21163.212890625\n",
      "epoch: 4, step: 3, loss: 21110.92578125\n",
      "epoch: 4, step: 4, loss: 21002.5390625\n",
      "epoch: 4, step: 5, loss: 21170.69921875\n",
      "epoch: 4, step: 6, loss: 21086.25\n",
      "epoch: 4, val_loss: 5321844224.0\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x168c8e380>\n",
      "epoch: 5, step: 0, loss: 21110.92578125\n",
      "epoch: 5, step: 1, loss: 21086.25\n",
      "epoch: 5, step: 2, loss: 21163.212890625\n",
      "epoch: 5, step: 3, loss: 21002.5390625\n",
      "epoch: 5, step: 4, loss: 21147.349609375\n",
      "epoch: 5, step: 5, loss: 21170.69921875\n",
      "epoch: 5, step: 6, loss: 21187.080078125\n",
      "epoch: 5, val_loss: 5321844224.0\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x168c8e380>\n",
      "epoch: 6, step: 0, loss: 21002.5390625\n",
      "epoch: 6, step: 1, loss: 21170.69921875\n",
      "epoch: 6, step: 2, loss: 21187.080078125\n",
      "epoch: 6, step: 3, loss: 21147.349609375\n",
      "epoch: 6, step: 4, loss: 21086.25\n",
      "epoch: 6, step: 5, loss: 21110.92578125\n",
      "epoch: 6, step: 6, loss: 21163.212890625\n",
      "epoch: 6, val_loss: 5321844224.0\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x168c8e380>\n",
      "epoch: 7, step: 0, loss: 21110.92578125\n",
      "epoch: 7, step: 1, loss: 21187.080078125\n",
      "epoch: 7, step: 2, loss: 21002.5390625\n",
      "epoch: 7, step: 3, loss: 21163.212890625\n",
      "epoch: 7, step: 4, loss: 21147.349609375\n",
      "epoch: 7, step: 5, loss: 21086.25\n",
      "epoch: 7, step: 6, loss: 21170.69921875\n",
      "epoch: 7, val_loss: 5321844224.0\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x168c8e380>\n",
      "epoch: 8, step: 0, loss: 21187.080078125\n",
      "epoch: 8, step: 1, loss: 21163.212890625\n",
      "epoch: 8, step: 2, loss: 21170.69921875\n",
      "epoch: 8, step: 3, loss: 21086.25\n",
      "epoch: 8, step: 4, loss: 21147.349609375\n",
      "epoch: 8, step: 5, loss: 21002.5390625\n",
      "epoch: 8, step: 6, loss: 21110.92578125\n",
      "epoch: 8, val_loss: 5321844224.0\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x168c8e380>\n",
      "epoch: 9, step: 0, loss: 21086.25\n",
      "epoch: 9, step: 1, loss: 21163.212890625\n",
      "epoch: 9, step: 2, loss: 21187.080078125\n",
      "epoch: 9, step: 3, loss: 21147.349609375\n",
      "epoch: 9, step: 4, loss: 21110.92578125\n",
      "epoch: 9, step: 5, loss: 21002.5390625\n",
      "epoch: 9, step: 6, loss: 21170.69921875\n",
      "epoch: 9, val_loss: 5321844224.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:i4zwry3w) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c34f009beeb84645a50922fee4ceef82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.020 MB uploaded\\r'), FloatProgress(value=0.047015344311377244, max=1…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇██</td></tr><tr><td>train_loss</td><td>▆▁▄▅▅▇▄█▆▇█▇█▅▇▄█▇▅▇▅▇▁▇▁█▄▅▅▁▆▄█▇▆▁▄█▅▇</td></tr><tr><td>val_loss</td><td>▁█▁█▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>step</td><td>70</td></tr><tr><td>train_loss</td><td>21170.69922</td></tr><tr><td>val_loss</td><td>5321844224.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">different-totem-10</strong> at: <a href='https://wandb.ai/tum-traffic-engineering/gnn_1/runs/i4zwry3w' target=\"_blank\">https://wandb.ai/tum-traffic-engineering/gnn_1/runs/i4zwry3w</a><br/> View project at: <a href='https://wandb.ai/tum-traffic-engineering/gnn_1' target=\"_blank\">https://wandb.ai/tum-traffic-engineering/gnn_1</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240701_133605-i4zwry3w/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:i4zwry3w). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cfd8820a43d42dcab74f1b2258d62de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011168028711108492, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/elenanatterer/Development/MATSim/eqasim-java/ile_de_france/src/main/python/gnn/wandb/run-20240701_133614-47rs1iqa</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/tum-traffic-engineering/gnn_1/runs/47rs1iqa' target=\"_blank\">dry-gorge-11</a></strong> to <a href='https://wandb.ai/tum-traffic-engineering/gnn_1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/tum-traffic-engineering/gnn_1' target=\"_blank\">https://wandb.ai/tum-traffic-engineering/gnn_1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/tum-traffic-engineering/gnn_1/runs/47rs1iqa' target=\"_blank\">https://wandb.ai/tum-traffic-engineering/gnn_1/runs/47rs1iqa</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x1664e9030>\n",
      "epoch: 0, step: 0, loss: 21110.92578125\n",
      "epoch: 0, step: 1, loss: 21163.212890625\n",
      "epoch: 0, step: 2, loss: 21086.25\n",
      "epoch: 0, step: 3, loss: 21002.5390625\n",
      "epoch: 0, step: 4, loss: 21147.349609375\n",
      "epoch: 0, step: 5, loss: 21187.080078125\n",
      "epoch: 0, step: 6, loss: 21170.69921875\n",
      "epoch: 0, val_loss: 5321844736.0\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x1664e9030>\n",
      "epoch: 1, step: 0, loss: 21086.25\n",
      "epoch: 1, step: 1, loss: 21002.5390625\n",
      "epoch: 1, step: 2, loss: 21170.69921875\n",
      "epoch: 1, step: 3, loss: 21163.212890625\n",
      "epoch: 1, step: 4, loss: 21110.92578125\n",
      "epoch: 1, step: 5, loss: 21147.349609375\n",
      "epoch: 1, step: 6, loss: 21187.080078125\n",
      "epoch: 1, val_loss: 5321844224.0\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x1664e9030>\n",
      "epoch: 2, step: 0, loss: 21110.92578125\n",
      "epoch: 2, step: 1, loss: 21170.69921875\n",
      "epoch: 2, step: 2, loss: 21147.349609375\n",
      "epoch: 2, step: 3, loss: 21163.212890625\n",
      "epoch: 2, step: 4, loss: 21086.25\n",
      "epoch: 2, step: 5, loss: 21002.5390625\n",
      "epoch: 2, step: 6, loss: 21187.080078125\n",
      "epoch: 2, val_loss: 5321844736.0\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x1664e9030>\n",
      "epoch: 3, step: 0, loss: 21002.5390625\n",
      "epoch: 3, step: 1, loss: 21147.349609375\n",
      "epoch: 3, step: 2, loss: 21110.92578125\n",
      "epoch: 3, step: 3, loss: 21187.080078125\n",
      "epoch: 3, step: 4, loss: 21163.212890625\n",
      "epoch: 3, step: 5, loss: 21086.25\n",
      "epoch: 3, step: 6, loss: 21170.69921875\n",
      "epoch: 3, val_loss: 5321844736.0\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x1664e9030>\n",
      "epoch: 4, step: 0, loss: 21147.349609375\n",
      "epoch: 4, step: 1, loss: 21163.212890625\n",
      "epoch: 4, step: 2, loss: 21187.080078125\n",
      "epoch: 4, step: 3, loss: 21110.92578125\n",
      "epoch: 4, step: 4, loss: 21170.69921875\n",
      "epoch: 4, step: 5, loss: 21002.5390625\n",
      "epoch: 4, step: 6, loss: 21086.25\n",
      "epoch: 4, val_loss: 5321843712.0\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x1664e9030>\n",
      "epoch: 5, step: 0, loss: 21147.349609375\n",
      "epoch: 5, step: 1, loss: 21086.25\n",
      "epoch: 5, step: 2, loss: 21170.69921875\n",
      "epoch: 5, step: 3, loss: 21002.5390625\n",
      "epoch: 5, step: 4, loss: 21187.080078125\n",
      "epoch: 5, step: 5, loss: 21110.92578125\n",
      "epoch: 5, step: 6, loss: 21163.212890625\n",
      "epoch: 5, val_loss: 5321844224.0\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x1664e9030>\n",
      "epoch: 6, step: 0, loss: 21002.5390625\n",
      "epoch: 6, step: 1, loss: 21170.69921875\n",
      "epoch: 6, step: 2, loss: 21110.92578125\n",
      "epoch: 6, step: 3, loss: 21187.080078125\n",
      "epoch: 6, step: 4, loss: 21086.25\n",
      "epoch: 6, step: 5, loss: 21147.349609375\n",
      "epoch: 6, step: 6, loss: 21163.212890625\n",
      "epoch: 6, val_loss: 5321844224.0\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x1664e9030>\n",
      "epoch: 7, step: 0, loss: 21086.25\n",
      "epoch: 7, step: 1, loss: 21147.349609375\n",
      "epoch: 7, step: 2, loss: 21170.69921875\n",
      "epoch: 7, step: 3, loss: 21110.92578125\n",
      "epoch: 7, step: 4, loss: 21002.5390625\n",
      "epoch: 7, step: 5, loss: 21163.212890625\n",
      "epoch: 7, step: 6, loss: 21187.080078125\n",
      "epoch: 7, val_loss: 5321844224.0\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x1664e9030>\n",
      "epoch: 8, step: 0, loss: 21002.5390625\n",
      "epoch: 8, step: 1, loss: 21187.080078125\n",
      "epoch: 8, step: 2, loss: 21086.25\n",
      "epoch: 8, step: 3, loss: 21147.349609375\n",
      "epoch: 8, step: 4, loss: 21110.92578125\n",
      "epoch: 8, step: 5, loss: 21163.212890625\n",
      "epoch: 8, step: 6, loss: 21170.69921875\n",
      "epoch: 8, val_loss: 5321844736.0\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x1664e9030>\n",
      "epoch: 9, step: 0, loss: 21163.212890625\n",
      "epoch: 9, step: 1, loss: 21187.080078125\n",
      "epoch: 9, step: 2, loss: 21170.69921875\n",
      "epoch: 9, step: 3, loss: 21110.92578125\n",
      "epoch: 9, step: 4, loss: 21002.5390625\n",
      "epoch: 9, step: 5, loss: 21086.25\n",
      "epoch: 9, step: 6, loss: 21147.349609375\n",
      "epoch: 9, val_loss: 5321844224.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:47rs1iqa) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df0599bd302e425b9bdeab131ca8e0af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.020 MB of 0.020 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇██</td></tr><tr><td>train_loss</td><td>▅▇▁█▄▁▇▆▅▇▇▁▁▅█▄▆█▅▁▆▇▁▅▁▅▄▆▄▇▁▇▁▄▅▇▇▇▁▆</td></tr><tr><td>val_loss</td><td>█▅██▁▅▅▅█▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>step</td><td>70</td></tr><tr><td>train_loss</td><td>21147.34961</td></tr><tr><td>val_loss</td><td>5321844224.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">dry-gorge-11</strong> at: <a href='https://wandb.ai/tum-traffic-engineering/gnn_1/runs/47rs1iqa' target=\"_blank\">https://wandb.ai/tum-traffic-engineering/gnn_1/runs/47rs1iqa</a><br/> View project at: <a href='https://wandb.ai/tum-traffic-engineering/gnn_1' target=\"_blank\">https://wandb.ai/tum-traffic-engineering/gnn_1</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240701_133614-47rs1iqa/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:47rs1iqa). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36b89d4a321d4b46a6ff5137e75b39f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.0111505129665602, max=1.0))…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/elenanatterer/Development/MATSim/eqasim-java/ile_de_france/src/main/python/gnn/wandb/run-20240701_133623-z2pekgus</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/tum-traffic-engineering/gnn_1/runs/z2pekgus' target=\"_blank\">prime-serenity-12</a></strong> to <a href='https://wandb.ai/tum-traffic-engineering/gnn_1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/tum-traffic-engineering/gnn_1' target=\"_blank\">https://wandb.ai/tum-traffic-engineering/gnn_1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/tum-traffic-engineering/gnn_1/runs/z2pekgus' target=\"_blank\">https://wandb.ai/tum-traffic-engineering/gnn_1/runs/z2pekgus</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x1664e9db0>\n",
      "epoch: 0, step: 0, loss: 21147.349609375\n",
      "epoch: 0, step: 1, loss: 21086.25\n",
      "epoch: 0, step: 2, loss: 21170.69921875\n",
      "epoch: 0, step: 3, loss: 21187.080078125\n",
      "epoch: 0, step: 4, loss: 21163.212890625\n",
      "epoch: 0, step: 5, loss: 21002.5390625\n",
      "epoch: 0, step: 6, loss: 21110.92578125\n",
      "epoch: 0, val_loss: 5321843712.0\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x1664e9db0>\n",
      "epoch: 1, step: 0, loss: 21110.92578125\n",
      "epoch: 1, step: 1, loss: 21002.5390625\n",
      "epoch: 1, step: 2, loss: 21086.25\n",
      "epoch: 1, step: 3, loss: 21163.212890625\n",
      "epoch: 1, step: 4, loss: 21170.69921875\n",
      "epoch: 1, step: 5, loss: 21147.349609375\n",
      "epoch: 1, step: 6, loss: 21187.080078125\n",
      "epoch: 1, val_loss: 5321844736.0\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x1664e9db0>\n",
      "epoch: 2, step: 0, loss: 21163.212890625\n",
      "epoch: 2, step: 1, loss: 21170.69921875\n",
      "epoch: 2, step: 2, loss: 21147.349609375\n",
      "epoch: 2, step: 3, loss: 21187.080078125\n",
      "epoch: 2, step: 4, loss: 21110.92578125\n",
      "epoch: 2, step: 5, loss: 21086.25\n",
      "epoch: 2, step: 6, loss: 21002.5390625\n",
      "epoch: 2, val_loss: 5321844736.0\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x1664e9db0>\n",
      "epoch: 3, step: 0, loss: 21187.080078125\n",
      "epoch: 3, step: 1, loss: 21002.5390625\n",
      "epoch: 3, step: 2, loss: 21110.92578125\n",
      "epoch: 3, step: 3, loss: 21086.25\n",
      "epoch: 3, step: 4, loss: 21147.349609375\n",
      "epoch: 3, step: 5, loss: 21170.69921875\n",
      "epoch: 3, step: 6, loss: 21163.212890625\n",
      "epoch: 3, val_loss: 5321843712.0\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x1664e9db0>\n",
      "epoch: 4, step: 0, loss: 21086.25\n",
      "epoch: 4, step: 1, loss: 21163.212890625\n",
      "epoch: 4, step: 2, loss: 21002.5390625\n",
      "epoch: 4, step: 3, loss: 21110.92578125\n",
      "epoch: 4, step: 4, loss: 21170.69921875\n",
      "epoch: 4, step: 5, loss: 21187.080078125\n",
      "epoch: 4, step: 6, loss: 21147.349609375\n",
      "epoch: 4, val_loss: 5321844736.0\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x1664e9db0>\n",
      "epoch: 5, step: 0, loss: 21187.080078125\n",
      "epoch: 5, step: 1, loss: 21002.5390625\n",
      "epoch: 5, step: 2, loss: 21163.212890625\n",
      "epoch: 5, step: 3, loss: 21147.349609375\n",
      "epoch: 5, step: 4, loss: 21170.69921875\n",
      "epoch: 5, step: 5, loss: 21086.25\n",
      "epoch: 5, step: 6, loss: 21110.92578125\n",
      "epoch: 5, val_loss: 5321844224.0\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x1664e9db0>\n",
      "epoch: 6, step: 0, loss: 21086.25\n",
      "epoch: 6, step: 1, loss: 21170.69921875\n",
      "epoch: 6, step: 2, loss: 21187.080078125\n",
      "epoch: 6, step: 3, loss: 21002.5390625\n",
      "epoch: 6, step: 4, loss: 21110.92578125\n",
      "epoch: 6, step: 5, loss: 21163.212890625\n",
      "epoch: 6, step: 6, loss: 21147.349609375\n",
      "epoch: 6, val_loss: 5321844736.0\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x1664e9db0>\n",
      "epoch: 7, step: 0, loss: 21170.69921875\n",
      "epoch: 7, step: 1, loss: 21187.080078125\n",
      "epoch: 7, step: 2, loss: 21163.212890625\n",
      "epoch: 7, step: 3, loss: 21147.349609375\n",
      "epoch: 7, step: 4, loss: 21086.25\n",
      "epoch: 7, step: 5, loss: 21002.5390625\n",
      "epoch: 7, step: 6, loss: 21110.92578125\n",
      "epoch: 7, val_loss: 5321844736.0\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x1664e9db0>\n",
      "epoch: 8, step: 0, loss: 21187.080078125\n",
      "epoch: 8, step: 1, loss: 21086.25\n",
      "epoch: 8, step: 2, loss: 21170.69921875\n",
      "epoch: 8, step: 3, loss: 21163.212890625\n",
      "epoch: 8, step: 4, loss: 21110.92578125\n",
      "epoch: 8, step: 5, loss: 21147.349609375\n",
      "epoch: 8, step: 6, loss: 21002.5390625\n",
      "epoch: 8, val_loss: 5321844736.0\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x1664e9db0>\n",
      "epoch: 9, step: 0, loss: 21086.25\n",
      "epoch: 9, step: 1, loss: 21110.92578125\n",
      "epoch: 9, step: 2, loss: 21187.080078125\n",
      "epoch: 9, step: 3, loss: 21170.69921875\n",
      "epoch: 9, step: 4, loss: 21147.349609375\n",
      "epoch: 9, step: 5, loss: 21002.5390625\n",
      "epoch: 9, step: 6, loss: 21163.212890625\n",
      "epoch: 9, val_loss: 5321844224.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:z2pekgus) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7070cc922cfb4ce5a9b59004c3df804d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇██</td></tr><tr><td>train_loss</td><td>▆▄█▁▅▁▇▆▇▇█▄█▅▄▇▄▁▅██▇▆▄▄█▅▇▇▇▄▁█▇▅▆▄█▆▇</td></tr><tr><td>val_loss</td><td>▁██▁█▅███▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>step</td><td>70</td></tr><tr><td>train_loss</td><td>21163.21289</td></tr><tr><td>val_loss</td><td>5321844224.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">prime-serenity-12</strong> at: <a href='https://wandb.ai/tum-traffic-engineering/gnn_1/runs/z2pekgus' target=\"_blank\">https://wandb.ai/tum-traffic-engineering/gnn_1/runs/z2pekgus</a><br/> View project at: <a href='https://wandb.ai/tum-traffic-engineering/gnn_1' target=\"_blank\">https://wandb.ai/tum-traffic-engineering/gnn_1</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240701_133623-z2pekgus/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:z2pekgus). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e3535451376460c97f0880c4e5c3c90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011167437499777104, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/elenanatterer/Development/MATSim/eqasim-java/ile_de_france/src/main/python/gnn/wandb/run-20240701_133631-wy65bp5r</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/tum-traffic-engineering/gnn_1/runs/wy65bp5r' target=\"_blank\">different-bird-13</a></strong> to <a href='https://wandb.ai/tum-traffic-engineering/gnn_1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/tum-traffic-engineering/gnn_1' target=\"_blank\">https://wandb.ai/tum-traffic-engineering/gnn_1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/tum-traffic-engineering/gnn_1/runs/wy65bp5r' target=\"_blank\">https://wandb.ai/tum-traffic-engineering/gnn_1/runs/wy65bp5r</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x168c8db40>\n",
      "epoch: 0, step: 0, loss: 21147.349609375\n",
      "epoch: 0, step: 1, loss: 21086.25\n",
      "epoch: 0, step: 2, loss: 21002.5390625\n",
      "epoch: 0, step: 3, loss: 21187.080078125\n",
      "epoch: 0, step: 4, loss: 21110.92578125\n",
      "epoch: 0, step: 5, loss: 21163.212890625\n",
      "epoch: 0, step: 6, loss: 21170.69921875\n",
      "epoch: 0, val_loss: 5321844736.0\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x168c8db40>\n",
      "epoch: 1, step: 0, loss: 21086.25\n",
      "epoch: 1, step: 1, loss: 21002.5390625\n",
      "epoch: 1, step: 2, loss: 21170.69921875\n",
      "epoch: 1, step: 3, loss: 21147.349609375\n",
      "epoch: 1, step: 4, loss: 21187.080078125\n",
      "epoch: 1, step: 5, loss: 21163.212890625\n",
      "epoch: 1, step: 6, loss: 21110.92578125\n",
      "epoch: 1, val_loss: 5321844224.0\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x168c8db40>\n",
      "epoch: 2, step: 0, loss: 21163.212890625\n",
      "epoch: 2, step: 1, loss: 21170.69921875\n",
      "epoch: 2, step: 2, loss: 21002.5390625\n",
      "epoch: 2, step: 3, loss: 21187.080078125\n",
      "epoch: 2, step: 4, loss: 21110.92578125\n",
      "epoch: 2, step: 5, loss: 21086.25\n",
      "epoch: 2, step: 6, loss: 21147.349609375\n",
      "epoch: 2, val_loss: 5321844224.0\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x168c8db40>\n",
      "epoch: 3, step: 0, loss: 21086.25\n",
      "epoch: 3, step: 1, loss: 21187.080078125\n",
      "epoch: 3, step: 2, loss: 21110.92578125\n",
      "epoch: 3, step: 3, loss: 21170.69921875\n",
      "epoch: 3, step: 4, loss: 21163.212890625\n",
      "epoch: 3, step: 5, loss: 21002.5390625\n",
      "epoch: 3, step: 6, loss: 21147.349609375\n",
      "epoch: 3, val_loss: 5321844736.0\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x168c8db40>\n",
      "epoch: 4, step: 0, loss: 21187.080078125\n",
      "epoch: 4, step: 1, loss: 21110.92578125\n",
      "epoch: 4, step: 2, loss: 21086.25\n",
      "epoch: 4, step: 3, loss: 21170.69921875\n",
      "epoch: 4, step: 4, loss: 21002.5390625\n",
      "epoch: 4, step: 5, loss: 21163.212890625\n",
      "epoch: 4, step: 6, loss: 21147.349609375\n",
      "epoch: 4, val_loss: 5321844224.0\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x168c8db40>\n",
      "epoch: 5, step: 0, loss: 21163.212890625\n",
      "epoch: 5, step: 1, loss: 21110.92578125\n",
      "epoch: 5, step: 2, loss: 21002.5390625\n",
      "epoch: 5, step: 3, loss: 21187.080078125\n",
      "epoch: 5, step: 4, loss: 21147.349609375\n",
      "epoch: 5, step: 5, loss: 21086.25\n",
      "epoch: 5, step: 6, loss: 21170.69921875\n",
      "epoch: 5, val_loss: 5321844224.0\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x168c8db40>\n",
      "epoch: 6, step: 0, loss: 21002.5390625\n",
      "epoch: 6, step: 1, loss: 21086.25\n",
      "epoch: 6, step: 2, loss: 21187.080078125\n",
      "epoch: 6, step: 3, loss: 21147.349609375\n",
      "epoch: 6, step: 4, loss: 21163.212890625\n",
      "epoch: 6, step: 5, loss: 21110.92578125\n",
      "epoch: 6, step: 6, loss: 21170.69921875\n",
      "epoch: 6, val_loss: 5321844736.0\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x168c8db40>\n",
      "epoch: 7, step: 0, loss: 21163.212890625\n",
      "epoch: 7, step: 1, loss: 21147.349609375\n",
      "epoch: 7, step: 2, loss: 21187.080078125\n",
      "epoch: 7, step: 3, loss: 21086.25\n",
      "epoch: 7, step: 4, loss: 21170.69921875\n",
      "epoch: 7, step: 5, loss: 21002.5390625\n",
      "epoch: 7, step: 6, loss: 21110.92578125\n",
      "epoch: 7, val_loss: 5321843712.0\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x168c8db40>\n",
      "epoch: 8, step: 0, loss: 21147.349609375\n",
      "epoch: 8, step: 1, loss: 21086.25\n",
      "epoch: 8, step: 2, loss: 21110.92578125\n",
      "epoch: 8, step: 3, loss: 21002.5390625\n",
      "epoch: 8, step: 4, loss: 21170.69921875\n",
      "epoch: 8, step: 5, loss: 21187.080078125\n",
      "epoch: 8, step: 6, loss: 21163.212890625\n",
      "epoch: 8, val_loss: 5321844736.0\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x168c8db40>\n",
      "epoch: 9, step: 0, loss: 21163.212890625\n",
      "epoch: 9, step: 1, loss: 21187.080078125\n",
      "epoch: 9, step: 2, loss: 21147.349609375\n",
      "epoch: 9, step: 3, loss: 21110.92578125\n",
      "epoch: 9, step: 4, loss: 21086.25\n",
      "epoch: 9, step: 5, loss: 21002.5390625\n",
      "epoch: 9, step: 6, loss: 21170.69921875\n",
      "epoch: 9, val_loss: 5321844736.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:wy65bp5r) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ea41b5ca87f440a9bdc2f08dca57682",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.020 MB of 0.020 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇██</td></tr><tr><td>train_loss</td><td>▆▄█▇▄▁▆▇▇▇█▄▄▅▇▁█▄▇▇▇▁█▄▁█▇▅▇█▇▁▆▅▇█▇▆▄▇</td></tr><tr><td>val_loss</td><td>█▅▅█▅▅█▁██</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>step</td><td>70</td></tr><tr><td>train_loss</td><td>21170.69922</td></tr><tr><td>val_loss</td><td>5321844736.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">different-bird-13</strong> at: <a href='https://wandb.ai/tum-traffic-engineering/gnn_1/runs/wy65bp5r' target=\"_blank\">https://wandb.ai/tum-traffic-engineering/gnn_1/runs/wy65bp5r</a><br/> View project at: <a href='https://wandb.ai/tum-traffic-engineering/gnn_1' target=\"_blank\">https://wandb.ai/tum-traffic-engineering/gnn_1</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240701_133631-wy65bp5r/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:wy65bp5r). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8e09f7cd390400ca384b234b99e63fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011167901388964513, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/elenanatterer/Development/MATSim/eqasim-java/ile_de_france/src/main/python/gnn/wandb/run-20240701_133642-7evjr63y</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/tum-traffic-engineering/gnn_1/runs/7evjr63y' target=\"_blank\">electric-dream-14</a></strong> to <a href='https://wandb.ai/tum-traffic-engineering/gnn_1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/tum-traffic-engineering/gnn_1' target=\"_blank\">https://wandb.ai/tum-traffic-engineering/gnn_1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/tum-traffic-engineering/gnn_1/runs/7evjr63y' target=\"_blank\">https://wandb.ai/tum-traffic-engineering/gnn_1/runs/7evjr63y</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x162c6c4c0>\n",
      "epoch: 0, step: 0, loss: 21086.25\n",
      "epoch: 0, step: 1, loss: 21147.349609375\n",
      "epoch: 0, step: 2, loss: 21110.92578125\n",
      "epoch: 0, step: 3, loss: 21002.5390625\n",
      "epoch: 0, step: 4, loss: 21187.080078125\n",
      "epoch: 0, step: 5, loss: 21163.212890625\n",
      "epoch: 0, step: 6, loss: 21170.69921875\n",
      "epoch: 0, val_loss: 5321844736.0\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x162c6c4c0>\n",
      "epoch: 1, step: 0, loss: 21002.5390625\n",
      "epoch: 1, step: 1, loss: 21163.212890625\n",
      "epoch: 1, step: 2, loss: 21187.080078125\n",
      "epoch: 1, step: 3, loss: 21170.69921875\n",
      "epoch: 1, step: 4, loss: 21147.349609375\n",
      "epoch: 1, step: 5, loss: 21086.25\n",
      "epoch: 1, step: 6, loss: 21110.92578125\n",
      "epoch: 1, val_loss: 5321843712.0\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x162c6c4c0>\n",
      "epoch: 2, step: 0, loss: 21086.25\n",
      "epoch: 2, step: 1, loss: 21163.212890625\n",
      "epoch: 2, step: 2, loss: 21170.69921875\n",
      "epoch: 2, step: 3, loss: 21110.92578125\n",
      "epoch: 2, step: 4, loss: 21147.349609375\n",
      "epoch: 2, step: 5, loss: 21187.080078125\n",
      "epoch: 2, step: 6, loss: 21002.5390625\n",
      "epoch: 2, val_loss: 5321844224.0\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x162c6c4c0>\n",
      "epoch: 3, step: 0, loss: 21147.349609375\n",
      "epoch: 3, step: 1, loss: 21110.92578125\n",
      "epoch: 3, step: 2, loss: 21086.25\n",
      "epoch: 3, step: 3, loss: 21002.5390625\n",
      "epoch: 3, step: 4, loss: 21187.080078125\n",
      "epoch: 3, step: 5, loss: 21170.69921875\n",
      "epoch: 3, step: 6, loss: 21163.212890625\n",
      "epoch: 3, val_loss: 5321844224.0\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x162c6c4c0>\n",
      "epoch: 4, step: 0, loss: 21187.080078125\n",
      "epoch: 4, step: 1, loss: 21147.349609375\n",
      "epoch: 4, step: 2, loss: 21163.212890625\n",
      "epoch: 4, step: 3, loss: 21170.69921875\n",
      "epoch: 4, step: 4, loss: 21002.5390625\n",
      "epoch: 4, step: 5, loss: 21110.92578125\n",
      "epoch: 4, step: 6, loss: 21086.25\n",
      "epoch: 4, val_loss: 5321844224.0\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x162c6c4c0>\n",
      "epoch: 5, step: 0, loss: 21086.25\n",
      "epoch: 5, step: 1, loss: 21187.080078125\n",
      "epoch: 5, step: 2, loss: 21170.69921875\n",
      "epoch: 5, step: 3, loss: 21147.349609375\n",
      "epoch: 5, step: 4, loss: 21110.92578125\n",
      "epoch: 5, step: 5, loss: 21163.212890625\n",
      "epoch: 5, step: 6, loss: 21002.5390625\n",
      "epoch: 5, val_loss: 5321844224.0\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x162c6c4c0>\n",
      "epoch: 6, step: 0, loss: 21147.349609375\n",
      "epoch: 6, step: 1, loss: 21163.212890625\n",
      "epoch: 6, step: 2, loss: 21170.69921875\n",
      "epoch: 6, step: 3, loss: 21086.25\n",
      "epoch: 6, step: 4, loss: 21187.080078125\n",
      "epoch: 6, step: 5, loss: 21002.5390625\n",
      "epoch: 6, step: 6, loss: 21110.92578125\n",
      "epoch: 6, val_loss: 5321843712.0\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x162c6c4c0>\n",
      "epoch: 7, step: 0, loss: 21170.69921875\n",
      "epoch: 7, step: 1, loss: 21002.5390625\n",
      "epoch: 7, step: 2, loss: 21110.92578125\n",
      "epoch: 7, step: 3, loss: 21086.25\n",
      "epoch: 7, step: 4, loss: 21163.212890625\n",
      "epoch: 7, step: 5, loss: 21187.080078125\n",
      "epoch: 7, step: 6, loss: 21147.349609375\n",
      "epoch: 7, val_loss: 5321844224.0\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x162c6c4c0>\n",
      "epoch: 8, step: 0, loss: 21170.69921875\n",
      "epoch: 8, step: 1, loss: 21110.92578125\n",
      "epoch: 8, step: 2, loss: 21086.25\n",
      "epoch: 8, step: 3, loss: 21163.212890625\n",
      "epoch: 8, step: 4, loss: 21187.080078125\n",
      "epoch: 8, step: 5, loss: 21147.349609375\n",
      "epoch: 8, step: 6, loss: 21002.5390625\n",
      "epoch: 8, val_loss: 5321844224.0\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x162c6c4c0>\n",
      "epoch: 9, step: 0, loss: 21086.25\n",
      "epoch: 9, step: 1, loss: 21147.349609375\n",
      "epoch: 9, step: 2, loss: 21110.92578125\n",
      "epoch: 9, step: 3, loss: 21187.080078125\n",
      "epoch: 9, step: 4, loss: 21163.212890625\n",
      "epoch: 9, step: 5, loss: 21002.5390625\n",
      "epoch: 9, step: 6, loss: 21170.69921875\n",
      "epoch: 9, val_loss: 5321844736.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:7evjr63y) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98c39d534466417ab35417f562bd9001",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.010 MB uploaded\\r'), FloatProgress(value=0.09911242603550297, max=1.…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇██</td></tr><tr><td>train_loss</td><td>▄▆▁▇▁▇▇▄▄▇▅█▆▄▁▇█▇▇▅▄▇▆▇▆▇█▁▇▅▇█▇▄█▆▄▅▇▇</td></tr><tr><td>val_loss</td><td>█▁▅▅▅▅▁▅▅█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>step</td><td>70</td></tr><tr><td>train_loss</td><td>21170.69922</td></tr><tr><td>val_loss</td><td>5321844736.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">electric-dream-14</strong> at: <a href='https://wandb.ai/tum-traffic-engineering/gnn_1/runs/7evjr63y' target=\"_blank\">https://wandb.ai/tum-traffic-engineering/gnn_1/runs/7evjr63y</a><br/> View project at: <a href='https://wandb.ai/tum-traffic-engineering/gnn_1' target=\"_blank\">https://wandb.ai/tum-traffic-engineering/gnn_1</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240701_133642-7evjr63y/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:7evjr63y). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4eaad47dacaa408fad625541903059eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011135936110966011, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/elenanatterer/Development/MATSim/eqasim-java/ile_de_france/src/main/python/gnn/wandb/run-20240701_133650-hta4c3m4</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/tum-traffic-engineering/gnn_1/runs/hta4c3m4' target=\"_blank\">frosty-frost-15</a></strong> to <a href='https://wandb.ai/tum-traffic-engineering/gnn_1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/tum-traffic-engineering/gnn_1' target=\"_blank\">https://wandb.ai/tum-traffic-engineering/gnn_1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/tum-traffic-engineering/gnn_1/runs/hta4c3m4' target=\"_blank\">https://wandb.ai/tum-traffic-engineering/gnn_1/runs/hta4c3m4</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x168e31390>\n",
      "epoch: 0, step: 0, loss: 21110.92578125\n",
      "epoch: 0, step: 1, loss: 21002.5390625\n",
      "epoch: 0, step: 2, loss: 21163.212890625\n",
      "epoch: 0, step: 3, loss: 21187.080078125\n",
      "epoch: 0, step: 4, loss: 21170.69921875\n",
      "epoch: 0, step: 5, loss: 21086.25\n",
      "epoch: 0, step: 6, loss: 21147.349609375\n",
      "epoch: 0, val_loss: 5321844736.0\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x168e31390>\n",
      "epoch: 1, step: 0, loss: 21147.349609375\n",
      "epoch: 1, step: 1, loss: 21187.080078125\n",
      "epoch: 1, step: 2, loss: 21163.212890625\n",
      "epoch: 1, step: 3, loss: 21086.25\n",
      "epoch: 1, step: 4, loss: 21170.69921875\n",
      "epoch: 1, step: 5, loss: 21110.92578125\n",
      "epoch: 1, step: 6, loss: 21002.5390625\n",
      "epoch: 1, val_loss: 5321844224.0\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x168e31390>\n",
      "epoch: 2, step: 0, loss: 21110.92578125\n",
      "epoch: 2, step: 1, loss: 21187.080078125\n",
      "epoch: 2, step: 2, loss: 21170.69921875\n",
      "epoch: 2, step: 3, loss: 21147.349609375\n",
      "epoch: 2, step: 4, loss: 21163.212890625\n",
      "epoch: 2, step: 5, loss: 21086.25\n",
      "epoch: 2, step: 6, loss: 21002.5390625\n",
      "epoch: 2, val_loss: 5321844224.0\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x168e31390>\n",
      "epoch: 3, step: 0, loss: 21163.212890625\n",
      "epoch: 3, step: 1, loss: 21170.69921875\n",
      "epoch: 3, step: 2, loss: 21086.25\n",
      "epoch: 3, step: 3, loss: 21110.92578125\n",
      "epoch: 3, step: 4, loss: 21002.5390625\n",
      "epoch: 3, step: 5, loss: 21187.080078125\n",
      "epoch: 3, step: 6, loss: 21147.349609375\n",
      "epoch: 3, val_loss: 5321844224.0\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x168e31390>\n",
      "epoch: 4, step: 0, loss: 21163.212890625\n",
      "epoch: 4, step: 1, loss: 21086.25\n",
      "epoch: 4, step: 2, loss: 21147.349609375\n",
      "epoch: 4, step: 3, loss: 21002.5390625\n",
      "epoch: 4, step: 4, loss: 21170.69921875\n",
      "epoch: 4, step: 5, loss: 21187.080078125\n",
      "epoch: 4, step: 6, loss: 21110.92578125\n",
      "epoch: 4, val_loss: 5321844224.0\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x168e31390>\n",
      "epoch: 5, step: 0, loss: 21163.212890625\n",
      "epoch: 5, step: 1, loss: 21086.25\n",
      "epoch: 5, step: 2, loss: 21110.92578125\n",
      "epoch: 5, step: 3, loss: 21170.69921875\n",
      "epoch: 5, step: 4, loss: 21147.349609375\n",
      "epoch: 5, step: 5, loss: 21187.080078125\n",
      "epoch: 5, step: 6, loss: 21002.5390625\n",
      "epoch: 5, val_loss: 5321843712.0\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x168e31390>\n",
      "epoch: 6, step: 0, loss: 21002.5390625\n",
      "epoch: 6, step: 1, loss: 21147.349609375\n",
      "epoch: 6, step: 2, loss: 21170.69921875\n",
      "epoch: 6, step: 3, loss: 21163.212890625\n",
      "epoch: 6, step: 4, loss: 21086.25\n",
      "epoch: 6, step: 5, loss: 21110.92578125\n",
      "epoch: 6, step: 6, loss: 21187.080078125\n",
      "epoch: 6, val_loss: 5321844224.0\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x168e31390>\n",
      "epoch: 7, step: 0, loss: 21170.69921875\n",
      "epoch: 7, step: 1, loss: 21002.5390625\n",
      "epoch: 7, step: 2, loss: 21110.92578125\n",
      "epoch: 7, step: 3, loss: 21086.25\n",
      "epoch: 7, step: 4, loss: 21163.212890625\n",
      "epoch: 7, step: 5, loss: 21147.349609375\n",
      "epoch: 7, step: 6, loss: 21187.080078125\n",
      "epoch: 7, val_loss: 5321843712.0\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x168e31390>\n",
      "epoch: 8, step: 0, loss: 21170.69921875\n",
      "epoch: 8, step: 1, loss: 21187.080078125\n",
      "epoch: 8, step: 2, loss: 21002.5390625\n",
      "epoch: 8, step: 3, loss: 21163.212890625\n",
      "epoch: 8, step: 4, loss: 21086.25\n",
      "epoch: 8, step: 5, loss: 21110.92578125\n",
      "epoch: 8, step: 6, loss: 21147.349609375\n",
      "epoch: 8, val_loss: 5321844736.0\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x168e31390>\n",
      "epoch: 9, step: 0, loss: 21147.349609375\n",
      "epoch: 9, step: 1, loss: 21163.212890625\n",
      "epoch: 9, step: 2, loss: 21002.5390625\n",
      "epoch: 9, step: 3, loss: 21187.080078125\n",
      "epoch: 9, step: 4, loss: 21170.69921875\n",
      "epoch: 9, step: 5, loss: 21086.25\n",
      "epoch: 9, step: 6, loss: 21110.92578125\n",
      "epoch: 9, val_loss: 5321844224.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b62782971c54bce9434a30d08e0c2c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.020 MB of 0.020 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇██</td></tr><tr><td>train_loss</td><td>▅▁█▄▆█▄▅▅█▆▄▇▄▅█▇▆▁█▇▅▇█▁▇▄▅▇▅▇▆▇▁▄▅▆▁▇▅</td></tr><tr><td>val_loss</td><td>█▅▅▅▅▁▅▁█▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>step</td><td>70</td></tr><tr><td>train_loss</td><td>21110.92578</td></tr><tr><td>val_loss</td><td>5321844224.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">frosty-frost-15</strong> at: <a href='https://wandb.ai/tum-traffic-engineering/gnn_1/runs/hta4c3m4' target=\"_blank\">https://wandb.ai/tum-traffic-engineering/gnn_1/runs/hta4c3m4</a><br/> View project at: <a href='https://wandb.ai/tum-traffic-engineering/gnn_1' target=\"_blank\">https://wandb.ai/tum-traffic-engineering/gnn_1</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240701_133650-hta4c3m4/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Train the model\n",
    "for epoch in range(10):\n",
    "    # 🐝 initialise a wandb run\n",
    "    wandb.init(\n",
    "        project=\"gnn_1\",\n",
    "        config={\n",
    "            \"epochs\": 10,\n",
    "            \"batch_size\": 1,\n",
    "            \"lr\": 0.01,\n",
    "            \"dropout\": random.uniform(0.01, 0.80),\n",
    "            })\n",
    "    config = wandb.config\n",
    "    \n",
    "    # Get data\n",
    "    train_dl = get_data_from_dataloader(dataset  = dataset, is_train=True, batch_size=config.batch_size)\n",
    "    valid_dl = get_data_from_dataloader(dataset  = dataset, is_train=False, batch_size=config.batch_size)\n",
    "    n_steps_per_epoch = math.ceil(len(train_dl.dataset) / config.batch_size)\n",
    "\n",
    "    # Get the model\n",
    "    model = GnnModel().to(device)\n",
    "    \n",
    "    # Define loss and optimizer\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "    loss_fct = torch.nn.MSELoss()\n",
    "    \n",
    "    # Training\n",
    "    example_ct = 0\n",
    "    step_ct = 0\n",
    "    for epoch in range(config.epochs):\n",
    "        model.train()\n",
    "        print(train_dl)\n",
    "        for step, data in enumerate(train_dl):\n",
    "            input_node_features, expected_node_feats = data.x.to(device), data.y.to(device)\n",
    "            predicted = model(data)\n",
    "            train_loss = loss_fct(predicted, expected_node_feats)\n",
    "            optimizer.zero_grad()\n",
    "            train_loss.backward()\n",
    "            optimizer.step()\n",
    "            wandb.log({\"train_loss\": train_loss.item(), \"step\": step_ct})\n",
    "            print(f\"epoch: {epoch}, step: {step}, loss: {train_loss.item()}\")\n",
    "            example_ct += len(expected_node_feats)\n",
    "            step_ct += 1\n",
    "            \n",
    "        val_loss = validate_model(model, valid_dl, loss_fct, device)\n",
    "        wandb.log({\"val_loss\": val_loss,  \"step\": step_ct})\n",
    "        # print(f\"epoch: {epoch}, val_loss: {val_loss}\")\n",
    "        \n",
    "wandb.summary[\"val_loss\"] = val_loss\n",
    "wandb.finish()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 20835.3457\n",
      "Root Mean Squared Error: 144.3445\n",
      "Mean of target values: 51.4052\n",
      "Standard deviation of target values: 134.8809\n",
      "Minimum target value: 0.0000\n",
      "Maximum target value: 1593.0000\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "# model.eval()\n",
    "# with torch.no_grad():\n",
    "#     pred = model(data).cpu()\n",
    "#     target = data.y.view(-1, 1).cpu()\n",
    "#     mse = F.mse_loss(pred, target).item()\n",
    "#     rmse = torch.sqrt(torch.tensor(mse)).item()\n",
    "#     print(f'Mean Squared Error: {mse:.4f}')\n",
    "#     print(f'Root Mean Squared Error: {rmse:.4f}')\n",
    "\n",
    "# # Calculate target value statistics for comparison\n",
    "# target_values = target.numpy()\n",
    "# mean_target = target_values.mean()\n",
    "# std_target = target_values.std()\n",
    "# min_target = target_values.min()\n",
    "# max_target = target_values.max()\n",
    "\n",
    "# print(f'Mean of target values: {mean_target:.4f}')\n",
    "# print(f'Standard deviation of target values: {std_target:.4f}')\n",
    "# print(f'Minimum target value: {min_target:.4f}')\n",
    "# print(f'Maximum target value: {max_target:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Paris_Analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
