{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import glob\n",
    "import math\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import torch\n",
    "\n",
    "import processing_io as pio\n",
    "from torch_geometric.transforms import LineGraph\n",
    "\n",
    "from torch_geometric.data import Data, Batch\n",
    "import shapely.wkt as wkt\n",
    "from tqdm import tqdm\n",
    "import fiona\n",
    "import os\n",
    "\n",
    "import alphashape\n",
    "from shapely.geometry import Polygon\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from shapely.geometry import Point\n",
    "\n",
    "\n",
    "highway_mapping = {\n",
    "    'trunk': 0, 'trunk_link': 0, 'motorway_link': 0,\n",
    "    'primary': 1, 'primary_link': 1,\n",
    "    'secondary': 2, 'secondary_link': 2,\n",
    "    'tertiary': 3, 'tertiary_link': 3,\n",
    "    'residential': 4, 'living_street': 5,\n",
    "    'pedestrian': 6, 'service': 7,\n",
    "    'construction': 8, 'unclassified': 9,\n",
    "    'np.nan': -1\n",
    "}\n",
    "result_df_name = 'sim_output_1pm_capacity_reduction_10k_PRELIMINARY'\n",
    "result_path = '../../../../data/datasets_simulation_outputs/' + result_df_name + '.pt'\n",
    "string_is_for_1pm = \"pop_1pm\"\n",
    "\n",
    "base_dir_sample_sim_input = '../../../../data/' + string_is_for_1pm + '_simulations/' + string_is_for_1pm + '_policies_combinations_with_normal_dist/'\n",
    "subdirs_pattern = os.path.join(base_dir_sample_sim_input, 'output_networks_*')\n",
    "subdirs = list(set(glob.glob(subdirs_pattern)))\n",
    "subdirs.sort()\n",
    "\n",
    "paris_inside_bvd_peripherique = \"../../../../data/paris_inside_bvd_per/referentiel-comptages-edit.shp\"\n",
    "gdf_paris_inside_bvd_per = gpd.read_file(paris_inside_bvd_peripherique)\n",
    "boundary_df = alphashape.alphashape(gdf_paris_inside_bvd_per, 435).exterior[0]\n",
    "linear_ring_polygon = Polygon(boundary_df)\n",
    "\n",
    "gdf_basecase_output_links = gpd.read_file('results/' + string_is_for_1pm + '_basecase_average_output_links.geojson')\n",
    "gdf_basecase_average_mode_stats = pd.read_csv('results/' + string_is_for_1pm + '_basecase_average_mode_stats.csv', delimiter=';')\n",
    "districts = gpd.read_file(\"../../../../data/visualisation/districts_paris.geojson\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abstract\n",
    "\n",
    "This is further than process_output_of_simulations_with_all_output_links_and_eqasim_info.ipynb, as it also includes more input information."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process results\n",
    "\n",
    "Process the outputs of the simulations for further usage by GNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_close_homes(links_gdf_input:pd.DataFrame, information_gdf_input:pd.DataFrame, utm_crs:str, distance:int=50):\n",
    "    links_gdf = links_gdf_input.copy()\n",
    "    information_gdf = information_gdf_input.copy()\n",
    "    close_places = []\n",
    "    links_gdf_utm = links_gdf.to_crs(utm_crs)\n",
    "    information_gdf_utm = information_gdf.to_crs(utm_crs)\n",
    "    for i, row in tqdm(enumerate(links_gdf_utm.iterrows()), desc=\"Processing rows\", unit=\"row\"):\n",
    "        buffer_utm = row[1].geometry.buffer(distance=distance)\n",
    "        buffer = gpd.GeoSeries([buffer_utm], crs=utm_crs).to_crs(links_gdf_utm.crs)[0]\n",
    "        matched_information = information_gdf_utm[information_gdf_utm.geometry.within(buffer)]\n",
    "        socioprofessional_classes = matched_information['socioprofessional_class'].tolist()\n",
    "        close_places.append((len(socioprofessional_classes), socioprofessional_classes))\n",
    "    return close_places\n",
    "\n",
    "# def process_close_count_to_tensor(close_count_list:list):\n",
    "#     socio_professional_classes = [item[1] for item in close_count_list]\n",
    "#     # unique_classes = set([cls for sublist in socio_professional_classes for cls in sublist])\n",
    "#     unique_classes = set([2, 3, 4, 5, 6, 7, 8])\n",
    "#     class_to_index = {cls: idx for idx, cls in enumerate(unique_classes)}\n",
    "\n",
    "#     tensor_shape = (len(close_count_list), len(unique_classes))\n",
    "#     close_homes_tensor = torch.zeros(tensor_shape)\n",
    "\n",
    "#     for i, classes in enumerate(socio_professional_classes):\n",
    "#         for cls in classes:\n",
    "#             close_homes_tensor[i, class_to_index[cls]] += 1\n",
    "    \n",
    "#     close_homes_tensor_sparse = close_homes_tensor.to_sparse()\n",
    "#     return close_homes_tensor_sparse\n",
    "\n",
    "def process_close_count_to_tensor(close_count_list: list):\n",
    "    socio_professional_classes = [item[1] for item in close_count_list]\n",
    "    unique_classes = set([2, 3, 4, 5, 6, 7, 8])\n",
    "    class_to_index = {cls: idx for idx, cls in enumerate(unique_classes)}\n",
    "\n",
    "    tensor_shape = (len(close_count_list), len(unique_classes))\n",
    "    close_homes_tensor = torch.zeros(tensor_shape)\n",
    "\n",
    "    for i, classes in enumerate(socio_professional_classes):\n",
    "        for cls in classes:\n",
    "            if cls in class_to_index:  # Ensure the class is in the predefined set\n",
    "                close_homes_tensor[i, class_to_index[cls]] += 1\n",
    "    \n",
    "    close_homes_tensor_sparse = close_homes_tensor.to_sparse()\n",
    "    return close_homes_tensor_sparse\n",
    "\n",
    "# Read all network data into a dictionary of GeoDataFrames\n",
    "def compute_result_dic_output_links():\n",
    "    result_dic = {}\n",
    "    base_network_no_policies = gdf_basecase_output_links\n",
    "    result_dic[\"base_network_no_policies\"] = base_network_no_policies\n",
    "    for subdir in tqdm(subdirs, desc=\"Processing subdirs\", unit=\"subdir\"):\n",
    "        # print(f'Accessing folder: {subdir}')\n",
    "        # print(len(os.listdir(subdir)))\n",
    "        networks = [network for network in os.listdir(subdir) if not network.endswith(\".DS_Store\")]\n",
    "        for network in networks:\n",
    "            file_path = os.path.join(subdir, network)\n",
    "            policy_key = pio.create_policy_key_1pm(network)\n",
    "            gdf_output_links = pio.read_output_links(file_path)\n",
    "            if (gdf_output_links is not None):\n",
    "                gdf_extended = pio.extend_geodataframe(gdf_base=gdf_basecase_output_links, gdf_to_extend=gdf_output_links, column_to_extend='highway', new_column_name='highway')\n",
    "                gdf_extended = pio.extend_geodataframe(gdf_base=gdf_basecase_output_links, gdf_to_extend=gdf_extended, column_to_extend='vol_car', new_column_name='vol_car_base_case')\n",
    "                result_dic[policy_key] = gdf_extended\n",
    "        break\n",
    "    return result_dic\n",
    "\n",
    "def calculate_averaged_results(trips_df):\n",
    "    \"\"\"Calculate average travel time and routed distance grouped by mode.\"\"\"\n",
    "    return trips_df.groupby('mode').agg(\n",
    "        total_travel_time=('travel_time', 'mean'),\n",
    "        total_routed_distance=('routed_distance', 'mean')\n",
    "    ).reset_index()\n",
    "\n",
    "def compute_result_dic_mode_stats(calculate_averaged_results):\n",
    "    result_dic_mode_stats = {}\n",
    "    result_dic_mode_stats[\"base_network_no_policies\"] = gdf_basecase_average_mode_stats\n",
    "    for subdir in tqdm(subdirs, desc=\"Processing subdirs\", unit=\"subdir\"):\n",
    "        networks = [network for network in os.listdir(subdir) if not network.endswith(\".DS_Store\")]\n",
    "        for network in networks:\n",
    "            file_path = os.path.join(subdir, network)\n",
    "            policy_key = pio.create_policy_key_1pm(network)\n",
    "            df_mode_stats = pd.read_csv(file_path + '/eqasim_trips.csv', delimiter=';')\n",
    "            averaged_results = calculate_averaged_results(df_mode_stats)\n",
    "            if (averaged_results is not None):\n",
    "                result_dic_mode_stats[policy_key] = averaged_results\n",
    "        break\n",
    "    return result_dic_mode_stats\n",
    "\n",
    "def encode_modes(gdf):\n",
    "    \"\"\"Encode the 'modes' attribute based on specific strings.\"\"\"\n",
    "    modes_conditions = {\n",
    "        'car': gdf['modes'].str.contains('car', case=False, na=False).astype(int),\n",
    "        'bus': gdf['modes'].str.contains('bus', case=False, na=False).astype(int),\n",
    "        'pt': gdf['modes'].str.contains('pt', case=False, na=False).astype(int),\n",
    "        'train': gdf['modes'].str.contains('train', case=False, na=False).astype(int),\n",
    "        'rail': gdf['modes'].str.contains('rail', case=False, na=False).astype(int),\n",
    "        'subway': gdf['modes'].str.contains('subway', case=False, na=False).astype(int)\n",
    "    }\n",
    "    modes_encoded = pd.DataFrame(modes_conditions)\n",
    "    return torch.tensor(modes_encoded.values, dtype=torch.float)\n",
    "\n",
    "def get_dfs(base_dir:str):\n",
    "    files = os.listdir(base_dir)\n",
    "    for file in files:\n",
    "        file_path = os.path.join(base_dir, file)\n",
    "        base_name, ext = os.path.splitext(file)\n",
    "        if base_name.startswith(\"idf_1pm_\"):\n",
    "            base_name = base_name.replace(\"idf_1pm_\", \"\")\n",
    "        var_name = base_name  # Start with the cleaned base name\n",
    "    \n",
    "        if file.endswith('.csv'):\n",
    "            try:\n",
    "                var_name = f\"{var_name}_df\"  \n",
    "                globals()[var_name] = pd.read_csv(file_path, sep=\";\")\n",
    "                print(f\"Loaded CSV file: {file} into variable: {var_name}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading CSV file {file}: {e}\")\n",
    "            \n",
    "        elif file.endswith('.gpkg'):\n",
    "            try:\n",
    "                var_name = f\"{var_name}_gdf\"  \n",
    "                layers = fiona.listlayers(file_path)\n",
    "                geodataframes = {layer: gpd.read_file(file_path, layer=layer, geometry = 'geometry', crs=\"EPSG:2154\") for layer in layers}\n",
    "                for layer, gdf in geodataframes.items():\n",
    "                # print(f\"Layer: {layer}\")\n",
    "                    gdf = gdf.to_crs(epsg=4326)\n",
    "                    globals()[var_name] = gdf\n",
    "                    print(f\"Loaded GPKG file: {file} into variable: {var_name}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading CSV file {file}: {e}\")\n",
    "    homes_gdf = globals()[\"homes_gdf\"]\n",
    "    households_df = globals()[\"households_df\"]\n",
    "    persons_df = globals()[\"persons_df\"]\n",
    "    activities_gdf = globals()[\"activities_gdf\"]\n",
    "    trips_df = globals()[\"trips_gdf\"]\n",
    "    return homes_gdf, households_df, persons_df, activities_gdf, trips_df\n",
    "\n",
    "def extract_start_end_points(geometry):\n",
    "    if len(geometry.coords) != 2:\n",
    "        raise ValueError(\"Linestring does not have exactly 2 elements.\")\n",
    "    return geometry.coords[0], geometry.coords[-1]\n",
    "\n",
    "def get_close_trips_tensor(links_gdf_input, trips_gdf_input, utm_crs, distance):\n",
    "    close_trips_count = compute_close_homes(links_gdf_input = links_gdf_input, information_gdf_input = trips_gdf_input, utm_crs = utm_crs, distance=distance)\n",
    "    close_trips_count_tensor = process_close_count_to_tensor(close_trips_count)\n",
    "    return close_trips_count, close_trips_count_tensor\n",
    "\n",
    "def get_start_and_end_gdf(trips_with_socio, crs):\n",
    "    trips_start = trips_with_socio.copy()\n",
    "    trips_end = trips_with_socio.copy()\n",
    "\n",
    "    trips_start_gdf = gpd.GeoDataFrame(\n",
    "    trips_start, \n",
    "    geometry=gpd.points_from_xy(\n",
    "        trips_start['start_point'].apply(lambda p: p[0]), \n",
    "        trips_start['start_point'].apply(lambda p: p[1])\n",
    "    ), \n",
    "    crs=crs\n",
    ")\n",
    "\n",
    "    trips_end_gdf = gpd.GeoDataFrame(\n",
    "    trips_end, \n",
    "    geometry=gpd.points_from_xy(\n",
    "        trips_end['end_point'].apply(lambda p: p[0]), \n",
    "        trips_end['end_point'].apply(lambda p: p[1])\n",
    "    ), \n",
    "    crs=crs\n",
    ")\n",
    "    return trips_start_gdf,trips_end_gdf\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/m_/fjnjc1sn0ggc7z_2y7n27xfh0000gn/T/ipykernel_18131/245684739.py:5: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  districts['district_centroid'] = districts['geometry'].centroid\n",
      "/Users/elenanatterer/anaconda3/envs/Paris_Analysis/lib/python3.10/site-packages/IPython/core/interactiveshell.py:3448: FutureWarning: The `op` parameter is deprecated and will be removed in a future release. Please use the `predicate` parameter instead.\n",
      "  if await self.run_code(code, result, async_=asy):\n",
      "/Users/elenanatterer/anaconda3/envs/Paris_Analysis/lib/python3.10/site-packages/pandas/core/reshape/merge.py:1203: RuntimeWarning: invalid value encountered in cast\n",
      "  if not (lk == lk.astype(rk.dtype))[~np.isnan(lk)].all():\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>link</th>\n",
       "      <th>from_node</th>\n",
       "      <th>to_node</th>\n",
       "      <th>length</th>\n",
       "      <th>freespeed</th>\n",
       "      <th>capacity</th>\n",
       "      <th>lanes</th>\n",
       "      <th>modes</th>\n",
       "      <th>vol_car</th>\n",
       "      <th>osm:relation:route_master</th>\n",
       "      <th>...</th>\n",
       "      <th>osm:way:railway</th>\n",
       "      <th>osm:way:name</th>\n",
       "      <th>storageCapacityUsedInQsim</th>\n",
       "      <th>osm:way:tunnel</th>\n",
       "      <th>geometry</th>\n",
       "      <th>index_right</th>\n",
       "      <th>district</th>\n",
       "      <th>surface</th>\n",
       "      <th>perimetre</th>\n",
       "      <th>district_centroid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100315</td>\n",
       "      <td>24972409</td>\n",
       "      <td>24972408</td>\n",
       "      <td>16.181257</td>\n",
       "      <td>8.333333</td>\n",
       "      <td>480.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>bus,car,car_passenger</td>\n",
       "      <td>6.627451</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Carrefour de l'Odéon</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LINESTRING (2.33869 48.85181, 2.33847 48.85181)</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.153096e+06</td>\n",
       "      <td>6483.686786</td>\n",
       "      <td>POINT (2.33290 48.84913)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100316</td>\n",
       "      <td>5904976363</td>\n",
       "      <td>24983651</td>\n",
       "      <td>14.860209</td>\n",
       "      <td>8.333333</td>\n",
       "      <td>480.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>bus,car,car_passenger,pt</td>\n",
       "      <td>9.607843</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Carrefour de l'Odéon</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LINESTRING (2.33874 48.85242, 2.33872 48.85229)</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.153096e+06</td>\n",
       "      <td>6483.686786</td>\n",
       "      <td>POINT (2.33290 48.84913)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100317</td>\n",
       "      <td>24983651</td>\n",
       "      <td>5904976363</td>\n",
       "      <td>14.860209</td>\n",
       "      <td>8.333333</td>\n",
       "      <td>960.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>bus,car,car_passenger,pt</td>\n",
       "      <td>2.490196</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Carrefour de l'Odéon</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LINESTRING (2.33872 48.85229, 2.33874 48.85242)</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.153096e+06</td>\n",
       "      <td>6483.686786</td>\n",
       "      <td>POINT (2.33290 48.84913)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100321</td>\n",
       "      <td>664205947</td>\n",
       "      <td>24972376</td>\n",
       "      <td>22.264540</td>\n",
       "      <td>8.333333</td>\n",
       "      <td>960.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>car,car_passenger</td>\n",
       "      <td>6.941176</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Boulevard Saint-Germain</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LINESTRING (2.33994 48.85200, 2.33986 48.85181)</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.153096e+06</td>\n",
       "      <td>6483.686786</td>\n",
       "      <td>POINT (2.33290 48.84913)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100324</td>\n",
       "      <td>24972376</td>\n",
       "      <td>24972375</td>\n",
       "      <td>64.853276</td>\n",
       "      <td>8.333333</td>\n",
       "      <td>480.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>bus,car,car_passenger</td>\n",
       "      <td>7.607843</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rue Dupuytren</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LINESTRING (2.33986 48.85181, 2.33909 48.85152)</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.153096e+06</td>\n",
       "      <td>6483.686786</td>\n",
       "      <td>POINT (2.33290 48.84913)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     link   from_node     to_node     length  freespeed  capacity  lanes  \\\n",
       "0  100315    24972409    24972408  16.181257   8.333333     480.0    1.0   \n",
       "1  100316  5904976363    24983651  14.860209   8.333333     480.0    1.0   \n",
       "2  100317    24983651  5904976363  14.860209   8.333333     960.0    2.0   \n",
       "3  100321   664205947    24972376  22.264540   8.333333     960.0    2.0   \n",
       "4  100324    24972376    24972375  64.853276   8.333333     480.0    1.0   \n",
       "\n",
       "                      modes   vol_car osm:relation:route_master  ...  \\\n",
       "0     bus,car,car_passenger  6.627451                       NaN  ...   \n",
       "1  bus,car,car_passenger,pt  9.607843                       NaN  ...   \n",
       "2  bus,car,car_passenger,pt  2.490196                       NaN  ...   \n",
       "3         car,car_passenger  6.941176                       NaN  ...   \n",
       "4     bus,car,car_passenger  7.607843                       NaN  ...   \n",
       "\n",
       "  osm:way:railway             osm:way:name storageCapacityUsedInQsim  \\\n",
       "0             NaN     Carrefour de l'Odéon                       NaN   \n",
       "1             NaN     Carrefour de l'Odéon                       NaN   \n",
       "2             NaN     Carrefour de l'Odéon                       NaN   \n",
       "3             NaN  Boulevard Saint-Germain                       NaN   \n",
       "4             NaN            Rue Dupuytren                       NaN   \n",
       "\n",
       "  osm:way:tunnel                                         geometry  \\\n",
       "0            NaN  LINESTRING (2.33869 48.85181, 2.33847 48.85181)   \n",
       "1            NaN  LINESTRING (2.33874 48.85242, 2.33872 48.85229)   \n",
       "2            NaN  LINESTRING (2.33872 48.85229, 2.33874 48.85242)   \n",
       "3            NaN  LINESTRING (2.33994 48.85200, 2.33986 48.85181)   \n",
       "4            NaN  LINESTRING (2.33986 48.85181, 2.33909 48.85152)   \n",
       "\n",
       "   index_right district       surface    perimetre         district_centroid  \n",
       "0          5.0      6.0  2.153096e+06  6483.686786  POINT (2.33290 48.84913)  \n",
       "1          5.0      6.0  2.153096e+06  6483.686786  POINT (2.33290 48.84913)  \n",
       "2          5.0      6.0  2.153096e+06  6483.686786  POINT (2.33290 48.84913)  \n",
       "3          5.0      6.0  2.153096e+06  6483.686786  POINT (2.33290 48.84913)  \n",
       "4          5.0      6.0  2.153096e+06  6483.686786  POINT (2.33290 48.84913)  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_dic_output_links = compute_result_dic_output_links()\n",
    "result_dic_mode_stats = compute_result_dic_mode_stats(calculate_averaged_results)\n",
    "base_gdf = result_dic_output_links[\"base_network_no_policies\"]\n",
    "links_gdf = gpd.GeoDataFrame(base_gdf, geometry='geometry')\n",
    "links_gdf.crs = \"EPSG:2154\"  # Assuming the original CRS is EPSG:2154\n",
    "links_gdf.to_crs(\"EPSG:4326\", inplace=True)\n",
    "districts['district_centroid'] = districts['geometry'].centroid\n",
    "links_gdf_with_districts = gpd.sjoin(links_gdf, districts, how='left', op='intersects')\n",
    "links_gdf_with_districts = links_gdf_with_districts.rename(columns={'c_ar': 'district'})\n",
    "links_gdf_with_districts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "links_gdf_final = links_gdf_with_districts.copy()\n",
    "links_gdf = links_gdf_final.drop(columns=['index_right', 'osm:relation:route_master', \"osm:way:railway\", \"osm:way:name\", \"storageCapacityUsedInQsim\", \"osm:way:tunnel\", \"surface\", \"perimetre\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded CSV file: idf_1pm_persons.csv into variable: persons_df\n",
      "Loaded GPKG file: idf_1pm_commutes.gpkg into variable: commutes_gdf\n",
      "Loaded CSV file: idf_1pm_households.csv into variable: households_df\n",
      "Loaded CSV file: idf_1pm_trips.csv into variable: trips_df\n",
      "Loaded CSV file: idf_1pm_activities.csv into variable: activities_df\n",
      "Loaded CSV file: idf_1pm_vehicle_types.csv into variable: vehicle_types_df\n",
      "Loaded GPKG file: idf_1pm_trips.gpkg into variable: trips_gdf\n",
      "Loaded GPKG file: idf_1pm_activities.gpkg into variable: activities_gdf\n",
      "Loaded CSV file: idf_1pm_vehicles.csv into variable: vehicles_df\n",
      "Loaded GPKG file: idf_1pm_homes.gpkg into variable: homes_gdf\n"
     ]
    }
   ],
   "source": [
    "base_dir_sample_sim_input = '../../../../data/pop_1pm_simulations/idf_1pm/' \n",
    "homes_gdf, households_df, persons_df, activities_gdf, trips_df = get_dfs(base_dir=base_dir_sample_sim_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "population_df = pd.read_csv(\"intermediate_results/population.csv\")\n",
    "\n",
    "sorted_population_df = population_df.sort_values(by=\"id\")\n",
    "sorted_persons_df = persons_df.sort_values(by=\"person_id\")\n",
    "merged_df = pd.merge(sorted_persons_df, sorted_population_df, left_on=\"person_id\", right_on=\"id\")\n",
    "removed_some_columns = merged_df.copy()\n",
    "removed_some_columns = removed_some_columns.drop(columns=['employed_y', 'hasPtSubscription', 'householdId', 'sex_y', 'htsPersonId', 'censusPersonId', 'hasLicense', 'id', 'age_y'])\n",
    "updated_persons = removed_some_columns.copy()\n",
    "persons_with_geospatial_information = homes_gdf.merge(updated_persons, on='household_id', how='right')\n",
    "\n",
    "if not isinstance(persons_with_geospatial_information, gpd.GeoDataFrame):\n",
    "    persons_with_geospatial_information = gpd.GeoDataFrame(persons_with_geospatial_information, geometry=gpd.points_from_xy(persons_with_geospatial_information.longitude, persons_with_geospatial_information.latitude), crs= links_gdf.crs)\n",
    "\n",
    "utm_crs = 'EPSG:32631'  # UTM zone 31N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows: 32367row [01:54, 282.82row/s]\n",
      "Processing rows: 32367row [02:06, 256.01row/s]\n"
     ]
    }
   ],
   "source": [
    "# DEAL WITH TRIPS\n",
    "\n",
    "trips_with_socio = trips_df.merge(persons_with_geospatial_information[['person_id', 'socioprofessional_class']], on='person_id', how='left')\n",
    "trips_with_socio['start_point'] = trips_with_socio['geometry'].apply(lambda geom: extract_start_end_points(geom)[0])\n",
    "trips_with_socio['end_point'] = trips_with_socio['geometry'].apply(lambda geom: extract_start_end_points(geom)[1])\n",
    "\n",
    "trips_start_gdf, trips_end_gdf = get_start_and_end_gdf(trips_with_socio=trips_with_socio, crs=links_gdf_final.crs)\n",
    "\n",
    "close_trips_start, close_start_trips_tensor = get_close_trips_tensor(links_gdf_input=links_gdf, trips_gdf_input=trips_start_gdf, utm_crs=utm_crs, distance=50)\n",
    "close_trips_end, close_end_trips_tensor = get_close_trips_tensor(links_gdf_input=links_gdf, trips_gdf_input=trips_end_gdf, utm_crs=utm_crs, distance=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create tensors for each combination of \"preceding_purpose\" and \"following_purpose\"\n",
    "# unique_purposes = trips_with_socio['preceding_purpose'].unique()\n",
    "# close_start_trips_tensor_dict = {}\n",
    "# close_start_trips_dict = {}\n",
    "# close_end_trips_tensor_dict = {}\n",
    "# close_end_trips_dict = {}\n",
    "\n",
    "# for preceding_purpose in tqdm(unique_purposes, desc=\"Processing preceding purposes\", unit=\"purpose\"):\n",
    "#     for following_purpose in tqdm(unique_purposes, desc=\"Processing following purposes\", unit=\"purpose\"):\n",
    "#         if preceding_purpose != following_purpose:\n",
    "#             filtered_trips = trips_with_socio[(trips_with_socio['preceding_purpose'] == preceding_purpose) & (trips_with_socio['following_purpose'] == following_purpose)]\n",
    "#             if not filtered_trips.empty:\n",
    "#                 filtered_trips_start_gdf, filtered_trips_end_gdf = get_start_and_end_gdf(trips_with_socio=filtered_trips, crs=links_gdf.crs)\n",
    "                \n",
    "#                 close_start_trips, close_start_trips_tensor = get_close_trips_tensor(links_gdf_input=links_gdf, trips_gdf_input=filtered_trips_start_gdf, utm_crs=utm_crs, distance=50)\n",
    "#                 close_end_trips, close_end_trips_tensor = get_close_trips_tensor(links_gdf_input=links_gdf, trips_gdf_input=filtered_trips_end_gdf, utm_crs=utm_crs, distance=50)\n",
    "                \n",
    "#                 tensor_key = f\"{preceding_purpose}_{following_purpose}\"\n",
    "#                 close_start_trips_tensor_dict[tensor_key] = close_start_trips_tensor\n",
    "#                 close_start_trips_dict[tensor_key] = close_start_trips\n",
    "#                 close_end_trips_tensor_dict[tensor_key] = close_end_trips_tensor\n",
    "#                 close_end_trips_dict[tensor_key] = close_end_trips\n",
    "\n",
    "# all_close_start_trips_tensors = torch.cat(list(close_start_trips_tensor_dict.values()), dim=0)\n",
    "# all_close_end_trips_tensors = torch.cat(list(close_end_trips_tensor_dict.values()), dim=0)\n",
    "\n",
    "# for key, tensor in close_start_trips_tensor_dict.items():\n",
    "#     print(f\"Size of tensor for {key}: {tensor.size()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>link</th>\n",
       "      <th>from_node</th>\n",
       "      <th>to_node</th>\n",
       "      <th>length</th>\n",
       "      <th>freespeed</th>\n",
       "      <th>capacity</th>\n",
       "      <th>lanes</th>\n",
       "      <th>modes</th>\n",
       "      <th>vol_car</th>\n",
       "      <th>osm:way:vehicle</th>\n",
       "      <th>...</th>\n",
       "      <th>osm:way:psv</th>\n",
       "      <th>osm:way:service</th>\n",
       "      <th>osm:way:id</th>\n",
       "      <th>osm:way:access</th>\n",
       "      <th>osm:way:oneway</th>\n",
       "      <th>highway</th>\n",
       "      <th>osm:relation:route</th>\n",
       "      <th>geometry</th>\n",
       "      <th>district</th>\n",
       "      <th>district_centroid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100315</td>\n",
       "      <td>24972409</td>\n",
       "      <td>24972408</td>\n",
       "      <td>16.181257</td>\n",
       "      <td>8.333333</td>\n",
       "      <td>480.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>bus,car,car_passenger</td>\n",
       "      <td>6.627451</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4216830.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yes</td>\n",
       "      <td>residential</td>\n",
       "      <td>bicycle</td>\n",
       "      <td>LINESTRING (2.33869 48.85181, 2.33847 48.85181)</td>\n",
       "      <td>6.0</td>\n",
       "      <td>POINT (2.33290 48.84913)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100316</td>\n",
       "      <td>5904976363</td>\n",
       "      <td>24983651</td>\n",
       "      <td>14.860209</td>\n",
       "      <td>8.333333</td>\n",
       "      <td>480.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>bus,car,car_passenger,pt</td>\n",
       "      <td>9.607843</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4216831.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>bus</td>\n",
       "      <td>LINESTRING (2.33874 48.85242, 2.33872 48.85229)</td>\n",
       "      <td>6.0</td>\n",
       "      <td>POINT (2.33290 48.84913)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100317</td>\n",
       "      <td>24983651</td>\n",
       "      <td>5904976363</td>\n",
       "      <td>14.860209</td>\n",
       "      <td>8.333333</td>\n",
       "      <td>960.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>bus,car,car_passenger,pt</td>\n",
       "      <td>2.490196</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4216831.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>bus</td>\n",
       "      <td>LINESTRING (2.33872 48.85229, 2.33874 48.85242)</td>\n",
       "      <td>6.0</td>\n",
       "      <td>POINT (2.33290 48.84913)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100321</td>\n",
       "      <td>664205947</td>\n",
       "      <td>24972376</td>\n",
       "      <td>22.264540</td>\n",
       "      <td>8.333333</td>\n",
       "      <td>960.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>car,car_passenger</td>\n",
       "      <td>6.941176</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4216834.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yes</td>\n",
       "      <td>residential</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LINESTRING (2.33994 48.85200, 2.33986 48.85181)</td>\n",
       "      <td>6.0</td>\n",
       "      <td>POINT (2.33290 48.84913)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100324</td>\n",
       "      <td>24972376</td>\n",
       "      <td>24972375</td>\n",
       "      <td>64.853276</td>\n",
       "      <td>8.333333</td>\n",
       "      <td>480.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>bus,car,car_passenger</td>\n",
       "      <td>7.607843</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4216833.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yes</td>\n",
       "      <td>residential</td>\n",
       "      <td>bicycle</td>\n",
       "      <td>LINESTRING (2.33986 48.85181, 2.33909 48.85152)</td>\n",
       "      <td>6.0</td>\n",
       "      <td>POINT (2.33290 48.84913)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     link   from_node     to_node     length  freespeed  capacity  lanes  \\\n",
       "0  100315    24972409    24972408  16.181257   8.333333     480.0    1.0   \n",
       "1  100316  5904976363    24983651  14.860209   8.333333     480.0    1.0   \n",
       "2  100317    24983651  5904976363  14.860209   8.333333     960.0    2.0   \n",
       "3  100321   664205947    24972376  22.264540   8.333333     960.0    2.0   \n",
       "4  100324    24972376    24972375  64.853276   8.333333     480.0    1.0   \n",
       "\n",
       "                      modes   vol_car osm:way:vehicle  ... osm:way:psv  \\\n",
       "0     bus,car,car_passenger  6.627451             NaN  ...         NaN   \n",
       "1  bus,car,car_passenger,pt  9.607843             NaN  ...         NaN   \n",
       "2  bus,car,car_passenger,pt  2.490196             NaN  ...         NaN   \n",
       "3         car,car_passenger  6.941176             NaN  ...         NaN   \n",
       "4     bus,car,car_passenger  7.607843             NaN  ...         NaN   \n",
       "\n",
       "  osm:way:service osm:way:id osm:way:access  osm:way:oneway      highway  \\\n",
       "0             NaN  4216830.0            NaN             yes  residential   \n",
       "1             NaN  4216831.0            NaN             NaN     tertiary   \n",
       "2             NaN  4216831.0            NaN             NaN     tertiary   \n",
       "3             NaN  4216834.0            NaN             yes  residential   \n",
       "4             NaN  4216833.0            NaN             yes  residential   \n",
       "\n",
       "  osm:relation:route                                         geometry  \\\n",
       "0            bicycle  LINESTRING (2.33869 48.85181, 2.33847 48.85181)   \n",
       "1                bus  LINESTRING (2.33874 48.85242, 2.33872 48.85229)   \n",
       "2                bus  LINESTRING (2.33872 48.85229, 2.33874 48.85242)   \n",
       "3                NaN  LINESTRING (2.33994 48.85200, 2.33986 48.85181)   \n",
       "4            bicycle  LINESTRING (2.33986 48.85181, 2.33909 48.85152)   \n",
       "\n",
       "  district         district_centroid  \n",
       "0      6.0  POINT (2.33290 48.84913)  \n",
       "1      6.0  POINT (2.33290 48.84913)  \n",
       "2      6.0  POINT (2.33290 48.84913)  \n",
       "3      6.0  POINT (2.33290 48.84913)  \n",
       "4      6.0  POINT (2.33290 48.84913)  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "links_gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEAL WITH DISTRICTS\n",
    "\n",
    "# district centroids\n",
    "\n",
    "links_gdf['district_centroid'] = links_gdf['district_centroid'].fillna(Point(0, 0))\n",
    "valid_centroids = links_gdf['district_centroid'].dropna()\n",
    "\n",
    "centroid_distance = np.array([\n",
    "    [\n",
    "        geom.coords[0][0],  # x-coordinate\n",
    "        geom.coords[0][1]   # y-coordinate\n",
    "    ]\n",
    "    for geom in valid_centroids\n",
    "])\n",
    "district_centroids_tensor = torch.tensor(centroid_distance, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "District 1.0\n",
      "Total counts: 102\n",
      "Stacked distributions shape: [4, 16, 11, 12, 0, 17, 42]\n",
      "District 2.0\n",
      "Total counts: 130\n",
      "Stacked distributions shape: [11, 31, 20, 6, 4, 0, 58]\n",
      "District 3.0\n",
      "Total counts: 194\n",
      "Stacked distributions shape: [0, 82, 52, 13, 0, 6, 41]\n",
      "District 4.0\n",
      "Total counts: 209\n",
      "Stacked distributions shape: [22, 20, 59, 23, 0, 23, 62]\n",
      "District 5.0\n",
      "Total counts: 348\n",
      "Stacked distributions shape: [12, 90, 64, 57, 34, 23, 68]\n",
      "District 6.0\n",
      "Total counts: 327\n",
      "Stacked distributions shape: [11, 38, 45, 19, 0, 101, 113]\n",
      "District 7.0\n",
      "Total counts: 272\n",
      "Stacked distributions shape: [24, 55, 18, 21, 7, 49, 98]\n",
      "District 8.0\n",
      "Total counts: 191\n",
      "Stacked distributions shape: [9, 108, 15, 7, 0, 10, 42]\n",
      "District 9.0\n",
      "Total counts: 310\n",
      "Stacked distributions shape: [47, 122, 35, 10, 37, 21, 38]\n",
      "District 10.0\n",
      "Total counts: 502\n",
      "Stacked distributions shape: [8, 145, 79, 86, 12, 66, 106]\n",
      "District 11.0\n",
      "Total counts: 872\n",
      "Stacked distributions shape: [10, 309, 159, 98, 18, 76, 202]\n",
      "District 12.0\n",
      "Total counts: 710\n",
      "Stacked distributions shape: [15, 164, 110, 27, 19, 163, 212]\n",
      "District 13.0\n",
      "Total counts: 999\n",
      "Stacked distributions shape: [28, 217, 145, 142, 43, 102, 322]\n",
      "District 14.0\n",
      "Total counts: 737\n",
      "Stacked distributions shape: [2, 186, 87, 99, 14, 115, 234]\n",
      "District 15.0\n",
      "Total counts: 974\n",
      "Stacked distributions shape: [102, 361, 78, 49, 31, 129, 224]\n",
      "District 16.0\n",
      "Total counts: 881\n",
      "Stacked distributions shape: [11, 244, 78, 80, 32, 97, 339]\n",
      "District 17.0\n",
      "Total counts: 851\n",
      "Stacked distributions shape: [28, 306, 64, 71, 33, 121, 228]\n",
      "District 18.0\n",
      "Total counts: 1113\n",
      "Stacked distributions shape: [59, 348, 130, 83, 61, 151, 281]\n",
      "District 19.0\n",
      "Total counts: 861\n",
      "Stacked distributions shape: [42, 127, 102, 83, 68, 121, 318]\n",
      "District 20.0\n",
      "Total counts: 1029\n",
      "Stacked distributions shape: [2, 214, 102, 126, 84, 187, 314]\n"
     ]
    }
   ],
   "source": [
    "# Aggregate close_homes_count by district\n",
    "district_home_counts = links_gdf.groupby('district')['close_homes_count']\n",
    "\n",
    "district_2_home_counts = {}\n",
    "for district, count in district_home_counts:\n",
    "    total_counts = 0\n",
    "    total_distributions = []\n",
    "    for c in count:\n",
    "        total_counts += c[0]\n",
    "        if c[1] is not None and len(c[1]) > 0:\n",
    "            total_distributions.extend(c[1])\n",
    "\n",
    "    print(f\"District {district}\")\n",
    "    print(f\"Total counts: {total_counts}\")\n",
    "    distribution_counts = [total_distributions.count(i) for i in range(2, 9)]   \n",
    "    print(f\"Stacked distributions shape: {distribution_counts}\")\n",
    "    district_2_home_counts[district] = distribution_counts\n",
    "    \n",
    "district_home_counts_tensor = torch.zeros((len(links_gdf), len(distribution_counts)), dtype=torch.float)\n",
    "\n",
    "for idx, row in links_gdf.iterrows():\n",
    "    district = row['district']\n",
    "    if district in district_2_home_counts:\n",
    "        district_home_counts_tensor[idx] = torch.tensor(district_2_home_counts[district], dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows: 32367row [01:50, 293.45row/s]\n"
     ]
    }
   ],
   "source": [
    "# DEAL WITH HOMES\n",
    "\n",
    "close_homes_count_normal = compute_close_homes(links_gdf_input = links_gdf, information_gdf_input = persons_with_geospatial_information, utm_crs = utm_crs)\n",
    "links_gdf['close_homes_count'] = close_homes_count_normal\n",
    "close_homes_tensor = process_close_count_to_tensor(close_homes_count_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows: 31216row [00:56, 548.20row/s]\n",
      "Processing rows: 15400row [00:55, 275.36row/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m purpose, activities \u001b[38;5;129;01min\u001b[39;00m activities_by_purpose\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m      8\u001b[0m     close_activities_count_purpose \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclose_activities_count_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpurpose\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 9\u001b[0m     close_activity_count \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_close_homes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlinks_gdf_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlinks_gdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minformation_gdf_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mactivities\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mutm_crs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mutm_crs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m     links_gdf[close_activities_count_purpose] \u001b[38;5;241m=\u001b[39m close_activity_count\n\u001b[1;32m     11\u001b[0m     activities_by_purpose_tensor[purpose] \u001b[38;5;241m=\u001b[39m process_close_count_to_tensor(close_activity_count)\n",
      "Cell \u001b[0;32mIn[2], line 10\u001b[0m, in \u001b[0;36mcompute_close_homes\u001b[0;34m(links_gdf_input, information_gdf_input, utm_crs, distance)\u001b[0m\n\u001b[1;32m      8\u001b[0m buffer_utm \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mgeometry\u001b[38;5;241m.\u001b[39mbuffer(distance\u001b[38;5;241m=\u001b[39mdistance)\n\u001b[1;32m      9\u001b[0m buffer \u001b[38;5;241m=\u001b[39m gpd\u001b[38;5;241m.\u001b[39mGeoSeries([buffer_utm], crs\u001b[38;5;241m=\u001b[39mutm_crs)\u001b[38;5;241m.\u001b[39mto_crs(links_gdf_utm\u001b[38;5;241m.\u001b[39mcrs)[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m---> 10\u001b[0m matched_information \u001b[38;5;241m=\u001b[39m information_gdf_utm[\u001b[43minformation_gdf_utm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgeometry\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwithin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m]\n\u001b[1;32m     11\u001b[0m socioprofessional_classes \u001b[38;5;241m=\u001b[39m matched_information[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msocioprofessional_class\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m     12\u001b[0m close_places\u001b[38;5;241m.\u001b[39mappend((\u001b[38;5;28mlen\u001b[39m(socioprofessional_classes), socioprofessional_classes))\n",
      "File \u001b[0;32m~/anaconda3/envs/Paris_Analysis/lib/python3.10/site-packages/geopandas/base.py:1896\u001b[0m, in \u001b[0;36mGeoPandasBase.within\u001b[0;34m(self, other, align)\u001b[0m\n\u001b[1;32m   1784\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwithin\u001b[39m(\u001b[38;5;28mself\u001b[39m, other, align\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m   1785\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Returns a ``Series`` of ``dtype('bool')`` with value ``True`` for\u001b[39;00m\n\u001b[1;32m   1786\u001b[0m \u001b[38;5;124;03m    each aligned geometry that is within `other`.\u001b[39;00m\n\u001b[1;32m   1787\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1894\u001b[0m \u001b[38;5;124;03m    GeoSeries.contains\u001b[39;00m\n\u001b[1;32m   1895\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1896\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_binary_op\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwithin\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malign\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/Paris_Analysis/lib/python3.10/site-packages/geopandas/base.py:60\u001b[0m, in \u001b[0;36m_binary_op\u001b[0;34m(op, this, other, align, *args, **kwargs)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Binary operation on GeoSeries objects that returns a Series\"\"\"\u001b[39;00m\n\u001b[1;32m     59\u001b[0m data, index \u001b[38;5;241m=\u001b[39m _delegate_binary_method(op, this, other, align, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 60\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeries\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/Paris_Analysis/lib/python3.10/site-packages/pandas/core/series.py:443\u001b[0m, in \u001b[0;36mSeries.__init__\u001b[0;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[1;32m    441\u001b[0m manager \u001b[38;5;241m=\u001b[39m get_option(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.data_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    442\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m manager \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mblock\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 443\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mSingleBlockManager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    444\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m manager \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    445\u001b[0m     data \u001b[38;5;241m=\u001b[39m SingleArrayManager\u001b[38;5;241m.\u001b[39mfrom_array(data, index)\n",
      "File \u001b[0;32m~/anaconda3/envs/Paris_Analysis/lib/python3.10/site-packages/pandas/core/internals/managers.py:1574\u001b[0m, in \u001b[0;36mSingleBlockManager.from_array\u001b[0;34m(cls, array, index)\u001b[0m\n\u001b[1;32m   1569\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m   1570\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_array\u001b[39m(\u001b[38;5;28mcls\u001b[39m, array: ArrayLike, index: Index) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m SingleBlockManager:\n\u001b[1;32m   1571\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1572\u001b[0m \u001b[38;5;124;03m    Constructor for if we have an array that is not yet a Block.\u001b[39;00m\n\u001b[1;32m   1573\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1574\u001b[0m     block \u001b[38;5;241m=\u001b[39m \u001b[43mnew_block\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplacement\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mslice\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mndim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1575\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(block, index)\n",
      "File \u001b[0;32m~/anaconda3/envs/Paris_Analysis/lib/python3.10/site-packages/pandas/core/internals/blocks.py:1940\u001b[0m, in \u001b[0;36mnew_block\u001b[0;34m(values, placement, ndim, klass)\u001b[0m\n\u001b[1;32m   1937\u001b[0m check_ndim(values, placement, ndim)\n\u001b[1;32m   1939\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m klass \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1940\u001b[0m     klass \u001b[38;5;241m=\u001b[39m \u001b[43mget_block_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalues\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1942\u001b[0m values \u001b[38;5;241m=\u001b[39m maybe_coerce_values(values)\n\u001b[1;32m   1943\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m klass(values, ndim\u001b[38;5;241m=\u001b[39mndim, placement\u001b[38;5;241m=\u001b[39mplacement)\n",
      "File \u001b[0;32m~/anaconda3/envs/Paris_Analysis/lib/python3.10/site-packages/pandas/core/internals/blocks.py:1911\u001b[0m, in \u001b[0;36mget_block_type\u001b[0;34m(values, dtype)\u001b[0m\n\u001b[1;32m   1907\u001b[0m kind \u001b[38;5;241m=\u001b[39m dtype\u001b[38;5;241m.\u001b[39mkind\n\u001b[1;32m   1909\u001b[0m \u001b[38;5;28mcls\u001b[39m: \u001b[38;5;28mtype\u001b[39m[Block]\n\u001b[0;32m-> 1911\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mis_sparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1912\u001b[0m     \u001b[38;5;66;03m# Need this first(ish) so that Sparse[datetime] is sparse\u001b[39;00m\n\u001b[1;32m   1913\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m ExtensionBlock\n\u001b[1;32m   1914\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dtype, CategoricalDtype):\n",
      "File \u001b[0;32m~/anaconda3/envs/Paris_Analysis/lib/python3.10/site-packages/pandas/core/dtypes/common.py:232\u001b[0m, in \u001b[0;36mis_sparse\u001b[0;34m(arr)\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mis_sparse\u001b[39m(arr) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[1;32m    191\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;124;03m    Check whether an array-like is a 1-D pandas sparse array.\u001b[39;00m\n\u001b[1;32m    193\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[38;5;124;03m    Returns `False` if the parameter has more than one dimension.\u001b[39;00m\n\u001b[1;32m    231\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 232\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marrays\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msparse\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SparseDtype\n\u001b[1;32m    234\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(arr, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, arr)\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dtype, SparseDtype)\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1053\u001b[0m, in \u001b[0;36m_handle_fromlist\u001b[0;34m(module, fromlist, import_, recursive)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# DEAL WITH ACTIVITIES\n",
    "\n",
    "activities_with_socio = activities_gdf.merge(persons_with_geospatial_information[['household_id', 'socioprofessional_class']], on='household_id', how='left')\n",
    "grouped_activities = activities_with_socio.groupby('purpose')\n",
    "activities_by_purpose = {purpose: group.reset_index(drop=True) for purpose, group in grouped_activities}\n",
    "activities_by_purpose_tensor = {}\n",
    "for purpose, activities in activities_by_purpose.items():\n",
    "    close_activities_count_purpose = f\"close_activities_count_{purpose}\"\n",
    "    close_activity_count = compute_close_homes(links_gdf_input=links_gdf, information_gdf_input=activities, utm_crs=utm_crs)\n",
    "    links_gdf[close_activities_count_purpose] = close_activity_count\n",
    "    activities_by_purpose_tensor[purpose] = process_close_count_to_tensor(close_activity_count)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze results and plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pio.analyze_geodataframes(result_dic=result_dic, consider_only_highway_edges=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pio.analyze_geodataframes(result_dic=result_dic, consider_only_highway_edges=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing result_dic: 100%|██████████| 79/79 [00:08<00:00,  9.64dataframe/s]\n"
     ]
    }
   ],
   "source": [
    "def process_result_dic(result_dic, result_dic_mode_stats):\n",
    "    datalist = []\n",
    "    linegraph_transformation = LineGraph()\n",
    "    base_network_no_policies = result_dic.get(\"base_network_no_policies\")\n",
    "    vol_base_case = base_network_no_policies['vol_car'].values\n",
    "    capacity_base_case = base_network_no_policies['capacity'].values\n",
    "    length_base_case = base_network_no_policies['length'].values\n",
    "    freespeed_base_case = base_network_no_policies['freespeed'].values\n",
    "    modes_base_case = encode_modes(base_network_no_policies)\n",
    "    close_homes = close_homes_tensor.to_dense()\n",
    "    activities_home = activities_by_purpose_tensor['home'].to_dense()\n",
    "    activities_work = activities_by_purpose_tensor['work'].to_dense()\n",
    "    activities_education = activities_by_purpose_tensor['education'].to_dense()\n",
    "    activities_shop = activities_by_purpose_tensor['shop'].to_dense()\n",
    "    activities_leisure = activities_by_purpose_tensor['leisure'].to_dense()\n",
    "    activities_other = activities_by_purpose_tensor['other'].to_dense()\n",
    "    # close_start_trips_tensor = all_close_start_trips_tensors.to_dense()\n",
    "    # close_end_trips_tensor = all_close_end_trips_tensors.to_dense()\n",
    "    district_centroids = district_centroids_tensor.to_dense()\n",
    "    district_home_counts_tensor = district_home_counts_tensor.to_dense()\n",
    "    \n",
    "    # Initialize base edge positions\n",
    "    gdf_base = gpd.GeoDataFrame(base_network_no_policies, geometry='geometry')\n",
    "    gdf_base.crs = \"EPSG:2154\"  # Assuming the original CRS is EPSG:2154\n",
    "    gdf_base.to_crs(\"EPSG:4326\", inplace=True)\n",
    "    edge_positions_base = np.array([((geom.coords[0][0] + geom.coords[-1][0]) / 2, \n",
    "                                     (geom.coords[0][1] + geom.coords[-1][1]) / 2) \n",
    "                                    for geom in gdf_base.geometry])\n",
    "    \n",
    "    nodes = pd.concat([gdf_base['from_node'], gdf_base['to_node']]).unique()\n",
    "    node_to_idx = {node: idx for idx, node in enumerate(nodes)}\n",
    "    gdf_base['from_idx'] = gdf_base['from_node'].map(node_to_idx)\n",
    "    gdf_base['to_idx'] = gdf_base['to_node'].map(node_to_idx)\n",
    "    edges_base = gdf_base[['from_idx', 'to_idx']].values\n",
    "    edge_positions_tensor = torch.tensor(edge_positions_base, dtype=torch.float)\n",
    "    edge_index = torch.tensor(edges_base, dtype=torch.long).t().contiguous()\n",
    "    x = torch.zeros((len(nodes), 1), dtype=torch.float)\n",
    "    data = Data(edge_index=edge_index, x=x, pos=edge_positions_tensor)\n",
    "    linegraph_data = linegraph_transformation(data)\n",
    "\n",
    "    for key, df in tqdm(result_dic.items(), desc=\"Processing result_dic\", unit=\"dataframe\"):        \n",
    "        if isinstance(df, pd.DataFrame) and key != \"base_network_no_policies\":\n",
    "            gdf = gpd.GeoDataFrame(df, geometry='geometry')\n",
    "            gdf.crs = \"EPSG:2154\"  \n",
    "            gdf.to_crs(\"EPSG:4326\", inplace=True)\n",
    "            capacities_new = gdf['capacity'].values\n",
    "            capacity_reduction = capacities_new - capacity_base_case\n",
    "            highway = gdf['highway'].apply(lambda x: highway_mapping.get(x, -1)).values\n",
    "            length = gdf['length'].values\n",
    "            freespeed= gdf['freespeed'].values\n",
    "            modes = encode_modes(gdf)\n",
    "    \n",
    "            edge_car_volume_difference = gdf['vol_car'].values - vol_base_case\n",
    "            target_values = torch.tensor(edge_car_volume_difference, dtype=torch.float).unsqueeze(1)\n",
    "\n",
    "            linegraph_x = torch.tensor(np.column_stack((vol_base_case, capacity_base_case, capacities_new, capacity_reduction, \n",
    "                                                        highway, length, freespeed, length_base_case, freespeed_base_case, \n",
    "                                                        modes, modes_base_case, close_homes, \n",
    "                                                        activities_home, activities_work, activities_education, activities_shop, activities_leisure, activities_other,\n",
    "                                                        # close_start_trips_tensor, close_end_trips_tensor,\n",
    "                                                        district_centroids,\n",
    "                                                        district_home_counts_tensor)), dtype=torch.float)\n",
    "            \n",
    "            linegraph_data.x = linegraph_x\n",
    "            linegraph_data.y = target_values\n",
    "            \n",
    "            df_mode_stats = result_dic_mode_stats.get(key)\n",
    "            if df_mode_stats is not None:\n",
    "                numeric_cols = df_mode_stats.select_dtypes(include=[np.number]).columns\n",
    "                mode_stats_numeric = df_mode_stats[numeric_cols].astype(float)\n",
    "                mode_stats_tensor = torch.tensor(mode_stats_numeric.values, dtype=torch.float)\n",
    "                linegraph_data.mode_stats = mode_stats_tensor\n",
    "            if linegraph_data.validate(raise_on_error=True):\n",
    "                datalist.append(linegraph_data)\n",
    "            else:\n",
    "                print(\"Invalid line graph data\")\n",
    "    data_dict_list = [{'x': lg_data.x, 'edge_index': lg_data.edge_index, 'pos': lg_data.pos, 'y': lg_data.y, 'graph_attr': lg_data.mode_stats} for lg_data in datalist]\n",
    "    return data_dict_list\n",
    "\n",
    "data_processed = process_result_dic(result_dic=result_dic_output_links, result_dic_mode_stats=result_dic_mode_stats)\n",
    "torch.save(data_processed, result_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': tensor([[6.6275e+00, 4.8000e+02, 4.8000e+02,  ..., 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00],\n",
       "         [9.6078e+00, 4.8000e+02, 4.8000e+02,  ..., 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00],\n",
       "         [2.4902e+00, 9.6000e+02, 9.6000e+02,  ..., 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00],\n",
       "         ...,\n",
       "         [0.0000e+00, 7.9992e+03, 7.9992e+03,  ..., 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00],\n",
       "         [0.0000e+00, 7.9992e+03, 7.9992e+03,  ..., 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00],\n",
       "         [0.0000e+00, 7.9992e+03, 7.9992e+03,  ..., 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00]]),\n",
       " 'edge_index': tensor([[    0,     1,     1,  ..., 31138, 31139, 31139],\n",
       "         [   19, 10935, 10936,  ..., 30278, 31138, 31139]]),\n",
       " 'pos': tensor([[-1.3631, -5.9836],\n",
       "         [-1.3631, -5.9836],\n",
       "         [-1.3631, -5.9836],\n",
       "         ...,\n",
       "         [-1.3631, -5.9836],\n",
       "         [-1.3631, -5.9836],\n",
       "         [-1.3631, -5.9836]]),\n",
       " 'y': tensor([[ 1.3725],\n",
       "         [-0.6078],\n",
       "         [ 1.5098],\n",
       "         ...,\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000]]),\n",
       " 'graph_attr': tensor([[1.1676e+03, 3.6210e+03],\n",
       "         [1.2798e+03, 4.8323e+03],\n",
       "         [4.3310e+02, 4.3941e+03],\n",
       "         [7.8911e-01, 1.0581e+03],\n",
       "         [1.6101e+03, 5.4772e+03],\n",
       "         [1.0168e+03, 1.2207e+03]])}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_processed[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save for further processing with GNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_processed_single_districts = pio.process_result_dic(result_dic_single_districts)\n",
    "# torch.save(data_processed_single_districts, result_path + '_single_districts.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(data_processed, result_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.scatter(persons_with_homes.geometry.x, persons_with_homes.geometry.y, s=1, color='blue', alpha=0.5)\n",
    "# plt.scatter(persons_with_home_within_linear_ring.geometry.x, persons_with_home_within_linear_ring.geometry.y, s=1, color='red', alpha=0.5)\n",
    "# plt.title('Locations of Persons with Homes')\n",
    "# plt.xlabel('Longitude')\n",
    "# plt.ylabel('Latitude')\n",
    "# plt.show()\n",
    "\n",
    "# from shapely.geometry import LineString\n",
    "# from shapely.geometry import MultiPolygon\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Create a LineString\n",
    "# line = LineString([(10, 10), (20, 10)])\n",
    "\n",
    "# # Create a buffer around the line\n",
    "# buffered_line = line.buffer(2, cap_style=\"round\")\n",
    "\n",
    "# # Plot the original line and the buffered area\n",
    "# plt.figure(figsize=(8, 6))\n",
    "# x, y = line.xy\n",
    "# plt.plot(x, y, color='blue', label='Original Line')\n",
    "# if isinstance(buffered_line, MultiPolygon):\n",
    "#     for polygon in buffered_line:\n",
    "#         x, y = polygon.exterior.xy\n",
    "#         plt.fill(x, y, alpha=0.5, color='lightblue', label='Buffered Area')\n",
    "# else:\n",
    "#     x, y = buffered_line.exterior.xy\n",
    "#     plt.fill(x, y, alpha=0.5, color='lightblue', label='Buffered Area')\n",
    "\n",
    "# plt.title('Line with Buffered Area')\n",
    "# plt.xlabel('X-axis')\n",
    "# plt.ylabel('Y-axis')\n",
    "# plt.legend()\n",
    "# plt.grid()\n",
    "# plt.axis('equal')\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "# def check_trips_equivalence(close_trips_start, close_trips_end):\n",
    "#     \"\"\"\n",
    "#     Check if close_trips_start and close_trips_end are equivalent.\n",
    "    \n",
    "#     Args:\n",
    "#     close_trips_start (list): List of tuples for start trips\n",
    "#     close_trips_end (list): List of tuples for end trips\n",
    "    \n",
    "#     Returns:\n",
    "#     bool: True if equivalent, False otherwise\n",
    "#     \"\"\"\n",
    "#     if len(close_trips_start) != len(close_trips_end):\n",
    "#         print(\"Lists have different lengths.\")\n",
    "#         return False\n",
    "    \n",
    "#     differences = []\n",
    "#     for i, (start, end) in enumerate(zip(close_trips_start, close_trips_end)):\n",
    "#         if start != end:\n",
    "#             differences.append((i, start, end))\n",
    "    \n",
    "#     if not differences:\n",
    "#         print(\"The lists are identical.\")\n",
    "#         return True\n",
    "#     else:\n",
    "#         print(f\"Found {len(differences)} differences:\")\n",
    "#         for diff in differences[:10]:  # Print first 10 differences\n",
    "#             print(f\"Index {diff[0]}: Start {diff[1]}, End {diff[2]}\")\n",
    "#         if len(differences) > 10:\n",
    "#             print(f\"... and {len(differences) - 10} more differences.\")\n",
    "#         return False\n",
    "\n",
    "# # Usage\n",
    "# are_equivalent = check_trips_equivalence(close_trips_start, close_trips_end)\n",
    "# print(f\"Are the trip lists equivalent? {are_equivalent}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Paris_Analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
