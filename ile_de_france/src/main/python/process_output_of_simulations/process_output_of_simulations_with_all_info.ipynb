{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import glob\n",
    "import math\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import torch\n",
    "\n",
    "import processing_io as pio\n",
    "from torch_geometric.transforms import LineGraph\n",
    "\n",
    "from torch_geometric.data import Data, Batch\n",
    "import shapely.wkt as wkt\n",
    "from tqdm import tqdm\n",
    "import fiona\n",
    "import os\n",
    "\n",
    "import alphashape\n",
    "from shapely.geometry import Polygon\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "\n",
    "highway_mapping = {\n",
    "    'trunk': 0, 'trunk_link': 0, 'motorway_link': 0,\n",
    "    'primary': 1, 'primary_link': 1,\n",
    "    'secondary': 2, 'secondary_link': 2,\n",
    "    'tertiary': 3, 'tertiary_link': 3,\n",
    "    'residential': 4, 'living_street': 5,\n",
    "    'pedestrian': 6, 'service': 7,\n",
    "    'construction': 8, 'unclassified': 9,\n",
    "    'np.nan': -1\n",
    "}\n",
    "result_df_name = 'sim_output_1pm_capacity_reduction_10k_PRELIMINARY'\n",
    "result_path = '../../../../data/datasets_simulation_outputs/' + result_df_name + '.pt'\n",
    "string_is_for_1pm = \"pop_1pm\"\n",
    "\n",
    "base_dir_sample_sim_input = '../../../../data/' + string_is_for_1pm + '_simulations/' + string_is_for_1pm + '_policies_combinations_with_normal_dist/'\n",
    "subdirs_pattern = os.path.join(base_dir_sample_sim_input, 'output_networks_*')\n",
    "subdirs = list(set(glob.glob(subdirs_pattern)))\n",
    "subdirs.sort()\n",
    "\n",
    "paris_inside_bvd_peripherique = \"../../../../data/paris_inside_bvd_per/referentiel-comptages-edit.shp\"\n",
    "gdf_paris_inside_bvd_per = gpd.read_file(paris_inside_bvd_peripherique)\n",
    "boundary_df = alphashape.alphashape(gdf_paris_inside_bvd_per, 435).exterior[0]\n",
    "linear_ring_polygon = Polygon(boundary_df)\n",
    "\n",
    "gdf_basecase_output_links = gpd.read_file('results/' + string_is_for_1pm + '_basecase_average_output_links.geojson')\n",
    "gdf_basecase_average_mode_stats = pd.read_csv('results/' + string_is_for_1pm + '_basecase_average_mode_stats.csv', delimiter=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abstract\n",
    "\n",
    "This is further than process_output_of_simulations_with_all_output_links_and_eqasim_info.ipynb, as it also includes more input information."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process results\n",
    "\n",
    "Process the outputs of the simulations for further usage by GNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing subdirs:   0%|          | 0/70 [00:16<?, ?subdir/s]\n",
      "Processing subdirs:   0%|          | 0/70 [00:01<?, ?subdir/s]\n"
     ]
    }
   ],
   "source": [
    "def compute_close_homes(links_gdf_input:pd.DataFrame, information_gdf_input:pd.DataFrame, utm_crs:str, distance:int=50):\n",
    "    links_gdf = links_gdf_input.copy()\n",
    "    information_gdf = information_gdf_input.copy()\n",
    "    close_places = []\n",
    "    links_gdf_utm = links_gdf.to_crs(utm_crs)\n",
    "    information_gdf_utm = information_gdf.to_crs(utm_crs)\n",
    "    for i, row in tqdm(enumerate(links_gdf_utm.iterrows()), desc=\"Processing rows\", unit=\"row\"):\n",
    "        buffer_utm = row[1].geometry.buffer(distance=distance)\n",
    "        buffer = gpd.GeoSeries([buffer_utm], crs=utm_crs).to_crs(links_gdf_utm.crs)[0]\n",
    "        matched_information = information_gdf_utm[information_gdf_utm.geometry.within(buffer)]\n",
    "        socioprofessional_classes = matched_information['socioprofessional_class'].tolist()\n",
    "        close_places.append((len(socioprofessional_classes), socioprofessional_classes))\n",
    "    return close_places\n",
    "\n",
    "def process_close_count_to_tensor(close_count_list:list):\n",
    "    socio_professional_classes = [item[1] for item in close_count_list]\n",
    "    unique_classes = set([cls for sublist in socio_professional_classes for cls in sublist])\n",
    "    class_to_index = {cls: idx for idx, cls in enumerate(unique_classes)}\n",
    "\n",
    "    tensor_shape = (len(close_count_list), len(unique_classes))\n",
    "    close_homes_tensor = torch.zeros(tensor_shape)\n",
    "\n",
    "    for i, classes in enumerate(socio_professional_classes):\n",
    "        for cls in classes:\n",
    "            close_homes_tensor[i, class_to_index[cls]] += 1\n",
    "    \n",
    "    close_homes_tensor_sparse = close_homes_tensor.to_sparse()\n",
    "    return close_homes_tensor_sparse\n",
    "\n",
    "# Read all network data into a dictionary of GeoDataFrames\n",
    "def compute_result_dic_output_links():\n",
    "    result_dic = {}\n",
    "    base_network_no_policies = gdf_basecase_output_links\n",
    "    result_dic[\"base_network_no_policies\"] = base_network_no_policies\n",
    "    for subdir in tqdm(subdirs, desc=\"Processing subdirs\", unit=\"subdir\"):\n",
    "        # print(f'Accessing folder: {subdir}')\n",
    "        # print(len(os.listdir(subdir)))\n",
    "        networks = [network for network in os.listdir(subdir) if not network.endswith(\".DS_Store\")]\n",
    "        for network in networks:\n",
    "            file_path = os.path.join(subdir, network)\n",
    "            policy_key = pio.create_policy_key_1pm(network)\n",
    "            gdf_output_links = pio.read_output_links(file_path)\n",
    "            if (gdf_output_links is not None):\n",
    "                gdf_extended = pio.extend_geodataframe(gdf_base=gdf_basecase_output_links, gdf_to_extend=gdf_output_links, column_to_extend='highway', new_column_name='highway')\n",
    "                gdf_extended = pio.extend_geodataframe(gdf_base=gdf_basecase_output_links, gdf_to_extend=gdf_extended, column_to_extend='vol_car', new_column_name='vol_car_base_case')\n",
    "                result_dic[policy_key] = gdf_extended\n",
    "        break\n",
    "    return result_dic\n",
    "\n",
    "def calculate_averaged_results(trips_df):\n",
    "    \"\"\"Calculate average travel time and routed distance grouped by mode.\"\"\"\n",
    "    return trips_df.groupby('mode').agg(\n",
    "        total_travel_time=('travel_time', 'mean'),\n",
    "        total_routed_distance=('routed_distance', 'mean')\n",
    "    ).reset_index()\n",
    "\n",
    "def compute_result_dic_mode_stats(calculate_averaged_results):\n",
    "    result_dic_mode_stats = {}\n",
    "    result_dic_mode_stats[\"base_network_no_policies\"] = gdf_basecase_average_mode_stats\n",
    "    for subdir in tqdm(subdirs, desc=\"Processing subdirs\", unit=\"subdir\"):\n",
    "        networks = [network for network in os.listdir(subdir) if not network.endswith(\".DS_Store\")]\n",
    "        for network in networks:\n",
    "            file_path = os.path.join(subdir, network)\n",
    "            policy_key = pio.create_policy_key_1pm(network)\n",
    "            df_mode_stats = pd.read_csv(file_path + '/eqasim_trips.csv', delimiter=';')\n",
    "            averaged_results = calculate_averaged_results(df_mode_stats)\n",
    "            if (averaged_results is not None):\n",
    "                result_dic_mode_stats[policy_key] = averaged_results\n",
    "        break\n",
    "    return result_dic_mode_stats\n",
    "\n",
    "def encode_modes(gdf):\n",
    "    \"\"\"Encode the 'modes' attribute based on specific strings.\"\"\"\n",
    "    modes_conditions = {\n",
    "        'car': gdf['modes'].str.contains('car', case=False, na=False).astype(int),\n",
    "        'bus': gdf['modes'].str.contains('bus', case=False, na=False).astype(int),\n",
    "        'pt': gdf['modes'].str.contains('pt', case=False, na=False).astype(int),\n",
    "        'train': gdf['modes'].str.contains('train', case=False, na=False).astype(int),\n",
    "        'rail': gdf['modes'].str.contains('rail', case=False, na=False).astype(int),\n",
    "        'subway': gdf['modes'].str.contains('subway', case=False, na=False).astype(int)\n",
    "    }\n",
    "    modes_encoded = pd.DataFrame(modes_conditions)\n",
    "    return torch.tensor(modes_encoded.values, dtype=torch.float)\n",
    "\n",
    "result_dic_output_links = compute_result_dic_output_links()\n",
    "result_dic_mode_stats = compute_result_dic_mode_stats(calculate_averaged_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded CSV file: idf_1pm_persons.csv into variable: persons_df\n",
      "Loaded GPKG file: idf_1pm_commutes.gpkg into variable: commutes_gdf\n",
      "Loaded CSV file: idf_1pm_households.csv into variable: households_df\n",
      "Loaded CSV file: idf_1pm_trips.csv into variable: trips_df\n",
      "Loaded CSV file: idf_1pm_activities.csv into variable: activities_df\n",
      "Loaded CSV file: idf_1pm_vehicle_types.csv into variable: vehicle_types_df\n",
      "Loaded GPKG file: idf_1pm_trips.gpkg into variable: trips_gdf\n",
      "Loaded GPKG file: idf_1pm_activities.gpkg into variable: activities_gdf\n",
      "Loaded CSV file: idf_1pm_vehicles.csv into variable: vehicles_df\n",
      "Loaded GPKG file: idf_1pm_homes.gpkg into variable: homes_gdf\n"
     ]
    }
   ],
   "source": [
    "base_dir_sample_sim_input = '../../../../data/pop_1pm_simulations/idf_1pm/' \n",
    "files = os.listdir(base_dir_sample_sim_input)\n",
    "\n",
    "for file in files:\n",
    "    file_path = os.path.join(base_dir_sample_sim_input, file)\n",
    "    base_name, ext = os.path.splitext(file)\n",
    "    if base_name.startswith(\"idf_1pm_\"):\n",
    "        base_name = base_name.replace(\"idf_1pm_\", \"\")\n",
    "    var_name = base_name  # Start with the cleaned base name\n",
    "    \n",
    "    if file.endswith('.csv'):\n",
    "        try:\n",
    "            var_name = f\"{var_name}_df\"  \n",
    "            globals()[var_name] = pd.read_csv(file_path, sep=\";\")\n",
    "            print(f\"Loaded CSV file: {file} into variable: {var_name}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading CSV file {file}: {e}\")\n",
    "            \n",
    "    elif file.endswith('.gpkg'):\n",
    "        try:\n",
    "            var_name = f\"{var_name}_gdf\"  \n",
    "            layers = fiona.listlayers(file_path)\n",
    "            geodataframes = {layer: gpd.read_file(file_path, layer=layer, geometry = 'geometry', crs=\"EPSG:2154\") for layer in layers}\n",
    "            for layer, gdf in geodataframes.items():\n",
    "                # print(f\"Layer: {layer}\")\n",
    "                gdf = gdf.to_crs(epsg=4326)\n",
    "                globals()[var_name] = gdf\n",
    "                print(f\"Loaded GPKG file: {file} into variable: {var_name}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading CSV file {file}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_gdf = result_dic_output_links[\"base_network_no_policies\"]\n",
    "links_gdf = gpd.GeoDataFrame(base_gdf, geometry='geometry')\n",
    "links_gdf.crs = \"EPSG:2154\"  # Assuming the original CRS is EPSG:2154\n",
    "links_gdf.to_crs(\"EPSG:4326\", inplace=True)\n",
    "\n",
    "homes_gdf = globals()[\"homes_gdf\"]\n",
    "households_df = globals()[\"households_df\"]\n",
    "population_df = pd.read_csv(\"intermediate_results/population.csv\")\n",
    "persons_df = globals()[\"persons_df\"]\n",
    "activities_gdf = globals()[\"activities_gdf\"]\n",
    "trips_df = globals()[\"trips_gdf\"]\n",
    "\n",
    "sorted_population_df = population_df.sort_values(by=\"id\")\n",
    "sorted_persons_df = persons_df.sort_values(by=\"person_id\")\n",
    "merged_df = pd.merge(sorted_persons_df, sorted_population_df, left_on=\"person_id\", right_on=\"id\")\n",
    "removed_some_columns = merged_df.copy()\n",
    "removed_some_columns = removed_some_columns.drop(columns=['employed_y', 'hasPtSubscription', 'householdId', 'sex_y', 'htsPersonId', 'censusPersonId', 'hasLicense', 'id', 'age_y'])\n",
    "updated_persons = removed_some_columns.copy()\n",
    "persons_with_geospatial_information = homes_gdf.merge(updated_persons, on='household_id', how='right')\n",
    "\n",
    "if not isinstance(persons_with_geospatial_information, gpd.GeoDataFrame):\n",
    "    persons_with_geospatial_information = gpd.GeoDataFrame(persons_with_geospatial_information, geometry=gpd.points_from_xy(persons_with_geospatial_information.longitude, persons_with_geospatial_information.latitude), crs= links_gdf.crs)\n",
    "\n",
    "utm_crs = 'EPSG:32631'  # UTM zone 31N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_start_end_points(geometry):\n",
    "    if len(geometry.coords) != 2:\n",
    "        raise ValueError(\"Linestring does not have exactly 2 elements.\")\n",
    "    return geometry.coords[0], geometry.coords[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows: 31216row [01:46, 292.62row/s]\n",
      "Processing rows: 31216row [01:17, 403.78row/s]\n"
     ]
    }
   ],
   "source": [
    "# DEAL WITH TRIPS\n",
    "\n",
    "def get_close_trips_tensor(links_gdf_input, trips_gdf_input, utm_crs):\n",
    "    close_trips_count = compute_close_homes(links_gdf_input = links_gdf_input, information_gdf_input = trips_gdf_input, utm_crs = utm_crs, distance=50)\n",
    "    close_trips_count_tensor = process_close_count_to_tensor(close_trips_count)\n",
    "    return close_trips_count, close_trips_count_tensor\n",
    "\n",
    "trips_with_socio = trips_df.merge(persons_with_geospatial_information[['person_id', 'socioprofessional_class']], on='person_id', how='left')\n",
    "trips_with_socio['start_point'] = trips_with_socio['geometry'].apply(lambda geom: extract_start_end_points(geom)[0])\n",
    "trips_with_socio['end_point'] = trips_with_socio['geometry'].apply(lambda geom: extract_start_end_points(geom)[1])\n",
    "\n",
    "trips_start = trips_with_socio.copy()\n",
    "trips_start_gdf = gpd.GeoDataFrame(\n",
    "    trips_start, \n",
    "    geometry=gpd.points_from_xy(\n",
    "        trips_start['start_point'].apply(lambda p: p[0]), \n",
    "        trips_start['start_point'].apply(lambda p: p[1])\n",
    "    ), \n",
    "    crs=links_gdf.crs\n",
    ")\n",
    "\n",
    "trips_end = trips_with_socio.copy()\n",
    "trips_end_gdf = gpd.GeoDataFrame(\n",
    "    trips_end, \n",
    "    geometry=gpd.points_from_xy(\n",
    "        trips_end['end_point'].apply(lambda p: p[0]), \n",
    "        trips_end['end_point'].apply(lambda p: p[1])\n",
    "    ), \n",
    "    crs=links_gdf.crs\n",
    ")\n",
    "\n",
    "close_trips_start, close_start_trips_tensor = get_close_trips_tensor(links_gdf_input=links_gdf, trips_gdf_input=trips_start_gdf, utm_crs=utm_crs)\n",
    "close_trips_end, close_end_trips_tensor = get_close_trips_tensor(links_gdf_input=links_gdf, trips_gdf_input=trips_end_gdf, utm_crs=utm_crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 662 differences:\n",
      "Index 221: Start (2, [3, 2]), End (1, [2])\n",
      "Index 223: Start (0, []), End (1, [3])\n",
      "Index 351: Start (1, [4]), End (0, [])\n",
      "Index 514: Start (4, [4, 5, 5, 7]), End (3, [4, 5, 7])\n",
      "Index 515: Start (3, [4, 5, 5]), End (2, [4, 5])\n",
      "Index 544: Start (4, [3, 3, 3, 5]), End (5, [8, 3, 3, 3, 5])\n",
      "Index 586: Start (9, [4, 4, 2, 8, 8, 8, 8, 5, 4]), End (10, [4, 4, 8, 2, 8, 8, 8, 8, 5, 4])\n",
      "Index 587: Start (8, [3, 2, 8, 8, 8, 8, 4, 4]), End (9, [3, 8, 2, 8, 8, 8, 8, 4, 4])\n",
      "Index 625: Start (2, [5, 4]), End (3, [5, 4, 8])\n",
      "Index 687: Start (0, []), End (1, [5])\n",
      "... and 652 more differences.\n",
      "Are the trip lists equivalent? False\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows: 11695row [00:24, 482.12row/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# DEAL WITH HOMES\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m close_homes_count_normal \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_close_homes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlinks_gdf_input\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlinks_gdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minformation_gdf_input\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mpersons_with_geospatial_information\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mutm_crs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mutm_crs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m links_gdf[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclose_homes_count\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m close_homes_count_normal\n\u001b[1;32m      5\u001b[0m close_homes_tensor \u001b[38;5;241m=\u001b[39m process_close_count_to_tensor(close_homes_count_normal)\n",
      "Cell \u001b[0;32mIn[2], line 10\u001b[0m, in \u001b[0;36mcompute_close_homes\u001b[0;34m(links_gdf_input, information_gdf_input, utm_crs, distance)\u001b[0m\n\u001b[1;32m      8\u001b[0m buffer_utm \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mgeometry\u001b[38;5;241m.\u001b[39mbuffer(distance\u001b[38;5;241m=\u001b[39mdistance)\n\u001b[1;32m      9\u001b[0m buffer \u001b[38;5;241m=\u001b[39m gpd\u001b[38;5;241m.\u001b[39mGeoSeries([buffer_utm], crs\u001b[38;5;241m=\u001b[39mutm_crs)\u001b[38;5;241m.\u001b[39mto_crs(links_gdf_utm\u001b[38;5;241m.\u001b[39mcrs)[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m---> 10\u001b[0m matched_information \u001b[38;5;241m=\u001b[39m information_gdf_utm[\u001b[43minformation_gdf_utm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgeometry\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwithin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m]\n\u001b[1;32m     11\u001b[0m socioprofessional_classes \u001b[38;5;241m=\u001b[39m matched_information[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msocioprofessional_class\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m     12\u001b[0m close_places\u001b[38;5;241m.\u001b[39mappend((\u001b[38;5;28mlen\u001b[39m(socioprofessional_classes), socioprofessional_classes))\n",
      "File \u001b[0;32m~/anaconda3/envs/Paris_Analysis/lib/python3.10/site-packages/geopandas/base.py:1896\u001b[0m, in \u001b[0;36mGeoPandasBase.within\u001b[0;34m(self, other, align)\u001b[0m\n\u001b[1;32m   1784\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwithin\u001b[39m(\u001b[38;5;28mself\u001b[39m, other, align\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m   1785\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Returns a ``Series`` of ``dtype('bool')`` with value ``True`` for\u001b[39;00m\n\u001b[1;32m   1786\u001b[0m \u001b[38;5;124;03m    each aligned geometry that is within `other`.\u001b[39;00m\n\u001b[1;32m   1787\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1894\u001b[0m \u001b[38;5;124;03m    GeoSeries.contains\u001b[39;00m\n\u001b[1;32m   1895\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1896\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_binary_op\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwithin\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malign\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/Paris_Analysis/lib/python3.10/site-packages/geopandas/base.py:59\u001b[0m, in \u001b[0;36m_binary_op\u001b[0;34m(op, this, other, align, *args, **kwargs)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_binary_op\u001b[39m(op, this, other, align, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;66;03m# type: (str, GeoSeries, GeoSeries, args/kwargs) -> Series[bool/float]\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Binary operation on GeoSeries objects that returns a Series\"\"\"\u001b[39;00m\n\u001b[0;32m---> 59\u001b[0m     data, index \u001b[38;5;241m=\u001b[39m \u001b[43m_delegate_binary_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malign\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Series(data, index\u001b[38;5;241m=\u001b[39mindex)\n",
      "File \u001b[0;32m~/anaconda3/envs/Paris_Analysis/lib/python3.10/site-packages/geopandas/base.py:43\u001b[0m, in \u001b[0;36m_delegate_binary_method\u001b[0;34m(op, this, other, align, *args, **kwargs)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;28mtype\u001b[39m(this), \u001b[38;5;28mtype\u001b[39m(other))\n\u001b[0;32m---> 43\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43ma_this\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data, this\u001b[38;5;241m.\u001b[39mindex\n",
      "File \u001b[0;32m~/anaconda3/envs/Paris_Analysis/lib/python3.10/site-packages/geopandas/array.py:596\u001b[0m, in \u001b[0;36mGeometryArray.within\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    595\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwithin\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[0;32m--> 596\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_binary_method\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwithin\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/Paris_Analysis/lib/python3.10/site-packages/geopandas/array.py:566\u001b[0m, in \u001b[0;36mGeometryArray._binary_method\u001b[0;34m(op, left, right, **kwargs)\u001b[0m\n\u001b[1;32m    563\u001b[0m         _crs_mismatch_warn(left, right, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m7\u001b[39m)\n\u001b[1;32m    564\u001b[0m     right \u001b[38;5;241m=\u001b[39m right\u001b[38;5;241m.\u001b[39m_data\n\u001b[0;32m--> 566\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mvectorized\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mleft\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/Paris_Analysis/lib/python3.10/site-packages/geopandas/_vectorized.py:793\u001b[0m, in \u001b[0;36mwithin\u001b[0;34m(data, other)\u001b[0m\n\u001b[1;32m    791\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwithin\u001b[39m(data, other):\n\u001b[1;32m    792\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m compat\u001b[38;5;241m.\u001b[39mUSE_SHAPELY_20:\n\u001b[0;32m--> 793\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mshapely\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwithin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    794\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m compat\u001b[38;5;241m.\u001b[39mUSE_PYGEOS:\n\u001b[1;32m    795\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _binary_method(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwithin\u001b[39m\u001b[38;5;124m\"\u001b[39m, data, other)\n",
      "File \u001b[0;32m~/anaconda3/envs/Paris_Analysis/lib/python3.10/site-packages/shapely/decorators.py:77\u001b[0m, in \u001b[0;36mmultithreading_enabled.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m arr \u001b[38;5;129;01min\u001b[39;00m array_args:\n\u001b[1;32m     76\u001b[0m         arr\u001b[38;5;241m.\u001b[39mflags\u001b[38;5;241m.\u001b[39mwriteable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m---> 77\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m arr, old_flag \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(array_args, old_flags):\n",
      "File \u001b[0;32m~/anaconda3/envs/Paris_Analysis/lib/python3.10/site-packages/shapely/predicates.py:946\u001b[0m, in \u001b[0;36mwithin\u001b[0;34m(a, b, **kwargs)\u001b[0m\n\u001b[1;32m    897\u001b[0m \u001b[38;5;129m@multithreading_enabled\u001b[39m\n\u001b[1;32m    898\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwithin\u001b[39m(a, b, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    899\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Returns True if geometry A is completely inside geometry B.\u001b[39;00m\n\u001b[1;32m    900\u001b[0m \n\u001b[1;32m    901\u001b[0m \u001b[38;5;124;03m    A is within B if no points of A lie in the exterior of B and at least one\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    944\u001b[0m \u001b[38;5;124;03m    False\u001b[39;00m\n\u001b[1;32m    945\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 946\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwithin\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# DEAL WITH HOMES\n",
    "\n",
    "close_homes_count_normal = compute_close_homes(links_gdf_input = links_gdf, information_gdf_input = persons_with_geospatial_information, utm_crs = utm_crs)\n",
    "links_gdf['close_homes_count'] = close_homes_count_normal\n",
    "close_homes_tensor = process_close_count_to_tensor(close_homes_count_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows: 31216row [01:02, 497.98row/s]\n",
      "Processing rows: 91row [00:00, 254.45row/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m purpose, activities \u001b[38;5;129;01min\u001b[39;00m activities_by_purpose\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m      8\u001b[0m     close_activities_count_purpose \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclose_activities_count_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpurpose\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 9\u001b[0m     close_activity_count \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_close_homes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlinks_gdf_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlinks_gdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minformation_gdf_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mactivities\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mutm_crs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mutm_crs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m     links_gdf[close_activities_count_purpose] \u001b[38;5;241m=\u001b[39m close_activity_count\n\u001b[1;32m     11\u001b[0m     activities_by_purpose_tensor[purpose] \u001b[38;5;241m=\u001b[39m process_close_count_to_tensor(close_activity_count)\n",
      "Cell \u001b[0;32mIn[2], line 10\u001b[0m, in \u001b[0;36mcompute_close_homes\u001b[0;34m(links_gdf_input, information_gdf_input, utm_crs, distance)\u001b[0m\n\u001b[1;32m      8\u001b[0m buffer_utm \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mgeometry\u001b[38;5;241m.\u001b[39mbuffer(distance\u001b[38;5;241m=\u001b[39mdistance)\n\u001b[1;32m      9\u001b[0m buffer \u001b[38;5;241m=\u001b[39m gpd\u001b[38;5;241m.\u001b[39mGeoSeries([buffer_utm], crs\u001b[38;5;241m=\u001b[39mutm_crs)\u001b[38;5;241m.\u001b[39mto_crs(links_gdf_utm\u001b[38;5;241m.\u001b[39mcrs)[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m---> 10\u001b[0m matched_information \u001b[38;5;241m=\u001b[39m \u001b[43minformation_gdf_utm\u001b[49m\u001b[43m[\u001b[49m\u001b[43minformation_gdf_utm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgeometry\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwithin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     11\u001b[0m socioprofessional_classes \u001b[38;5;241m=\u001b[39m matched_information[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msocioprofessional_class\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m     12\u001b[0m close_places\u001b[38;5;241m.\u001b[39mappend((\u001b[38;5;28mlen\u001b[39m(socioprofessional_classes), socioprofessional_classes))\n",
      "File \u001b[0;32m~/anaconda3/envs/Paris_Analysis/lib/python3.10/site-packages/geopandas/geodataframe.py:1475\u001b[0m, in \u001b[0;36mGeoDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1469\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):\n\u001b[1;32m   1470\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1471\u001b[0m \u001b[38;5;124;03m    If the result is a column containing only 'geometry', return a\u001b[39;00m\n\u001b[1;32m   1472\u001b[0m \u001b[38;5;124;03m    GeoSeries. If it's a DataFrame with any columns of GeometryDtype,\u001b[39;00m\n\u001b[1;32m   1473\u001b[0m \u001b[38;5;124;03m    return a GeoDataFrame.\u001b[39;00m\n\u001b[1;32m   1474\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1475\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getitem__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1476\u001b[0m     \u001b[38;5;66;03m# Custom logic to avoid waiting for pandas GH51895\u001b[39;00m\n\u001b[1;32m   1477\u001b[0m     \u001b[38;5;66;03m# result is not geometry dtype for multi-indexes\u001b[39;00m\n\u001b[1;32m   1478\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   1479\u001b[0m         pd\u001b[38;5;241m.\u001b[39mapi\u001b[38;5;241m.\u001b[39mtypes\u001b[38;5;241m.\u001b[39mis_scalar(key)\n\u001b[1;32m   1480\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m key \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1483\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_geometry_type(result)\n\u001b[1;32m   1484\u001b[0m     ):\n",
      "File \u001b[0;32m~/anaconda3/envs/Paris_Analysis/lib/python3.10/site-packages/pandas/core/frame.py:3449\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3447\u001b[0m \u001b[38;5;66;03m# Do we have a (boolean) 1d indexer?\u001b[39;00m\n\u001b[1;32m   3448\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m com\u001b[38;5;241m.\u001b[39mis_bool_indexer(key):\n\u001b[0;32m-> 3449\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_bool_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3451\u001b[0m \u001b[38;5;66;03m# We are left with two options: a single key, and a collection of keys,\u001b[39;00m\n\u001b[1;32m   3452\u001b[0m \u001b[38;5;66;03m# We interpret tuples as collections only for non-MultiIndex\u001b[39;00m\n\u001b[1;32m   3453\u001b[0m is_single_key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_list_like(key)\n",
      "File \u001b[0;32m~/anaconda3/envs/Paris_Analysis/lib/python3.10/site-packages/pandas/core/frame.py:3504\u001b[0m, in \u001b[0;36mDataFrame._getitem_bool_array\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3502\u001b[0m key \u001b[38;5;241m=\u001b[39m check_bool_indexer(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex, key)\n\u001b[1;32m   3503\u001b[0m indexer \u001b[38;5;241m=\u001b[39m key\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m-> 3504\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_take_with_is_copy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/Paris_Analysis/lib/python3.10/site-packages/pandas/core/generic.py:3628\u001b[0m, in \u001b[0;36mNDFrame._take_with_is_copy\u001b[0;34m(self, indices, axis)\u001b[0m\n\u001b[1;32m   3620\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_take_with_is_copy\u001b[39m(\u001b[38;5;28mself\u001b[39m: FrameOrSeries, indices, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m FrameOrSeries:\n\u001b[1;32m   3621\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   3622\u001b[0m \u001b[38;5;124;03m    Internal version of the `take` method that sets the `_is_copy`\u001b[39;00m\n\u001b[1;32m   3623\u001b[0m \u001b[38;5;124;03m    attribute to keep track of the parent dataframe (using in indexing\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3626\u001b[0m \u001b[38;5;124;03m    See the docstring of `take` for full explanation of the parameters.\u001b[39;00m\n\u001b[1;32m   3627\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 3628\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3629\u001b[0m     \u001b[38;5;66;03m# Maybe set copy if we didn't actually change the index.\u001b[39;00m\n\u001b[1;32m   3630\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m result\u001b[38;5;241m.\u001b[39m_get_axis(axis)\u001b[38;5;241m.\u001b[39mequals(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_axis(axis)):\n",
      "File \u001b[0;32m~/anaconda3/envs/Paris_Analysis/lib/python3.10/site-packages/pandas/core/generic.py:3618\u001b[0m, in \u001b[0;36mNDFrame.take\u001b[0;34m(self, indices, axis, is_copy, **kwargs)\u001b[0m\n\u001b[1;32m   3613\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_consolidate_inplace()\n\u001b[1;32m   3615\u001b[0m new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39mtake(\n\u001b[1;32m   3616\u001b[0m     indices, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_block_manager_axis(axis), verify\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   3617\u001b[0m )\n\u001b[0;32m-> 3618\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_constructor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_data\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtake\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/Paris_Analysis/lib/python3.10/site-packages/geopandas/geodataframe.py:29\u001b[0m, in \u001b[0;36m_geodataframe_constructor_with_fallback\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_geodataframe_constructor_with_fallback\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     24\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;124;03m    A flexible constructor for GeoDataFrame._constructor, which falls back\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;124;03m    to returning a DataFrame (if a certain operation does not preserve the\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;124;03m    geometry column)\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 29\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[43mGeoDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m     geometry_cols_mask \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mdtypes \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgeometry\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(geometry_cols_mask) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m geometry_cols_mask\u001b[38;5;241m.\u001b[39msum() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/envs/Paris_Analysis/lib/python3.10/site-packages/geopandas/geodataframe.py:176\u001b[0m, in \u001b[0;36mGeoDataFrame.__init__\u001b[0;34m(self, data, geometry, crs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    170\u001b[0m         \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgeometry\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcrs\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    171\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgeometry\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mcrs\n\u001b[1;32m    172\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m crs\n\u001b[1;32m    173\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgeometry\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mcrs \u001b[38;5;241m==\u001b[39m crs\n\u001b[1;32m    174\u001b[0m     ):\n\u001b[1;32m    175\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(crs_mismatch_error)\n\u001b[0;32m--> 176\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgeometry\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m _ensure_geometry(\u001b[38;5;28mself\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgeometry\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues, crs)\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/Paris_Analysis/lib/python3.10/site-packages/geopandas/geodataframe.py:1532\u001b[0m, in \u001b[0;36mGeoDataFrame.__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     value \u001b[38;5;241m=\u001b[39m [value] \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     crs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcrs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   1533\u001b[0m     value \u001b[38;5;241m=\u001b[39m _ensure_geometry(value, crs\u001b[38;5;241m=\u001b[39mcrs)\n\u001b[1;32m   1534\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgeometry\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/envs/Paris_Analysis/lib/python3.10/site-packages/pandas/core/generic.py:5487\u001b[0m, in \u001b[0;36mNDFrame.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5480\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   5481\u001b[0m     name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_internal_names_set\n\u001b[1;32m   5482\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metadata\n\u001b[1;32m   5483\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accessors\n\u001b[1;32m   5484\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info_axis\u001b[38;5;241m.\u001b[39m_can_hold_identifiers_and_holds_name(name)\n\u001b[1;32m   5485\u001b[0m ):\n\u001b[1;32m   5486\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[name]\n\u001b[0;32m-> 5487\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mobject\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getattribute__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/Paris_Analysis/lib/python3.10/site-packages/geopandas/geodataframe.py:436\u001b[0m, in \u001b[0;36mGeoDataFrame.crs\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    403\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    404\u001b[0m \u001b[38;5;124;03mThe Coordinate Reference System (CRS) represented as a ``pyproj.CRS``\u001b[39;00m\n\u001b[1;32m    405\u001b[0m \u001b[38;5;124;03mobject.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    433\u001b[0m \n\u001b[1;32m    434\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    435\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 436\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgeometry\u001b[49m\u001b[38;5;241m.\u001b[39mcrs\n\u001b[1;32m    437\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n\u001b[1;32m    438\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[1;32m    439\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe CRS attribute of a GeoDataFrame without an active \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    440\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgeometry column is not defined. Use GeoDataFrame.set_geometry \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    441\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto set the active geometry column.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    442\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/Paris_Analysis/lib/python3.10/site-packages/geopandas/geodataframe.py:220\u001b[0m, in \u001b[0;36mGeoDataFrame._get_geometry\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    215\u001b[0m     msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    216\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are calling a geospatial method on the GeoDataFrame, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    217\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut the active geometry column (\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_geometry_column_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    218\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis not present. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    219\u001b[0m     )\n\u001b[0;32m--> 220\u001b[0m geo_cols \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns[\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtypes\u001b[49m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgeometry\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    221\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(geo_cols) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    222\u001b[0m     msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    223\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mThere are columns with geometry data type (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgeo_cols\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m), and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    224\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can either set one as the active geometry with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    225\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdf.set_geometry(\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m) or access the column as a \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    226\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGeoSeries (df[\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m]) and call the method directly on it.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    227\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/Paris_Analysis/lib/python3.10/site-packages/pandas/core/generic.py:5658\u001b[0m, in \u001b[0;36mNDFrame.dtypes\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   5630\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m   5631\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdtypes\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   5632\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   5633\u001b[0m \u001b[38;5;124;03m    Return the dtypes in the DataFrame.\u001b[39;00m\n\u001b[1;32m   5634\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5656\u001b[0m \u001b[38;5;124;03m    dtype: object\u001b[39;00m\n\u001b[1;32m   5657\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 5658\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_dtypes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5659\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor_sliced(data, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info_axis, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mobject_)\n",
      "File \u001b[0;32m~/anaconda3/envs/Paris_Analysis/lib/python3.10/site-packages/pandas/core/internals/managers.py:250\u001b[0m, in \u001b[0;36mBaseBlockManager.get_dtypes\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_dtypes\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 250\u001b[0m     dtypes \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mblk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mblk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mblocks\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m dtypes\u001b[38;5;241m.\u001b[39mtake(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblknos)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# DEAL WITH ACTIVITIES\n",
    "\n",
    "activities_with_socio = activities_gdf.merge(persons_with_geospatial_information[['household_id', 'socioprofessional_class']], on='household_id', how='left')\n",
    "grouped_activities = activities_with_socio.groupby('purpose')\n",
    "activities_by_purpose = {purpose: group.reset_index(drop=True) for purpose, group in grouped_activities}\n",
    "activities_by_purpose_tensor = {}\n",
    "for purpose, activities in activities_by_purpose.items():\n",
    "    close_activities_count_purpose = f\"close_activities_count_{purpose}\"\n",
    "    close_activity_count = compute_close_homes(links_gdf_input=links_gdf, information_gdf_input=activities, utm_crs=utm_crs)\n",
    "    links_gdf[close_activities_count_purpose] = close_activity_count\n",
    "    activities_by_purpose_tensor[purpose] = process_close_count_to_tensor(close_activity_count)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze results and plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pio.analyze_geodataframes(result_dic=result_dic, consider_only_highway_edges=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pio.analyze_geodataframes(result_dic=result_dic, consider_only_highway_edges=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing result_dic: 100%|| 79/79 [00:08<00:00,  9.64dataframe/s]\n"
     ]
    }
   ],
   "source": [
    "def process_result_dic(result_dic, result_dic_mode_stats):\n",
    "    datalist = []\n",
    "    linegraph_transformation = LineGraph()\n",
    "    base_network_no_policies = result_dic.get(\"base_network_no_policies\")\n",
    "    vol_base_case = base_network_no_policies['vol_car'].values\n",
    "    capacity_base_case = base_network_no_policies['capacity'].values\n",
    "    length_base_case = base_network_no_policies['length'].values\n",
    "    freespeed_base_case = base_network_no_policies['freespeed'].values\n",
    "    modes_base_case = encode_modes(base_network_no_policies)\n",
    "    close_homes = close_homes_tensor.to_dense()\n",
    "    activities_home = activities_by_purpose_tensor['home'].to_dense()\n",
    "    activities_work = activities_by_purpose_tensor['work'].to_dense()\n",
    "    activities_education = activities_by_purpose_tensor['education'].to_dense()\n",
    "    activities_shop = activities_by_purpose_tensor['shop'].to_dense()\n",
    "    activities_leisure = activities_by_purpose_tensor['leisure'].to_dense()\n",
    "    activities_other = activities_by_purpose_tensor['other'].to_dense()\n",
    "    close_start_trips_tensor = close_start_trips_tensor.to_dense()\n",
    "    close_end_trips_tensor = close_end_trips_tensor.to_dense()\n",
    "    \n",
    "    # Initialize base edge positions\n",
    "    gdf_base = gpd.GeoDataFrame(base_network_no_policies, geometry='geometry')\n",
    "    gdf_base.crs = \"EPSG:2154\"  # Assuming the original CRS is EPSG:2154\n",
    "    gdf_base.to_crs(\"EPSG:4326\", inplace=True)\n",
    "    edge_positions_base = np.array([((geom.coords[0][0] + geom.coords[-1][0]) / 2, \n",
    "                                     (geom.coords[0][1] + geom.coords[-1][1]) / 2) \n",
    "                                    for geom in gdf_base.geometry])\n",
    "    \n",
    "    nodes = pd.concat([gdf_base['from_node'], gdf_base['to_node']]).unique()\n",
    "    node_to_idx = {node: idx for idx, node in enumerate(nodes)}\n",
    "    gdf_base['from_idx'] = gdf_base['from_node'].map(node_to_idx)\n",
    "    gdf_base['to_idx'] = gdf_base['to_node'].map(node_to_idx)\n",
    "    edges_base = gdf_base[['from_idx', 'to_idx']].values\n",
    "    edge_positions_tensor = torch.tensor(edge_positions_base, dtype=torch.float)\n",
    "    edge_index = torch.tensor(edges_base, dtype=torch.long).t().contiguous()\n",
    "    x = torch.zeros((len(nodes), 1), dtype=torch.float)\n",
    "    data = Data(edge_index=edge_index, x=x, pos=edge_positions_tensor)\n",
    "    linegraph_data = linegraph_transformation(data)\n",
    "\n",
    "    for key, df in tqdm(result_dic.items(), desc=\"Processing result_dic\", unit=\"dataframe\"):        \n",
    "        if isinstance(df, pd.DataFrame) and key != \"base_network_no_policies\":\n",
    "            gdf = gpd.GeoDataFrame(df, geometry='geometry')\n",
    "            gdf.crs = \"EPSG:2154\"  \n",
    "            gdf.to_crs(\"EPSG:4326\", inplace=True)\n",
    "            capacities_new = gdf['capacity'].values\n",
    "            capacity_reduction = capacities_new - capacity_base_case\n",
    "            highway = gdf['highway'].apply(lambda x: highway_mapping.get(x, -1)).values\n",
    "            length = gdf['length'].values\n",
    "            freespeed= gdf['freespeed'].values\n",
    "            modes = encode_modes(gdf)\n",
    "    \n",
    "            edge_car_volume_difference = gdf['vol_car'].values - vol_base_case\n",
    "            target_values = torch.tensor(edge_car_volume_difference, dtype=torch.float).unsqueeze(1)\n",
    "\n",
    "            linegraph_x = torch.tensor(np.column_stack((vol_base_case, capacity_base_case, capacities_new, capacity_reduction, \n",
    "                                                        highway, length, freespeed, length_base_case, freespeed_base_case, \n",
    "                                                        modes, modes_base_case, close_homes, \n",
    "                                                        activities_home, activities_work, activities_education, activities_shop, activities_leisure, activities_other,\n",
    "                                                        close_start_trips_tensor, close_end_trips_tensor)), dtype=torch.float)\n",
    "            \n",
    "            linegraph_data.x = linegraph_x\n",
    "            linegraph_data.y = target_values\n",
    "            \n",
    "            df_mode_stats = result_dic_mode_stats.get(key)\n",
    "            if df_mode_stats is not None:\n",
    "                numeric_cols = df_mode_stats.select_dtypes(include=[np.number]).columns\n",
    "                mode_stats_numeric = df_mode_stats[numeric_cols].astype(float)\n",
    "                mode_stats_tensor = torch.tensor(mode_stats_numeric.values, dtype=torch.float)\n",
    "                linegraph_data.mode_stats = mode_stats_tensor\n",
    "            if linegraph_data.validate(raise_on_error=True):\n",
    "                datalist.append(linegraph_data)\n",
    "            else:\n",
    "                print(\"Invalid line graph data\")\n",
    "    data_dict_list = [{'x': lg_data.x, 'edge_index': lg_data.edge_index, 'pos': lg_data.pos, 'y': lg_data.y, 'graph_attr': lg_data.mode_stats} for lg_data in datalist]\n",
    "    return data_dict_list\n",
    "\n",
    "data_processed = process_result_dic(result_dic=result_dic_output_links, result_dic_mode_stats=result_dic_mode_stats)\n",
    "torch.save(data_processed, result_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': tensor([[6.6275e+00, 4.8000e+02, 4.8000e+02,  ..., 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00],\n",
       "         [9.6078e+00, 4.8000e+02, 4.8000e+02,  ..., 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00],\n",
       "         [2.4902e+00, 9.6000e+02, 9.6000e+02,  ..., 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00],\n",
       "         ...,\n",
       "         [0.0000e+00, 7.9992e+03, 7.9992e+03,  ..., 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00],\n",
       "         [0.0000e+00, 7.9992e+03, 7.9992e+03,  ..., 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00],\n",
       "         [0.0000e+00, 7.9992e+03, 7.9992e+03,  ..., 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00]]),\n",
       " 'edge_index': tensor([[    0,     1,     1,  ..., 31138, 31139, 31139],\n",
       "         [   19, 10935, 10936,  ..., 30278, 31138, 31139]]),\n",
       " 'pos': tensor([[-1.3631, -5.9836],\n",
       "         [-1.3631, -5.9836],\n",
       "         [-1.3631, -5.9836],\n",
       "         ...,\n",
       "         [-1.3631, -5.9836],\n",
       "         [-1.3631, -5.9836],\n",
       "         [-1.3631, -5.9836]]),\n",
       " 'y': tensor([[ 1.3725],\n",
       "         [-0.6078],\n",
       "         [ 1.5098],\n",
       "         ...,\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000]]),\n",
       " 'graph_attr': tensor([[1.1676e+03, 3.6210e+03],\n",
       "         [1.2798e+03, 4.8323e+03],\n",
       "         [4.3310e+02, 4.3941e+03],\n",
       "         [7.8911e-01, 1.0581e+03],\n",
       "         [1.6101e+03, 5.4772e+03],\n",
       "         [1.0168e+03, 1.2207e+03]])}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_processed[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save for further processing with GNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_processed_single_districts = pio.process_result_dic(result_dic_single_districts)\n",
    "# torch.save(data_processed_single_districts, result_path + '_single_districts.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(data_processed, result_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.scatter(persons_with_homes.geometry.x, persons_with_homes.geometry.y, s=1, color='blue', alpha=0.5)\n",
    "# plt.scatter(persons_with_home_within_linear_ring.geometry.x, persons_with_home_within_linear_ring.geometry.y, s=1, color='red', alpha=0.5)\n",
    "# plt.title('Locations of Persons with Homes')\n",
    "# plt.xlabel('Longitude')\n",
    "# plt.ylabel('Latitude')\n",
    "# plt.show()\n",
    "\n",
    "# from shapely.geometry import LineString\n",
    "# from shapely.geometry import MultiPolygon\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Create a LineString\n",
    "# line = LineString([(10, 10), (20, 10)])\n",
    "\n",
    "# # Create a buffer around the line\n",
    "# buffered_line = line.buffer(2, cap_style=\"round\")\n",
    "\n",
    "# # Plot the original line and the buffered area\n",
    "# plt.figure(figsize=(8, 6))\n",
    "# x, y = line.xy\n",
    "# plt.plot(x, y, color='blue', label='Original Line')\n",
    "# if isinstance(buffered_line, MultiPolygon):\n",
    "#     for polygon in buffered_line:\n",
    "#         x, y = polygon.exterior.xy\n",
    "#         plt.fill(x, y, alpha=0.5, color='lightblue', label='Buffered Area')\n",
    "# else:\n",
    "#     x, y = buffered_line.exterior.xy\n",
    "#     plt.fill(x, y, alpha=0.5, color='lightblue', label='Buffered Area')\n",
    "\n",
    "# plt.title('Line with Buffered Area')\n",
    "# plt.xlabel('X-axis')\n",
    "# plt.ylabel('Y-axis')\n",
    "# plt.legend()\n",
    "# plt.grid()\n",
    "# plt.axis('equal')\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "# def check_trips_equivalence(close_trips_start, close_trips_end):\n",
    "#     \"\"\"\n",
    "#     Check if close_trips_start and close_trips_end are equivalent.\n",
    "    \n",
    "#     Args:\n",
    "#     close_trips_start (list): List of tuples for start trips\n",
    "#     close_trips_end (list): List of tuples for end trips\n",
    "    \n",
    "#     Returns:\n",
    "#     bool: True if equivalent, False otherwise\n",
    "#     \"\"\"\n",
    "#     if len(close_trips_start) != len(close_trips_end):\n",
    "#         print(\"Lists have different lengths.\")\n",
    "#         return False\n",
    "    \n",
    "#     differences = []\n",
    "#     for i, (start, end) in enumerate(zip(close_trips_start, close_trips_end)):\n",
    "#         if start != end:\n",
    "#             differences.append((i, start, end))\n",
    "    \n",
    "#     if not differences:\n",
    "#         print(\"The lists are identical.\")\n",
    "#         return True\n",
    "#     else:\n",
    "#         print(f\"Found {len(differences)} differences:\")\n",
    "#         for diff in differences[:10]:  # Print first 10 differences\n",
    "#             print(f\"Index {diff[0]}: Start {diff[1]}, End {diff[2]}\")\n",
    "#         if len(differences) > 10:\n",
    "#             print(f\"... and {len(differences) - 10} more differences.\")\n",
    "#         return False\n",
    "\n",
    "# # Usage\n",
    "# are_equivalent = check_trips_equivalence(close_trips_start, close_trips_end)\n",
    "# print(f\"Are the trip lists equivalent? {are_equivalent}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Paris_Analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
