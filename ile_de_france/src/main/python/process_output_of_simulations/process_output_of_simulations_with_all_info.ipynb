{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import glob\n",
    "import math\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import torch\n",
    "\n",
    "import processing_io as pio\n",
    "from torch_geometric.transforms import LineGraph\n",
    "\n",
    "from torch_geometric.data import Data, Batch\n",
    "import shapely.wkt as wkt\n",
    "from tqdm import tqdm\n",
    "import fiona\n",
    "import os\n",
    "\n",
    "import alphashape\n",
    "from shapely.geometry import Polygon\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from shapely.geometry import Point\n",
    "\n",
    "\n",
    "highway_mapping = {\n",
    "    'trunk': 0, 'trunk_link': 0, 'motorway_link': 0,\n",
    "    'primary': 1, 'primary_link': 1,\n",
    "    'secondary': 2, 'secondary_link': 2,\n",
    "    'tertiary': 3, 'tertiary_link': 3,\n",
    "    'residential': 4, 'living_street': 5,\n",
    "    'pedestrian': 6, 'service': 7,\n",
    "    'construction': 8, 'unclassified': 9,\n",
    "    'np.nan': -1\n",
    "}\n",
    "result_df_name = 'sim_output_1pm_capacity_reduction_10k_PRELIMINARY'\n",
    "result_path = '../../../../data/datasets_simulation_outputs/' + result_df_name + '.pt'\n",
    "string_is_for_1pm = \"pop_1pm\"\n",
    "\n",
    "base_dir_sample_sim_input = '../../../../data/' + string_is_for_1pm + '_simulations/' + string_is_for_1pm + '_policies_combinations_with_normal_dist/'\n",
    "subdirs_pattern = os.path.join(base_dir_sample_sim_input, 'output_networks_*')\n",
    "subdirs = list(set(glob.glob(subdirs_pattern)))\n",
    "subdirs.sort()\n",
    "\n",
    "paris_inside_bvd_peripherique = \"../../../../data/paris_inside_bvd_per/referentiel-comptages-edit.shp\"\n",
    "gdf_paris_inside_bvd_per = gpd.read_file(paris_inside_bvd_peripherique)\n",
    "boundary_df = alphashape.alphashape(gdf_paris_inside_bvd_per, 435).exterior[0]\n",
    "linear_ring_polygon = Polygon(boundary_df)\n",
    "\n",
    "gdf_basecase_output_links = gpd.read_file('results/' + string_is_for_1pm + '_basecase_average_output_links.geojson')\n",
    "gdf_basecase_average_mode_stats = pd.read_csv('results/' + string_is_for_1pm + '_basecase_average_mode_stats.csv', delimiter=';')\n",
    "districts = gpd.read_file(\"../../../../data/visualisation/districts_paris.geojson\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abstract\n",
    "\n",
    "This is further than process_output_of_simulations_with_all_output_links_and_eqasim_info.ipynb, as it also includes more input information."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process results\n",
    "\n",
    "Process the outputs of the simulations for further usage by GNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_close_homes(links_gdf_input:pd.DataFrame, information_gdf_input:pd.DataFrame, utm_crs:str, distance:int=50):\n",
    "    links_gdf = links_gdf_input.copy()\n",
    "    information_gdf = information_gdf_input.copy()\n",
    "    close_places = []\n",
    "    links_gdf_utm = links_gdf.to_crs(utm_crs)\n",
    "    information_gdf_utm = information_gdf.to_crs(utm_crs)\n",
    "    for i, row in tqdm(enumerate(links_gdf_utm.iterrows()), desc=\"Processing rows\", unit=\"row\"):\n",
    "        buffer_utm = row[1].geometry.buffer(distance=distance)\n",
    "        buffer = gpd.GeoSeries([buffer_utm], crs=utm_crs).to_crs(links_gdf_utm.crs)[0]\n",
    "        matched_information = information_gdf_utm[information_gdf_utm.geometry.within(buffer)]\n",
    "        socioprofessional_classes = matched_information['socioprofessional_class'].tolist()\n",
    "        close_places.append((len(socioprofessional_classes), socioprofessional_classes))\n",
    "    return close_places\n",
    "\n",
    "def process_close_count_to_tensor(close_count_list: list):\n",
    "    socio_professional_classes = [item[1] for item in close_count_list]\n",
    "    unique_classes = set([2, 3, 4, 5, 6, 7, 8])\n",
    "    class_to_index = {cls: idx for idx, cls in enumerate(unique_classes)}\n",
    "\n",
    "    tensor_shape = (len(close_count_list), len(unique_classes))\n",
    "    close_homes_tensor = torch.zeros(tensor_shape)\n",
    "\n",
    "    for i, classes in enumerate(socio_professional_classes):\n",
    "        for cls in classes:\n",
    "            if cls in class_to_index:  # Ensure the class is in the predefined set\n",
    "                close_homes_tensor[i, class_to_index[cls]] += 1\n",
    "    \n",
    "    close_homes_tensor_sparse = close_homes_tensor.to_sparse()\n",
    "    return close_homes_tensor_sparse\n",
    "\n",
    "# Read all network data into a dictionary of GeoDataFrames\n",
    "def compute_result_dic_output_links():\n",
    "    result_dic = {}\n",
    "    base_network_no_policies = gdf_basecase_output_links\n",
    "    result_dic[\"base_network_no_policies\"] = base_network_no_policies\n",
    "    for subdir in tqdm(subdirs, desc=\"Processing subdirs\", unit=\"subdir\"):\n",
    "        # print(f'Accessing folder: {subdir}')\n",
    "        # print(len(os.listdir(subdir)))\n",
    "        networks = [network for network in os.listdir(subdir) if not network.endswith(\".DS_Store\")]\n",
    "        for network in networks:\n",
    "            file_path = os.path.join(subdir, network)\n",
    "            policy_key = pio.create_policy_key_1pm(network)\n",
    "            gdf_output_links = pio.read_output_links(file_path)\n",
    "            if (gdf_output_links is not None):\n",
    "                gdf_extended = pio.extend_geodataframe(gdf_base=gdf_basecase_output_links, gdf_to_extend=gdf_output_links, column_to_extend='highway', new_column_name='highway')\n",
    "                gdf_extended = pio.extend_geodataframe(gdf_base=gdf_basecase_output_links, gdf_to_extend=gdf_extended, column_to_extend='vol_car', new_column_name='vol_car_base_case')\n",
    "                result_dic[policy_key] = gdf_extended\n",
    "        break\n",
    "    return result_dic\n",
    "\n",
    "def calculate_averaged_results(trips_df):\n",
    "    \"\"\"Calculate average travel time and routed distance grouped by mode.\"\"\"\n",
    "    return trips_df.groupby('mode').agg(\n",
    "        total_travel_time=('travel_time', 'mean'),\n",
    "        total_routed_distance=('routed_distance', 'mean')\n",
    "    ).reset_index()\n",
    "\n",
    "def compute_result_dic_mode_stats(calculate_averaged_results):\n",
    "    result_dic_mode_stats = {}\n",
    "    result_dic_mode_stats[\"base_network_no_policies\"] = gdf_basecase_average_mode_stats\n",
    "    for subdir in tqdm(subdirs, desc=\"Processing subdirs\", unit=\"subdir\"):\n",
    "        networks = [network for network in os.listdir(subdir) if not network.endswith(\".DS_Store\")]\n",
    "        for network in networks:\n",
    "            file_path = os.path.join(subdir, network)\n",
    "            policy_key = pio.create_policy_key_1pm(network)\n",
    "            df_mode_stats = pd.read_csv(file_path + '/eqasim_trips.csv', delimiter=';')\n",
    "            averaged_results = calculate_averaged_results(df_mode_stats)\n",
    "            if (averaged_results is not None):\n",
    "                result_dic_mode_stats[policy_key] = averaged_results\n",
    "        break\n",
    "    return result_dic_mode_stats\n",
    "\n",
    "def encode_modes(gdf):\n",
    "    \"\"\"Encode the 'modes' attribute based on specific strings.\"\"\"\n",
    "    modes_conditions = {\n",
    "        'car': gdf['modes'].str.contains('car', case=False, na=False).astype(int),\n",
    "        'bus': gdf['modes'].str.contains('bus', case=False, na=False).astype(int),\n",
    "        'pt': gdf['modes'].str.contains('pt', case=False, na=False).astype(int),\n",
    "        'train': gdf['modes'].str.contains('train', case=False, na=False).astype(int),\n",
    "        'rail': gdf['modes'].str.contains('rail', case=False, na=False).astype(int),\n",
    "        'subway': gdf['modes'].str.contains('subway', case=False, na=False).astype(int)\n",
    "    }\n",
    "    modes_encoded = pd.DataFrame(modes_conditions)\n",
    "    return torch.tensor(modes_encoded.values, dtype=torch.float)\n",
    "\n",
    "def get_dfs(base_dir:str):\n",
    "    files = os.listdir(base_dir)\n",
    "    for file in files:\n",
    "        file_path = os.path.join(base_dir, file)\n",
    "        base_name, ext = os.path.splitext(file)\n",
    "        if base_name.startswith(\"idf_1pm_\"):\n",
    "            base_name = base_name.replace(\"idf_1pm_\", \"\")\n",
    "        var_name = base_name  # Start with the cleaned base name\n",
    "    \n",
    "        if file.endswith('.csv'):\n",
    "            try:\n",
    "                var_name = f\"{var_name}_df\"  \n",
    "                globals()[var_name] = pd.read_csv(file_path, sep=\";\")\n",
    "                print(f\"Loaded CSV file: {file} into variable: {var_name}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading CSV file {file}: {e}\")\n",
    "            \n",
    "        elif file.endswith('.gpkg'):\n",
    "            try:\n",
    "                var_name = f\"{var_name}_gdf\"  \n",
    "                layers = fiona.listlayers(file_path)\n",
    "                geodataframes = {layer: gpd.read_file(file_path, layer=layer, geometry = 'geometry', crs=\"EPSG:2154\") for layer in layers}\n",
    "                for layer, gdf in geodataframes.items():\n",
    "                # print(f\"Layer: {layer}\")\n",
    "                    gdf = gdf.to_crs(epsg=4326)\n",
    "                    globals()[var_name] = gdf\n",
    "                    print(f\"Loaded GPKG file: {file} into variable: {var_name}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading CSV file {file}: {e}\")\n",
    "    homes_gdf = globals()[\"homes_gdf\"]\n",
    "    households_df = globals()[\"households_df\"]\n",
    "    persons_df = globals()[\"persons_df\"]\n",
    "    activities_gdf = globals()[\"activities_gdf\"]\n",
    "    trips_df = globals()[\"trips_gdf\"]\n",
    "    return homes_gdf, households_df, persons_df, activities_gdf, trips_df\n",
    "\n",
    "def extract_start_end_points(geometry):\n",
    "    if len(geometry.coords) != 2:\n",
    "        raise ValueError(\"Linestring does not have exactly 2 elements.\")\n",
    "    return geometry.coords[0], geometry.coords[-1]\n",
    "\n",
    "def get_close_trips_tensor(links_gdf_input, trips_gdf_input, utm_crs, distance):\n",
    "    close_trips_count = compute_close_homes(links_gdf_input = links_gdf_input, information_gdf_input = trips_gdf_input, utm_crs = utm_crs, distance=distance)\n",
    "    close_trips_count_tensor = process_close_count_to_tensor(close_trips_count)\n",
    "    return close_trips_count, close_trips_count_tensor\n",
    "\n",
    "def get_start_and_end_gdf(trips_with_socio, crs):\n",
    "    trips_start = trips_with_socio.copy()\n",
    "    trips_end = trips_with_socio.copy()\n",
    "\n",
    "    trips_start_gdf = gpd.GeoDataFrame(\n",
    "    trips_start, \n",
    "    geometry=gpd.points_from_xy(\n",
    "        trips_start['start_point'].apply(lambda p: p[0]), \n",
    "        trips_start['start_point'].apply(lambda p: p[1])\n",
    "    ), \n",
    "    crs=crs\n",
    ")\n",
    "\n",
    "    trips_end_gdf = gpd.GeoDataFrame(\n",
    "    trips_end, \n",
    "    geometry=gpd.points_from_xy(\n",
    "        trips_end['end_point'].apply(lambda p: p[0]), \n",
    "        trips_end['end_point'].apply(lambda p: p[1])\n",
    "    ), \n",
    "    crs=crs\n",
    ")\n",
    "    return trips_start_gdf,trips_end_gdf\n",
    "\n",
    "def process_centroid(geom_list):\n",
    "    if not geom_list:  # Empty list\n",
    "        return [np.nan, np.nan]\n",
    "    elif len(geom_list) == 1:\n",
    "        return [geom_list[0], np.nan]\n",
    "    else:\n",
    "        return [geom_list[0], geom_list[1]]\n",
    "    \n",
    "def extract_point_coordinates(geom_list):\n",
    "    coordinates = []\n",
    "    for geom in geom_list:\n",
    "        if isinstance(geom, Point):\n",
    "            coordinates.append((geom.x, geom.y))\n",
    "        else:\n",
    "            coordinates.append((np.nan, np.nan))\n",
    "    return coordinates\n",
    "\n",
    "def process_value_list(perimeter_list):\n",
    "    if not perimeter_list:  # Empty list\n",
    "        return [np.nan, np.nan]\n",
    "    elif len(perimeter_list) == 1:\n",
    "        return [perimeter_list[0], np.nan]\n",
    "    else:\n",
    "        return [perimeter_list[0], perimeter_list[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing subdirs:   0%|          | 0/90 [00:16<?, ?subdir/s]\n",
      "Processing subdirs:   0%|          | 0/90 [00:01<?, ?subdir/s]\n",
      "/var/folders/m_/fjnjc1sn0ggc7z_2y7n27xfh0000gn/T/ipykernel_8056/2759847660.py:10: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  districts['district_centroid'] = districts['geometry'].centroid\n",
      "/Users/elenanatterer/anaconda3/envs/Paris_Analysis/lib/python3.10/site-packages/IPython/core/interactiveshell.py:3448: FutureWarning: The `op` parameter is deprecated and will be removed in a future release. Please use the `predicate` parameter instead.\n",
      "  if await self.run_code(code, result, async_=asy):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31216, 28)\n",
      "(31216, 28)\n",
      "(31216, 28)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/elenanatterer/anaconda3/envs/Paris_Analysis/lib/python3.10/site-packages/pandas/core/reshape/merge.py:1203: RuntimeWarning: invalid value encountered in cast\n",
      "  if not (lk == lk.astype(rk.dtype))[~np.isnan(lk)].all():\n"
     ]
    }
   ],
   "source": [
    "result_dic_output_links = compute_result_dic_output_links()\n",
    "result_dic_mode_stats = compute_result_dic_mode_stats(calculate_averaged_results)\n",
    "base_gdf = result_dic_output_links[\"base_network_no_policies\"]\n",
    "print(base_gdf.shape)\n",
    "links_gdf_base = gpd.GeoDataFrame(base_gdf, geometry='geometry')\n",
    "print(links_gdf_base.shape)\n",
    "links_gdf_base.crs = \"EPSG:2154\"  # Assuming the original CRS is EPSG:2154\n",
    "links_gdf_base.to_crs(\"EPSG:4326\", inplace=True)\n",
    "print(links_gdf_base.shape)\n",
    "districts['district_centroid'] = districts['geometry'].centroid\n",
    "links_gdf_with_districts = gpd.sjoin(links_gdf_base, districts, how='left', op='intersects')\n",
    "\n",
    "# Group by edge and aggregate the district names\n",
    "links_gdf_with_districts = links_gdf_with_districts.groupby('link').agg({\n",
    "    'from_node': 'first',\n",
    "    'to_node': 'first',\n",
    "    'length': 'first',\n",
    "    'freespeed': 'first',\n",
    "    'capacity': 'first',\n",
    "    'lanes': 'first',\n",
    "    'modes': 'first',\n",
    "    'vol_car': 'first',\n",
    "    'highway': 'first',\n",
    "    'geometry': 'first',\n",
    "    'c_ar': lambda x: list(x.dropna()),\n",
    "    'district_centroid': lambda x: list(x.dropna()),\n",
    "    'perimetre': lambda x: list(x.dropna()),\n",
    "    'surface': lambda x: list(x.dropna()),\n",
    "}).reset_index()\n",
    "gdf_now = gpd.GeoDataFrame(links_gdf_with_districts, geometry='geometry', crs=links_gdf_base.crs)\n",
    "gdf_now = gdf_now.rename(columns={'c_ar': 'district', 'perimetre': 'district_perimeter', 'surface': 'district_surface'})\n",
    "links_gdf_final = gdf_now.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>link</th>\n",
       "      <th>from_node</th>\n",
       "      <th>to_node</th>\n",
       "      <th>length</th>\n",
       "      <th>freespeed</th>\n",
       "      <th>capacity</th>\n",
       "      <th>lanes</th>\n",
       "      <th>modes</th>\n",
       "      <th>vol_car</th>\n",
       "      <th>highway</th>\n",
       "      <th>geometry</th>\n",
       "      <th>district</th>\n",
       "      <th>district_centroid</th>\n",
       "      <th>district_perimeter</th>\n",
       "      <th>district_surface</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100315</td>\n",
       "      <td>24972409</td>\n",
       "      <td>24972408</td>\n",
       "      <td>16.181257</td>\n",
       "      <td>8.333333</td>\n",
       "      <td>480.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>bus,car,car_passenger</td>\n",
       "      <td>6.627451</td>\n",
       "      <td>residential</td>\n",
       "      <td>LINESTRING (2.33869 48.85181, 2.33847 48.85181)</td>\n",
       "      <td>[6.0]</td>\n",
       "      <td>[POINT (2.3328979990533134 48.849130358585185)]</td>\n",
       "      <td>[6483.68678565]</td>\n",
       "      <td>[2153095.58639283]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100316</td>\n",
       "      <td>5904976363</td>\n",
       "      <td>24983651</td>\n",
       "      <td>14.860209</td>\n",
       "      <td>8.333333</td>\n",
       "      <td>480.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>bus,car,car_passenger,pt</td>\n",
       "      <td>9.607843</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>LINESTRING (2.33874 48.85242, 2.33872 48.85229)</td>\n",
       "      <td>[6.0]</td>\n",
       "      <td>[POINT (2.3328979990533134 48.849130358585185)]</td>\n",
       "      <td>[6483.68678565]</td>\n",
       "      <td>[2153095.58639283]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100317</td>\n",
       "      <td>24983651</td>\n",
       "      <td>5904976363</td>\n",
       "      <td>14.860209</td>\n",
       "      <td>8.333333</td>\n",
       "      <td>960.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>bus,car,car_passenger,pt</td>\n",
       "      <td>2.490196</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>LINESTRING (2.33872 48.85229, 2.33874 48.85242)</td>\n",
       "      <td>[6.0]</td>\n",
       "      <td>[POINT (2.3328979990533134 48.849130358585185)]</td>\n",
       "      <td>[6483.68678565]</td>\n",
       "      <td>[2153095.58639283]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100321</td>\n",
       "      <td>664205947</td>\n",
       "      <td>24972376</td>\n",
       "      <td>22.264540</td>\n",
       "      <td>8.333333</td>\n",
       "      <td>960.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>car,car_passenger</td>\n",
       "      <td>6.941176</td>\n",
       "      <td>residential</td>\n",
       "      <td>LINESTRING (2.33994 48.85200, 2.33986 48.85181)</td>\n",
       "      <td>[6.0]</td>\n",
       "      <td>[POINT (2.3328979990533134 48.849130358585185)]</td>\n",
       "      <td>[6483.68678565]</td>\n",
       "      <td>[2153095.58639283]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100324</td>\n",
       "      <td>24972376</td>\n",
       "      <td>24972375</td>\n",
       "      <td>64.853276</td>\n",
       "      <td>8.333333</td>\n",
       "      <td>480.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>bus,car,car_passenger</td>\n",
       "      <td>7.607843</td>\n",
       "      <td>residential</td>\n",
       "      <td>LINESTRING (2.33986 48.85181, 2.33909 48.85152)</td>\n",
       "      <td>[6.0]</td>\n",
       "      <td>[POINT (2.3328979990533134 48.849130358585185)]</td>\n",
       "      <td>[6483.68678565]</td>\n",
       "      <td>[2153095.58639283]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     link   from_node     to_node     length  freespeed  capacity  lanes  \\\n",
       "0  100315    24972409    24972408  16.181257   8.333333     480.0    1.0   \n",
       "1  100316  5904976363    24983651  14.860209   8.333333     480.0    1.0   \n",
       "2  100317    24983651  5904976363  14.860209   8.333333     960.0    2.0   \n",
       "3  100321   664205947    24972376  22.264540   8.333333     960.0    2.0   \n",
       "4  100324    24972376    24972375  64.853276   8.333333     480.0    1.0   \n",
       "\n",
       "                      modes   vol_car      highway  \\\n",
       "0     bus,car,car_passenger  6.627451  residential   \n",
       "1  bus,car,car_passenger,pt  9.607843     tertiary   \n",
       "2  bus,car,car_passenger,pt  2.490196     tertiary   \n",
       "3         car,car_passenger  6.941176  residential   \n",
       "4     bus,car,car_passenger  7.607843  residential   \n",
       "\n",
       "                                          geometry district  \\\n",
       "0  LINESTRING (2.33869 48.85181, 2.33847 48.85181)    [6.0]   \n",
       "1  LINESTRING (2.33874 48.85242, 2.33872 48.85229)    [6.0]   \n",
       "2  LINESTRING (2.33872 48.85229, 2.33874 48.85242)    [6.0]   \n",
       "3  LINESTRING (2.33994 48.85200, 2.33986 48.85181)    [6.0]   \n",
       "4  LINESTRING (2.33986 48.85181, 2.33909 48.85152)    [6.0]   \n",
       "\n",
       "                                 district_centroid district_perimeter  \\\n",
       "0  [POINT (2.3328979990533134 48.849130358585185)]    [6483.68678565]   \n",
       "1  [POINT (2.3328979990533134 48.849130358585185)]    [6483.68678565]   \n",
       "2  [POINT (2.3328979990533134 48.849130358585185)]    [6483.68678565]   \n",
       "3  [POINT (2.3328979990533134 48.849130358585185)]    [6483.68678565]   \n",
       "4  [POINT (2.3328979990533134 48.849130358585185)]    [6483.68678565]   \n",
       "\n",
       "     district_surface  \n",
       "0  [2153095.58639283]  \n",
       "1  [2153095.58639283]  \n",
       "2  [2153095.58639283]  \n",
       "3  [2153095.58639283]  \n",
       "4  [2153095.58639283]  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "links_gdf_final.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded CSV file: idf_1pm_persons.csv into variable: persons_df\n",
      "Loaded GPKG file: idf_1pm_commutes.gpkg into variable: commutes_gdf\n",
      "Loaded CSV file: idf_1pm_households.csv into variable: households_df\n",
      "Loaded CSV file: idf_1pm_trips.csv into variable: trips_df\n",
      "Loaded CSV file: idf_1pm_activities.csv into variable: activities_df\n",
      "Loaded CSV file: idf_1pm_vehicle_types.csv into variable: vehicle_types_df\n",
      "Loaded GPKG file: idf_1pm_trips.gpkg into variable: trips_gdf\n",
      "Loaded GPKG file: idf_1pm_activities.gpkg into variable: activities_gdf\n",
      "Loaded CSV file: idf_1pm_vehicles.csv into variable: vehicles_df\n",
      "Loaded GPKG file: idf_1pm_homes.gpkg into variable: homes_gdf\n"
     ]
    }
   ],
   "source": [
    "base_dir_sample_sim_input = '../../../../data/pop_1pm_simulations/idf_1pm/' \n",
    "homes_gdf, households_df, persons_df, activities_gdf, trips_df = get_dfs(base_dir=base_dir_sample_sim_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "population_df = pd.read_csv(\"intermediate_results/population.csv\")\n",
    "\n",
    "sorted_population_df = population_df.sort_values(by=\"id\")\n",
    "sorted_persons_df = persons_df.sort_values(by=\"person_id\")\n",
    "merged_df = pd.merge(sorted_persons_df, sorted_population_df, left_on=\"person_id\", right_on=\"id\")\n",
    "removed_some_columns = merged_df.copy()\n",
    "removed_some_columns = removed_some_columns.drop(columns=['employed_y', 'hasPtSubscription', 'householdId', 'sex_y', 'htsPersonId', 'censusPersonId', 'hasLicense', 'id', 'age_y'])\n",
    "updated_persons = removed_some_columns.copy()\n",
    "persons_with_geospatial_information = homes_gdf.merge(updated_persons, on='household_id', how='right')\n",
    "\n",
    "if not isinstance(persons_with_geospatial_information, gpd.GeoDataFrame):\n",
    "    persons_with_geospatial_information = gpd.GeoDataFrame(persons_with_geospatial_information, geometry=gpd.points_from_xy(persons_with_geospatial_information.longitude, persons_with_geospatial_information.latitude), crs= links_gdf.crs)\n",
    "\n",
    "utm_crs = 'EPSG:32631'  # UTM zone 31N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows: 31216row [01:26, 362.46row/s]\n",
      "Processing rows: 2133row [00:06, 353.36row/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/Paris_Analysis/lib/python3.10/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m   5497\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5498\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5499\u001b[0;31m             \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5500\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'GeoSeries' object has no attribute '_cacher'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/m_/fjnjc1sn0ggc7z_2y7n27xfh0000gn/T/ipykernel_8056/3451390360.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mtrips_start_gdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrips_end_gdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_start_and_end_gdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrips_with_socio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrips_with_socio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlinks_gdf_final\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mclose_trips_start\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclose_start_trips_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_close_trips_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinks_gdf_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlinks_gdf_final\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrips_gdf_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrips_start_gdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mutm_crs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mutm_crs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdistance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mclose_trips_end\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclose_end_trips_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_close_trips_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinks_gdf_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlinks_gdf_final\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrips_gdf_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrips_end_gdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mutm_crs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mutm_crs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdistance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/m_/fjnjc1sn0ggc7z_2y7n27xfh0000gn/T/ipykernel_8056/303235414.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(links_gdf_input, trips_gdf_input, utm_crs, distance)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_close_trips_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinks_gdf_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrips_gdf_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mutm_crs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdistance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m     \u001b[0mclose_trips_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_close_homes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinks_gdf_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinks_gdf_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minformation_gdf_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrips_gdf_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mutm_crs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutm_crs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdistance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdistance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m     \u001b[0mclose_trips_count_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_close_count_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclose_trips_count\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mclose_trips_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclose_trips_count_tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/m_/fjnjc1sn0ggc7z_2y7n27xfh0000gn/T/ipykernel_8056/303235414.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(links_gdf_input, information_gdf_input, utm_crs, distance)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0minformation_gdf_utm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minformation_gdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_crs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mutm_crs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinks_gdf_utm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Processing rows\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"row\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mbuffer_utm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeometry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdistance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdistance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mbuffer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGeoSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbuffer_utm\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mutm_crs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_crs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinks_gdf_utm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mmatched_information\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minformation_gdf_utm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minformation_gdf_utm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeometry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwithin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0msocioprofessional_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmatched_information\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'socioprofessional_class'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mclose_places\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msocioprofessional_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msocioprofessional_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mclose_places\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/Paris_Analysis/lib/python3.10/site-packages/geopandas/geodataframe.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1471\u001b[0m         \u001b[0mIf\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0ma\u001b[0m \u001b[0mcolumn\u001b[0m \u001b[0mcontaining\u001b[0m \u001b[0monly\u001b[0m \u001b[0;34m'geometry'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1472\u001b[0m         \u001b[0mGeoSeries\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mIf\u001b[0m \u001b[0mit\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0ms\u001b[0m \u001b[0ma\u001b[0m \u001b[0mDataFrame\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0many\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0mof\u001b[0m \u001b[0mGeometryDtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1473\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0ma\u001b[0m \u001b[0mGeoDataFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m         \"\"\"\n\u001b[0;32m-> 1475\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1476\u001b[0m         \u001b[0;31m# Custom logic to avoid waiting for pandas GH51895\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1477\u001b[0m         \u001b[0;31m# result is not geometry dtype for multi-indexes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1478\u001b[0m         if (\n",
      "\u001b[0;32m~/anaconda3/envs/Paris_Analysis/lib/python3.10/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3445\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3447\u001b[0m         \u001b[0;31m# Do we have a (boolean) 1d indexer?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3448\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_bool_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3449\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_bool_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3451\u001b[0m         \u001b[0;31m# We are left with two options: a single key, and a collection of keys,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3452\u001b[0m         \u001b[0;31m# We interpret tuples as collections only for non-MultiIndex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/Paris_Analysis/lib/python3.10/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3500\u001b[0m         \u001b[0;31m# check_bool_indexer will throw exception if Series key cannot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3501\u001b[0m         \u001b[0;31m# be reindexed to match DataFrame rows\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3502\u001b[0m         \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_bool_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3503\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3504\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_take_with_is_copy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/Paris_Analysis/lib/python3.10/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, indices, axis)\u001b[0m\n\u001b[1;32m   3624\u001b[0m         for the SettingWithCopyWarning).\n\u001b[1;32m   3625\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3626\u001b[0m         \u001b[0mSee\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdocstring\u001b[0m \u001b[0mof\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfull\u001b[0m \u001b[0mexplanation\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3627\u001b[0m         \"\"\"\n\u001b[0;32m-> 3628\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3629\u001b[0m         \u001b[0;31m# Maybe set copy if we didn't actually change the index.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3630\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mequals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3631\u001b[0m             \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_is_copy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/Paris_Analysis/lib/python3.10/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, indices, axis, is_copy, **kwargs)\u001b[0m\n\u001b[1;32m   3614\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3615\u001b[0m         new_data = self._mgr.take(\n\u001b[1;32m   3616\u001b[0m             \u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_block_manager_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3617\u001b[0m         )\n\u001b[0;32m-> 3618\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"take\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/Paris_Analysis/lib/python3.10/site-packages/geopandas/geodataframe.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mA\u001b[0m \u001b[0mflexible\u001b[0m \u001b[0mconstructor\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mGeoDataFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwhich\u001b[0m \u001b[0mfalls\u001b[0m \u001b[0mback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     to returning a DataFrame (if a certain operation does not preserve the\n\u001b[1;32m     27\u001b[0m     geometry column)\n\u001b[1;32m     28\u001b[0m     \"\"\"\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGeoDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m     \u001b[0mgeometry_cols_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtypes\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"geometry\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgeometry_cols_mask\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mgeometry_cols_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/Paris_Analysis/lib/python3.10/site-packages/geopandas/geodataframe.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, data, geometry, crs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    173\u001b[0m                     \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"geometry\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcrs\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mcrs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m                 ):\n\u001b[1;32m    175\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcrs_mismatch_error\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"geometry\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_ensure_geometry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"geometry\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m                 \u001b[0mgeometry\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"geometry\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/Paris_Analysis/lib/python3.10/site-packages/geopandas/geodataframe.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1471\u001b[0m         \u001b[0mIf\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0ma\u001b[0m \u001b[0mcolumn\u001b[0m \u001b[0mcontaining\u001b[0m \u001b[0monly\u001b[0m \u001b[0;34m'geometry'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1472\u001b[0m         \u001b[0mGeoSeries\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mIf\u001b[0m \u001b[0mit\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0ms\u001b[0m \u001b[0ma\u001b[0m \u001b[0mDataFrame\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0many\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0mof\u001b[0m \u001b[0mGeometryDtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1473\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0ma\u001b[0m \u001b[0mGeoDataFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m         \"\"\"\n\u001b[0;32m-> 1475\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1476\u001b[0m         \u001b[0;31m# Custom logic to avoid waiting for pandas GH51895\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1477\u001b[0m         \u001b[0;31m# result is not geometry dtype for multi-indexes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1478\u001b[0m         if (\n",
      "\u001b[0;32m~/anaconda3/envs/Paris_Analysis/lib/python3.10/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3423\u001b[0m             \u001b[0;31m# shortcut if the key is in columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3424\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3425\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMultiIndex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3426\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3427\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3429\u001b[0m         \u001b[0;31m# Do we have a slicer (on rows)?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3430\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_to_index_sliceable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/Paris_Analysis/lib/python3.10/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   3885\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3886\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_box_col_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3888\u001b[0m             \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3889\u001b[0;31m             \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_as_cached\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3891\u001b[0m             \u001b[0;31m# for a chain\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3892\u001b[0m             \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_copy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_copy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/Paris_Analysis/lib/python3.10/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, item, cacher)\u001b[0m\n\u001b[1;32m   1195\u001b[0m         \"\"\"\n\u001b[1;32m   1196\u001b[0m         \u001b[0mSet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0m_cacher\u001b[0m \u001b[0mattribute\u001b[0m \u001b[0mon\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mcalling\u001b[0m \u001b[0mobject\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0ma\u001b[0m \u001b[0mweakref\u001b[0m \u001b[0mto\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1197\u001b[0m         \u001b[0mcacher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1198\u001b[0m         \"\"\"\n\u001b[0;32m-> 1199\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cacher\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcacher\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/Paris_Analysis/lib/python3.10/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m   5495\u001b[0m         \u001b[0;31m# e.g. ``obj.x`` and ``obj.x = 4`` will always reference/modify\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5496\u001b[0m         \u001b[0;31m# the same attribute.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5497\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5498\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5499\u001b[0;31m             \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5500\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5501\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5502\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# DEAL WITH TRIPS\n",
    "\n",
    "trips_with_socio = trips_df.merge(persons_with_geospatial_information[['person_id', 'socioprofessional_class']], on='person_id', how='left')\n",
    "trips_with_socio['start_point'] = trips_with_socio['geometry'].apply(lambda geom: extract_start_end_points(geom)[0])\n",
    "trips_with_socio['end_point'] = trips_with_socio['geometry'].apply(lambda geom: extract_start_end_points(geom)[1])\n",
    "\n",
    "trips_start_gdf, trips_end_gdf = get_start_and_end_gdf(trips_with_socio=trips_with_socio, crs=links_gdf_final.crs)\n",
    "\n",
    "close_trips_start, close_start_trips_tensor = get_close_trips_tensor(links_gdf_input=links_gdf_final, trips_gdf_input=trips_start_gdf, utm_crs=utm_crs, distance=50)\n",
    "close_trips_end, close_end_trips_tensor = get_close_trips_tensor(links_gdf_input=links_gdf_final, trips_gdf_input=trips_end_gdf, utm_crs=utm_crs, distance=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create tensors for each combination of \"preceding_purpose\" and \"following_purpose\"\n",
    "# unique_purposes = trips_with_socio['preceding_purpose'].unique()\n",
    "# close_start_trips_tensor_dict = {}\n",
    "# close_start_trips_dict = {}\n",
    "# close_end_trips_tensor_dict = {}\n",
    "# close_end_trips_dict = {}\n",
    "\n",
    "# for preceding_purpose in tqdm(unique_purposes, desc=\"Processing preceding purposes\", unit=\"purpose\"):\n",
    "#     for following_purpose in tqdm(unique_purposes, desc=\"Processing following purposes\", unit=\"purpose\"):\n",
    "#         if preceding_purpose != following_purpose:\n",
    "#             filtered_trips = trips_with_socio[(trips_with_socio['preceding_purpose'] == preceding_purpose) & (trips_with_socio['following_purpose'] == following_purpose)]\n",
    "#             if not filtered_trips.empty:\n",
    "#                 filtered_trips_start_gdf, filtered_trips_end_gdf = get_start_and_end_gdf(trips_with_socio=filtered_trips, crs=links_gdf_final.crs)\n",
    "                \n",
    "#                 close_start_trips, close_start_trips_tensor = get_close_trips_tensor(links_gdf_input=links_gdf_final, trips_gdf_input=filtered_trips_start_gdf, utm_crs=utm_crs, distance=50)\n",
    "#                 close_end_trips, close_end_trips_tensor = get_close_trips_tensor(links_gdf_input=links_gdf_final, trips_gdf_input=filtered_trips_end_gdf, utm_crs=utm_crs, distance=50)\n",
    "                \n",
    "#                 tensor_key = f\"{preceding_purpose}_{following_purpose}\"\n",
    "#                 close_start_trips_tensor_dict[tensor_key] = close_start_trips_tensor\n",
    "#                 close_start_trips_dict[tensor_key] = close_start_trips\n",
    "#                 close_end_trips_tensor_dict[tensor_key] = close_end_trips_tensor\n",
    "#                 close_end_trips_dict[tensor_key] = close_end_trips\n",
    "\n",
    "# all_close_start_trips_tensors = torch.cat(list(close_start_trips_tensor_dict.values()), dim=0)\n",
    "# all_close_end_trips_tensors = torch.cat(list(close_end_trips_tensor_dict.values()), dim=0)\n",
    "\n",
    "# for key, tensor in close_start_trips_tensor_dict.items():\n",
    "#     print(f\"Size of tensor for {key}: {tensor.size()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # DEAL WITH HOMES\n",
    "\n",
    "# close_homes_count_normal = compute_close_homes(links_gdf_input = links_gdf_final, information_gdf_input = persons_with_geospatial_information, utm_crs = utm_crs)\n",
    "# links_gdf_final['close_homes_count'] = close_homes_count_normal\n",
    "# close_homes_tensor = process_close_count_to_tensor(close_homes_count_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # DEAL WITH ACTIVITIES\n",
    "\n",
    "# activities_with_socio = activities_gdf.merge(persons_with_geospatial_information[['household_id', 'socioprofessional_class']], on='household_id', how='left')\n",
    "# grouped_activities = activities_with_socio.groupby('purpose')\n",
    "# activities_by_purpose = {purpose: group.reset_index(drop=True) for purpose, group in grouped_activities}\n",
    "# activities_by_purpose_tensor = {}\n",
    "# for purpose, activities in activities_by_purpose.items():\n",
    "#     close_activities_count_purpose = f\"close_activities_count_{purpose}\"\n",
    "#     close_activity_count = compute_close_homes(links_gdf_input=links_gdf_final, information_gdf_input=activities, utm_crs=utm_crs)\n",
    "#     links_gdf_final[close_activities_count_purpose] = close_activity_count\n",
    "#     activities_by_purpose_tensor[purpose] = process_close_count_to_tensor(close_activity_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deal with districts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of district_centroids_tensor: torch.Size([31216, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "# DISTRICT CENTROIDS\n",
    "\n",
    "centroid_distances = np.array([\n",
    "    process_centroid(geom_list)\n",
    "    for geom_list in links_gdf_final['district_centroid']\n",
    "])\n",
    "\n",
    "# Process the centroids\n",
    "centroid_distance_with_coordinates = np.array([\n",
    "    extract_point_coordinates(geom_list)\n",
    "    for geom_list in centroid_distances\n",
    "])\n",
    "district_centroids_tensor = torch.tensor(centroid_distance_with_coordinates, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of district_perimeters_tensor: torch.Size([31216, 2])\n",
      "Shape of district_surfaces_tensor: torch.Size([31216, 2])\n"
     ]
    }
   ],
   "source": [
    "# DISTRICT PERIMETER AND SURFACE\n",
    "\n",
    "district_perimeters = np.array([\n",
    "    process_value_list(perimeter_list)\n",
    "    for perimeter_list in links_gdf_final['district_perimeter']\n",
    "])\n",
    "district_surfaces = np.array([\n",
    "    process_value_list(surface_list)\n",
    "    for surface_list in links_gdf_final['district_surface']\n",
    "])\n",
    "\n",
    "district_perimeters_tensor = torch.tensor(district_perimeters, dtype=torch.float)\n",
    "district_surfaces_tensor = torch.tensor(district_surfaces, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Column not found: close_homes_count'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# DISTRICT HOME COUNTS \u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m district_home_counts \u001b[38;5;241m=\u001b[39m \u001b[43mlinks_gdf_final\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdistrict\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mclose_homes_count\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_district_2_information_counts\u001b[39m(district_activities_counts):\n\u001b[1;32m      6\u001b[0m     district_2_activities_counts \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[0;32m~/anaconda3/envs/Paris_Analysis/lib/python3.10/site-packages/pandas/core/groupby/generic.py:1538\u001b[0m, in \u001b[0;36mDataFrameGroupBy.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(key) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;66;03m# if len == 1, then it becomes a SeriesGroupBy and this is actually\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m     \u001b[38;5;66;03m# valid syntax, so don't raise warning\u001b[39;00m\n\u001b[1;32m   1532\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   1533\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIndexing with multiple keys (implicitly converted to a tuple \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1534\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mof keys) will be deprecated, use a list instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1535\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m   1536\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m   1537\u001b[0m     )\n\u001b[0;32m-> 1538\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getitem__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/Paris_Analysis/lib/python3.10/site-packages/pandas/core/base.py:232\u001b[0m, in \u001b[0;36mSelectionMixin.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    231\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj:\n\u001b[0;32m--> 232\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mColumn not found: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    233\u001b[0m     subset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj[key]\n\u001b[1;32m    234\u001b[0m     ndim \u001b[38;5;241m=\u001b[39m subset\u001b[38;5;241m.\u001b[39mndim\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Column not found: close_homes_count'"
     ]
    }
   ],
   "source": [
    "# DISTRICT HOME COUNTS \n",
    "\n",
    "district_home_counts = links_gdf_final.groupby('district')['close_homes_count']\n",
    "\n",
    "def compute_district_2_information_counts(district_activities_counts):\n",
    "    district_2_activities_counts = {}\n",
    "    for district, count in district_activities_counts:\n",
    "        total_counts = 0\n",
    "        total_distributions = []\n",
    "        for c in count:\n",
    "            total_counts += c[0]\n",
    "            if c[1] is not None and len(c[1]) > 0:\n",
    "                total_distributions.extend(c[1])\n",
    "        print(f\"District {district}\")\n",
    "        print(f\"Total counts: {total_counts}\")\n",
    "        distribution_counts = [total_distributions.count(i) for i in range(2, 9)]   \n",
    "        print(f\"Distributions shape: {distribution_counts}\")\n",
    "        district_2_activities_counts[district] = distribution_counts\n",
    "    return district_2_activities_counts, distribution_counts\n",
    "\n",
    "\n",
    "def compute_district_2_information_tensor(district_2_home_counts, distribution_counts):\n",
    "    district_home_counts_tensor = torch.zeros((len(links_gdf_final), len(distribution_counts)), dtype=torch.float)\n",
    "    for idx, row in links_gdf_final.iterrows():\n",
    "        district = row['district']\n",
    "        if district in district_2_home_counts:\n",
    "            district_home_counts_tensor[idx] = torch.tensor(district_2_home_counts[district], dtype=torch.float)\n",
    "    return district_home_counts_tensor\n",
    "\n",
    "district_2_home_counts, distribution_counts = compute_district_2_information_counts(district_home_counts)\n",
    "district_home_counts_tensor = compute_district_2_information_tensor(district_2_home_counts, distribution_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'distribution_counts' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 22\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m purpose \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124meducation\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mshop\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mleisure\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mother\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhome\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwork\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[1;32m     21\u001b[0m     district_activities_counts \u001b[38;5;241m=\u001b[39m links_gdf\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdistrict\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclose_activities_count_\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m purpose]\n\u001b[0;32m---> 22\u001b[0m     district_2_activities_counts, distribution_counts \u001b[38;5;241m=\u001b[39m \u001b[43mget_district_2_information_counts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdistrict_activities_counts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m     district_activities_counts_tensor[purpose] \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros((\u001b[38;5;28mlen\u001b[39m(links_gdf), \u001b[38;5;28mlen\u001b[39m(distribution_counts)), dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat)\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m idx, row \u001b[38;5;129;01min\u001b[39;00m links_gdf\u001b[38;5;241m.\u001b[39miterrows():\n",
      "Cell \u001b[0;32mIn[19], line 18\u001b[0m, in \u001b[0;36mget_district_2_information_counts\u001b[0;34m(district_activities_counts)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDistributions shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdistribution_counts\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     17\u001b[0m     district_2_activities_counts[district] \u001b[38;5;241m=\u001b[39m distribution_counts\n\u001b[0;32m---> 18\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m district_2_activities_counts, \u001b[43mdistribution_counts\u001b[49m\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'distribution_counts' referenced before assignment"
     ]
    }
   ],
   "source": [
    "# DISTRICT ACTIVITIES COUNTS\n",
    "\n",
    "district_activities_counts_tensor = {}\n",
    "for purpose in grouped_activities.keys():\n",
    "    district_activities_counts = links_gdf_final.groupby('district')['close_activities_count_' + purpose]\n",
    "    district_2_activities_counts, distribution_counts = compute_district_2_information_counts(district_activities_counts)\n",
    "    district_activities_counts_tensor[purpose] = compute_district_2_information_tensor(district_activities_counts_tensor, purpose, district_2_activities_counts, distribution_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DISTRICT TRIPS START AND END\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 entries of start_points_tensor: tensor([[ 2.3387, 48.8518],\n",
      "        [ 2.3387, 48.8524],\n",
      "        [ 2.3387, 48.8523],\n",
      "        [ 2.3399, 48.8520],\n",
      "        [ 2.3399, 48.8518]])\n",
      "First 5 entries of end_points_tensor: tensor([[ 2.3385, 48.8518],\n",
      "        [ 2.3387, 48.8523],\n",
      "        [ 2.3387, 48.8524],\n",
      "        [ 2.3399, 48.8518],\n",
      "        [ 2.3391, 48.8515]])\n",
      "First 5 entries of edge_positions_tensor: tensor([[ 2.3386, 48.8518],\n",
      "        [ 2.3387, 48.8524],\n",
      "        [ 2.3387, 48.8524],\n",
      "        [ 2.3399, 48.8519],\n",
      "        [ 2.3395, 48.8517]])\n",
      "First 5 entries of edge_start_end_tensor: tensor([[[ 2.3387, 48.8518],\n",
      "         [ 2.3385, 48.8518]],\n",
      "\n",
      "        [[ 2.3387, 48.8524],\n",
      "         [ 2.3387, 48.8523]],\n",
      "\n",
      "        [[ 2.3387, 48.8523],\n",
      "         [ 2.3387, 48.8524]],\n",
      "\n",
      "        [[ 2.3399, 48.8520],\n",
      "         [ 2.3399, 48.8518]],\n",
      "\n",
      "        [[ 2.3399, 48.8518],\n",
      "         [ 2.3391, 48.8515]]])\n"
     ]
    }
   ],
   "source": [
    "# PROCESS LINK GEOMETRIES\n",
    "\n",
    "edge_midpoints = np.array([((geom.coords[0][0] + geom.coords[-1][0]) / 2, \n",
    "                                    (geom.coords[0][1] + geom.coords[-1][1]) / 2) \n",
    "                                for geom in links_gdf_final.geometry])\n",
    "\n",
    "nodes = pd.concat([links_gdf_final['from_node'], links_gdf_final['to_node']]).unique()\n",
    "node_to_idx = {node: idx for idx, node in enumerate(nodes)}\n",
    "links_gdf_final['from_idx'] = links_gdf_final['from_node'].map(node_to_idx)\n",
    "links_gdf_final['to_idx'] = links_gdf_final['to_node'].map(node_to_idx)\n",
    "edges_base = links_gdf_final[['from_idx', 'to_idx']].values\n",
    "edge_midpoint_tensor = torch.tensor(edge_midpoints, dtype=torch.float)\n",
    "\n",
    "# Initialize start and end points\n",
    "start_points = np.array([geom.coords[0] for geom in links_gdf_final.geometry])\n",
    "end_points = np.array([geom.coords[-1] for geom in links_gdf_final.geometry])\n",
    "\n",
    "# Convert to tensors\n",
    "edge_start_point_tensor = torch.tensor(start_points, dtype=torch.float)\n",
    "edge_end_point_tensor = torch.tensor(end_points, dtype=torch.float)\n",
    "\n",
    "edge_start_end_tensor = torch.stack((edge_start_point_tensor, edge_end_point_tensor), dim=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze results and plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pio.analyze_geodataframes(result_dic=result_dic, consider_only_highway_edges=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pio.analyze_geodataframes(result_dic=result_dic, consider_only_highway_edges=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31216, 28)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'close_homes_tensor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 95\u001b[0m\n\u001b[1;32m     92\u001b[0m     data_dict_list \u001b[38;5;241m=\u001b[39m [{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m'\u001b[39m: lg_data\u001b[38;5;241m.\u001b[39mx, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124medge_index\u001b[39m\u001b[38;5;124m'\u001b[39m: lg_data\u001b[38;5;241m.\u001b[39medge_index, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpos\u001b[39m\u001b[38;5;124m'\u001b[39m: lg_data\u001b[38;5;241m.\u001b[39mpos, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m: lg_data\u001b[38;5;241m.\u001b[39my, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgraph_attr\u001b[39m\u001b[38;5;124m'\u001b[39m: lg_data\u001b[38;5;241m.\u001b[39mmode_stats} \u001b[38;5;28;01mfor\u001b[39;00m lg_data \u001b[38;5;129;01min\u001b[39;00m datalist]\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m data_dict_list\n\u001b[0;32m---> 95\u001b[0m data_processed \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_result_dic\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult_dic\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresult_dic_output_links\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresult_dic_mode_stats\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresult_dic_mode_stats\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m torch\u001b[38;5;241m.\u001b[39msave(data_processed, result_path)\n",
      "Cell \u001b[0;32mIn[8], line 11\u001b[0m, in \u001b[0;36mprocess_result_dic\u001b[0;34m(result_dic, result_dic_mode_stats)\u001b[0m\n\u001b[1;32m      9\u001b[0m freespeed_base_case \u001b[38;5;241m=\u001b[39m base_network_no_policies[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfreespeed\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues\n\u001b[1;32m     10\u001b[0m modes_base_case \u001b[38;5;241m=\u001b[39m encode_modes(base_network_no_policies)\n\u001b[0;32m---> 11\u001b[0m close_homes \u001b[38;5;241m=\u001b[39m \u001b[43mclose_homes_tensor\u001b[49m\u001b[38;5;241m.\u001b[39mto_dense()\n\u001b[1;32m     12\u001b[0m activities_home \u001b[38;5;241m=\u001b[39m activities_by_purpose_tensor[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhome\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto_dense()\n\u001b[1;32m     13\u001b[0m activities_work \u001b[38;5;241m=\u001b[39m activities_by_purpose_tensor[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwork\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto_dense()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'close_homes_tensor' is not defined"
     ]
    }
   ],
   "source": [
    "def process_result_dic(result_dic, result_dic_mode_stats):\n",
    "    datalist = []\n",
    "    linegraph_transformation = LineGraph()\n",
    "    \n",
    "    edge_start_point_tensor = edge_start_point_tensor.to_dense()\n",
    "    edge_end_point_tensor = edge_end_point_tensor.to_dense()\n",
    "    edge_start_end_point_tensor = edge_start_end_tensor.to_dense()\n",
    "    edge_midpoint_tensor = edge_midpoint_tensor.to_dense()\n",
    "    \n",
    "    base_network_no_policies = result_dic.get(\"base_network_no_policies\")\n",
    "    vol_base_case = base_network_no_policies['vol_car'].values\n",
    "    capacity_base_case = base_network_no_policies['capacity'].values\n",
    "    length_base_case = base_network_no_policies['length'].values\n",
    "    freespeed_base_case = base_network_no_policies['freespeed'].values\n",
    "    modes_base_case = encode_modes(base_network_no_policies)\n",
    "    close_homes = close_homes_tensor.to_dense()\n",
    "    activities_home = activities_by_purpose_tensor['home'].to_dense()\n",
    "    activities_work = activities_by_purpose_tensor['work'].to_dense()\n",
    "    activities_education = activities_by_purpose_tensor['education'].to_dense()\n",
    "    activities_shop = activities_by_purpose_tensor['shop'].to_dense()\n",
    "    activities_leisure = activities_by_purpose_tensor['leisure'].to_dense()\n",
    "    activities_other = activities_by_purpose_tensor['other'].to_dense()\n",
    "    # close_start_trips_tensor = all_close_start_trips_tensors.to_dense()\n",
    "    # close_end_trips_tensor = all_close_end_trips_tensors.to_dense()\n",
    "    \n",
    "    district_centroids = district_centroids_tensor.to_dense()\n",
    "    district_perimeters = district_perimeters_tensor.to_dense()\n",
    "    district_surfaces = district_surfaces_tensor.to_dense()\n",
    "    district_home_counts = district_home_counts_tensor.to_dense()\n",
    "    district_activities_home = district_activities_counts_tensor['home'].to_dense()\n",
    "    district_activities_work = district_activities_counts_tensor['work'].to_dense()\n",
    "    district_activities_education = district_activities_counts_tensor['education'].to_dense()\n",
    "    district_activities_shop = district_activities_counts_tensor['shop'].to_dense()\n",
    "    district_activities_leisure = district_activities_counts_tensor['leisure'].to_dense()\n",
    "    district_activities_other = district_activities_counts_tensor['other'].to_dense()\n",
    "    \n",
    "    \n",
    "    edge_index = torch.tensor(edges_base, dtype=torch.long).t().contiguous()\n",
    "    x = torch.zeros((len(nodes), 1), dtype=torch.float)\n",
    "    data = Data(edge_index=edge_index, x=x)\n",
    "    # data = Data(edge_index=edge_index, x=x, pos=edge_positions_tensor)\n",
    "    linegraph_data = linegraph_transformation(data)\n",
    "\n",
    "    for key, df in tqdm(result_dic.items(), desc=\"Processing result_dic\", unit=\"dataframe\"):        \n",
    "        if isinstance(df, pd.DataFrame) and key != \"base_network_no_policies\":\n",
    "            gdf = gpd.GeoDataFrame(df, geometry='geometry')\n",
    "            gdf.crs = \"EPSG:2154\"  \n",
    "            gdf.to_crs(\"EPSG:4326\", inplace=True)\n",
    "            capacities_new = gdf['capacity'].values\n",
    "            capacity_reduction = capacities_new - capacity_base_case\n",
    "            highway = gdf['highway'].apply(lambda x: highway_mapping.get(x, -1)).values\n",
    "            length = gdf['length'].values\n",
    "            freespeed= gdf['freespeed'].values\n",
    "            modes = encode_modes(gdf)\n",
    "    \n",
    "            edge_car_volume_difference = gdf['vol_car'].values - vol_base_case\n",
    "            target_values = torch.tensor(edge_car_volume_difference, dtype=torch.float).unsqueeze(1)\n",
    "\n",
    "            linegraph_x = torch.tensor(np.column_stack((vol_base_case, capacity_base_case, capacities_new, capacity_reduction, \n",
    "                                                        highway, length, freespeed, length_base_case, freespeed_base_case, \n",
    "                                                        modes, modes_base_case, close_homes, \n",
    "                                                        activities_home, activities_work, activities_education, activities_shop, activities_leisure, activities_other,\n",
    "                                                        # close_start_trips_tensor, close_end_trips_tensor,\n",
    "                                                        district_perimeters,\n",
    "                                                        district_surfaces,\n",
    "                                                        district_home_counts,\n",
    "                                                        district_activities_home,\n",
    "                                                        district_activities_work,\n",
    "                                                        district_activities_education,\n",
    "                                                        district_activities_shop,\n",
    "                                                        district_activities_leisure,\n",
    "                                                        district_activities_other\n",
    "                                                        )), dtype=torch.float)\n",
    "            linegraph_pos = torch.tensor(np.column_stack(edge_start_end_point_tensor, edge_start_point_tensor, edge_end_point_tensor, edge_midpoint_tensor, district_centroids), dtype=torch.float)\n",
    "            linegraph_data.x = linegraph_x\n",
    "            linegraph_data.pos = linegraph_pos\n",
    "            linegraph_data.y = target_values\n",
    "            \n",
    "            df_mode_stats = result_dic_mode_stats.get(key)\n",
    "            if df_mode_stats is not None:\n",
    "                numeric_cols = df_mode_stats.select_dtypes(include=[np.number]).columns\n",
    "                mode_stats_numeric = df_mode_stats[numeric_cols].astype(float)\n",
    "                mode_stats_tensor = torch.tensor(mode_stats_numeric.values, dtype=torch.float)\n",
    "                linegraph_data.mode_stats = mode_stats_tensor\n",
    "            if linegraph_data.validate(raise_on_error=True):\n",
    "                datalist.append(linegraph_data)\n",
    "            else:\n",
    "                print(\"Invalid line graph data\")\n",
    "    data_dict_list = [{'x': lg_data.x, 'edge_index': lg_data.edge_index, 'pos': lg_data.pos, 'y': lg_data.y, 'graph_attr': lg_data.mode_stats} for lg_data in datalist]\n",
    "    return data_dict_list\n",
    "\n",
    "data_processed = process_result_dic(result_dic=result_dic_output_links, result_dic_mode_stats=result_dic_mode_stats)\n",
    "torch.save(data_processed, result_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': tensor([[6.6275e+00, 4.8000e+02, 4.8000e+02,  ..., 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00],\n",
       "         [9.6078e+00, 4.8000e+02, 4.8000e+02,  ..., 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00],\n",
       "         [2.4902e+00, 9.6000e+02, 9.6000e+02,  ..., 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00],\n",
       "         ...,\n",
       "         [0.0000e+00, 7.9992e+03, 7.9992e+03,  ..., 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00],\n",
       "         [0.0000e+00, 7.9992e+03, 7.9992e+03,  ..., 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00],\n",
       "         [0.0000e+00, 7.9992e+03, 7.9992e+03,  ..., 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00]]),\n",
       " 'edge_index': tensor([[    0,     1,     1,  ..., 31138, 31139, 31139],\n",
       "         [   19, 10935, 10936,  ..., 30278, 31138, 31139]]),\n",
       " 'pos': tensor([[-1.3631, -5.9836],\n",
       "         [-1.3631, -5.9836],\n",
       "         [-1.3631, -5.9836],\n",
       "         ...,\n",
       "         [-1.3631, -5.9836],\n",
       "         [-1.3631, -5.9836],\n",
       "         [-1.3631, -5.9836]]),\n",
       " 'y': tensor([[ 1.3725],\n",
       "         [-0.6078],\n",
       "         [ 1.5098],\n",
       "         ...,\n",
       "         [ 0.0000],\n",
       "         [ 0.0000],\n",
       "         [ 0.0000]]),\n",
       " 'graph_attr': tensor([[1.1676e+03, 3.6210e+03],\n",
       "         [1.2798e+03, 4.8323e+03],\n",
       "         [4.3310e+02, 4.3941e+03],\n",
       "         [7.8911e-01, 1.0581e+03],\n",
       "         [1.6101e+03, 5.4772e+03],\n",
       "         [1.0168e+03, 1.2207e+03]])}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_processed[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save for further processing with GNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_processed_single_districts = pio.process_result_dic(result_dic_single_districts)\n",
    "# torch.save(data_processed_single_districts, result_path + '_single_districts.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(data_processed, result_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.scatter(persons_with_homes.geometry.x, persons_with_homes.geometry.y, s=1, color='blue', alpha=0.5)\n",
    "# plt.scatter(persons_with_home_within_linear_ring.geometry.x, persons_with_home_within_linear_ring.geometry.y, s=1, color='red', alpha=0.5)\n",
    "# plt.title('Locations of Persons with Homes')\n",
    "# plt.xlabel('Longitude')\n",
    "# plt.ylabel('Latitude')\n",
    "# plt.show()\n",
    "\n",
    "# from shapely.geometry import LineString\n",
    "# from shapely.geometry import MultiPolygon\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Create a LineString\n",
    "# line = LineString([(10, 10), (20, 10)])\n",
    "\n",
    "# # Create a buffer around the line\n",
    "# buffered_line = line.buffer(2, cap_style=\"round\")\n",
    "\n",
    "# # Plot the original line and the buffered area\n",
    "# plt.figure(figsize=(8, 6))\n",
    "# x, y = line.xy\n",
    "# plt.plot(x, y, color='blue', label='Original Line')\n",
    "# if isinstance(buffered_line, MultiPolygon):\n",
    "#     for polygon in buffered_line:\n",
    "#         x, y = polygon.exterior.xy\n",
    "#         plt.fill(x, y, alpha=0.5, color='lightblue', label='Buffered Area')\n",
    "# else:\n",
    "#     x, y = buffered_line.exterior.xy\n",
    "#     plt.fill(x, y, alpha=0.5, color='lightblue', label='Buffered Area')\n",
    "\n",
    "# plt.title('Line with Buffered Area')\n",
    "# plt.xlabel('X-axis')\n",
    "# plt.ylabel('Y-axis')\n",
    "# plt.legend()\n",
    "# plt.grid()\n",
    "# plt.axis('equal')\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "# def check_trips_equivalence(close_trips_start, close_trips_end):\n",
    "#     \"\"\"\n",
    "#     Check if close_trips_start and close_trips_end are equivalent.\n",
    "    \n",
    "#     Args:\n",
    "#     close_trips_start (list): List of tuples for start trips\n",
    "#     close_trips_end (list): List of tuples for end trips\n",
    "    \n",
    "#     Returns:\n",
    "#     bool: True if equivalent, False otherwise\n",
    "#     \"\"\"\n",
    "#     if len(close_trips_start) != len(close_trips_end):\n",
    "#         print(\"Lists have different lengths.\")\n",
    "#         return False\n",
    "    \n",
    "#     differences = []\n",
    "#     for i, (start, end) in enumerate(zip(close_trips_start, close_trips_end)):\n",
    "#         if start != end:\n",
    "#             differences.append((i, start, end))\n",
    "    \n",
    "#     if not differences:\n",
    "#         print(\"The lists are identical.\")\n",
    "#         return True\n",
    "#     else:\n",
    "#         print(f\"Found {len(differences)} differences:\")\n",
    "#         for diff in differences[:10]:  # Print first 10 differences\n",
    "#             print(f\"Index {diff[0]}: Start {diff[1]}, End {diff[2]}\")\n",
    "#         if len(differences) > 10:\n",
    "#             print(f\"... and {len(differences) - 10} more differences.\")\n",
    "#         return False\n",
    "\n",
    "# # Usage\n",
    "# are_equivalent = check_trips_equivalence(close_trips_start, close_trips_end)\n",
    "# print(f\"Are the trip lists equivalent? {are_equivalent}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Paris_Analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
