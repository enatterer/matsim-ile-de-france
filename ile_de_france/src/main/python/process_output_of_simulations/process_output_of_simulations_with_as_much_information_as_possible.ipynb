{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import math\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import torch\n",
    "\n",
    "import processing_io as pio\n",
    "from torch_geometric.transforms import LineGraph\n",
    "\n",
    "from torch_geometric.data import Data, Batch\n",
    "\n",
    "highway_mapping = {\n",
    "    'trunk': 0, 'trunk_link': 0, 'motorway_link': 0,\n",
    "    'primary': 1, 'primary_link': 1,\n",
    "    'secondary': 2, 'secondary_link': 2,\n",
    "    'tertiary': 3, 'tertiary_link': 3,\n",
    "    'residential': 4, 'living_street': 5,\n",
    "    'pedestrian': 6, 'service': 7,\n",
    "    'construction': 8, 'unclassified': 9,\n",
    "    'np.nan': -1\n",
    "}\n",
    "\n",
    "result_df_name = 'dataset_1pm_capacity_reduction'\n",
    "\n",
    "result_path = '../../../../data/datasets_simulation_outputs/' + result_df_name + '.pt'\n",
    "string_is_for_1pm = \"pop_1pm\"\n",
    "\n",
    "base_dir = '../../../../data/' + string_is_for_1pm + '_simulations/' + string_is_for_1pm + '_policies_combinations_with_normal_dist/'\n",
    "subdirs_pattern = os.path.join(base_dir, 'output_networks_*')\n",
    "subdirs = list(set(glob.glob(subdirs_pattern)))\n",
    "subdirs.sort()\n",
    "\n",
    "gdf_basecase_mean = gpd.read_file('results/gdf_' + string_is_for_1pm + '_basecase_mean.geojson')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process results\n",
    "\n",
    "Process the outputs of the simulations for further usage by GNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accessing folder: ../../../../data/pop_1pm_simulations/pop_1pm_policies_combinations_with_normal_dist/output_networks_5000\n",
      "100\n",
      "100\n",
      "../../../../data/pop_1pm_simulations/pop_1pm_policies_combinations_with_normal_dist/output_networks_5000/network_d_4_7_8_13_19\n",
      "Policy introduced in Arrondissement(s) d, 4, 7, 8, 13, 19\n"
     ]
    }
   ],
   "source": [
    "# Read all network data into a dictionary of GeoDataFrames\n",
    "result_dic = {}\n",
    "base_network_no_policies = gdf_basecase_mean\n",
    "result_dic[\"base_network_no_policies\"] = base_network_no_policies\n",
    "counter =0\n",
    "\n",
    "# Loop through each subdirectory\n",
    "for subdir in subdirs:\n",
    "    print(f'Accessing folder: {subdir}')\n",
    "    print(len(os.listdir(subdir)))\n",
    "    networks = [network for network in os.listdir(subdir) if not network.endswith(\".DS_Store\")]\n",
    "    print(len(networks))\n",
    "\n",
    "    for network in networks:\n",
    "        file_path = os.path.join(subdir, network)\n",
    "        policy_key = pio.create_policy_key_1pm(network)\n",
    "        print(file_path)\n",
    "        print(policy_key)\n",
    "        gdf = pio.read_output_links(file_path)\n",
    "        \n",
    "        if (gdf is not None):\n",
    "            gdf_extended = pio.extend_geodataframe(gdf_base=gdf_basecase_mean, gdf_to_extend=gdf, column_to_extend='highway', new_column_name='highway')\n",
    "            gdf_extended = pio.extend_geodataframe(gdf_base=gdf_basecase_mean, gdf_to_extend=gdf_extended, column_to_extend='vol_car', new_column_name='vol_car_base_case')\n",
    "            result_dic[policy_key] = gdf_extended\n",
    "        break\n",
    "    break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze results and plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy: Policy introduced in Arrondissement(s) d, 4, 7, 8, 13, 19\n",
      "Total change in 'vol_car': 0.56%\n",
      "Total change in capacity (car edges): -12.11%\n"
     ]
    }
   ],
   "source": [
    "# pio.analyze_geodataframes(result_dic=result_dic, consider_only_highway_edges=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy: Policy introduced in Arrondissement(s) d, 4, 7, 8, 13, 19\n",
      "Total change in 'vol_car': 0.96%\n",
      "Total change in capacity (car edges): -4.19%\n"
     ]
    }
   ],
   "source": [
    "pio.analyze_geodataframes(result_dic=result_dic, consider_only_highway_edges=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_result_dic(result_dic):\n",
    "    datalist = []\n",
    "    linegraph_transformation = LineGraph()\n",
    "    base_network_no_policies = result_dic.get(\"base_network_no_policies\")\n",
    "    vol_base_case = base_network_no_policies['vol_car'].values\n",
    "    capacity_base_case = base_network_no_policies['capacity'].values\n",
    "    \n",
    "    # Initialize base edge positions\n",
    "    gdf_base = gpd.GeoDataFrame(base_network_no_policies, geometry='geometry')\n",
    "    gdf_base.crs = \"EPSG:2154\"  # Assuming the original CRS is EPSG:2154\n",
    "    gdf_base.to_crs(\"EPSG:4326\", inplace=True)\n",
    "    edge_positions_base = np.array([((geom.coords[0][0] + geom.coords[-1][0]) / 2, \n",
    "                                     (geom.coords[0][1] + geom.coords[-1][1]) / 2) \n",
    "                                    for geom in gdf_base.geometry])\n",
    "    \n",
    "    nodes = pd.concat([gdf_base['from_node'], gdf_base['to_node']]).unique()\n",
    "    node_to_idx = {node: idx for idx, node in enumerate(nodes)}\n",
    "    gdf_base['from_idx'] = gdf_base['from_node'].map(node_to_idx)\n",
    "    gdf_base['to_idx'] = gdf_base['to_node'].map(node_to_idx)\n",
    "    edges_base = gdf_base[['from_idx', 'to_idx']].values\n",
    "    edge_positions_tensor = torch.tensor(edge_positions_base, dtype=torch.float)\n",
    "    edge_index = torch.tensor(edges_base, dtype=torch.long).t().contiguous()\n",
    "    x = torch.zeros((len(nodes), 1), dtype=torch.float)\n",
    "    data = Data(edge_index=edge_index, x=x, pos=edge_positions_tensor)\n",
    "    linegraph_data = linegraph_transformation(data)\n",
    "\n",
    "    for key, df in result_dic.items():        \n",
    "        if isinstance(df, pd.DataFrame) and key != \"base_network_no_policies\":\n",
    "            gdf = gpd.GeoDataFrame(df, geometry='geometry')\n",
    "            gdf.crs = \"EPSG:2154\"  # Assuming the original CRS is EPSG:2154\n",
    "            gdf.to_crs(\"EPSG:4326\", inplace=True)\n",
    "\n",
    "            capacities_new = gdf['capacity'].values\n",
    "            capacity_reduction = capacities_new - capacity_base_case\n",
    "            \n",
    "            highway = gdf['highway'].apply(lambda x: highway_mapping.get(x, -1)).values\n",
    "            edge_car_volume_difference = gdf['vol_car'].values - vol_base_case\n",
    "            target_values = torch.tensor(edge_car_volume_difference, dtype=torch.float).unsqueeze(1)\n",
    "\n",
    "            # Transform to line graph\n",
    "            linegraph_x = torch.tensor(np.column_stack((vol_base_case, capacity_base_case, capacities_new, capacity_reduction, highway)), dtype=torch.float)\n",
    "            linegraph_data.x = linegraph_x\n",
    "            \n",
    "            # Target tensor for car volumes\n",
    "            linegraph_data.y = target_values\n",
    "            if linegraph_data.validate(raise_on_error=True):\n",
    "                datalist.append(linegraph_data)\n",
    "            else:\n",
    "                print(\"Invalid line graph data\")\n",
    "                \n",
    "    # Convert dataset to a list of dictionaries\n",
    "    data_dict_list = [{'x': lg_data.x, 'edge_index': lg_data.edge_index, 'pos': lg_data.pos, 'y': lg_data.y} for lg_data in datalist]\n",
    "    return data_dict_list"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save for further processing with GNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_processed = process_result_dic(result_dic)\n",
    "# data_processed_single_districts = pio.process_result_dic(result_dic_single_districts)\n",
    "# torch.save(data_processed_single_districts, result_path + '_single_districts.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(data_processed, result_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Paris_Analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
