{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import math\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import torch\n",
    "\n",
    "import processing_io as pio\n",
    "from torch_geometric.transforms import LineGraph\n",
    "\n",
    "from torch_geometric.data import Data, Batch\n",
    "import shapely.wkt as wkt\n",
    "\n",
    "\n",
    "highway_mapping = {\n",
    "    'trunk': 0, 'trunk_link': 0, 'motorway_link': 0,\n",
    "    'primary': 1, 'primary_link': 1,\n",
    "    'secondary': 2, 'secondary_link': 2,\n",
    "    'tertiary': 3, 'tertiary_link': 3,\n",
    "    'residential': 4, 'living_street': 5,\n",
    "    'pedestrian': 6, 'service': 7,\n",
    "    'construction': 8, 'unclassified': 9,\n",
    "    'np.nan': -1\n",
    "}\n",
    "\n",
    "result_df_name = 'sim_output_1pm_capacity_reduction_10k_PRELIMINARY'\n",
    "\n",
    "result_path = '../../../../data/datasets_simulation_outputs/' + result_df_name + '.pt'\n",
    "string_is_for_1pm = \"pop_1pm\"\n",
    "\n",
    "base_dir = '../../../../data/' + string_is_for_1pm + '_simulations/' + string_is_for_1pm + '_policies_combinations_with_normal_dist/'\n",
    "subdirs_pattern = os.path.join(base_dir, 'output_networks_*')\n",
    "subdirs = list(set(glob.glob(subdirs_pattern)))\n",
    "subdirs.sort()\n",
    "\n",
    "gdf_basecase_output_links = gpd.read_file('results/' + string_is_for_1pm + '_basecase_average_output_links.geojson')\n",
    "gdf_basecase_average_mode_stats = pd.read_csv('results/' + string_is_for_1pm + '_basecase_average_mode_stats.csv', delimiter=';')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process results\n",
    "\n",
    "Process the outputs of the simulations for further usage by GNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accessing folder: ../../../../data/pop_1pm_simulations/pop_1pm_policies_combinations_with_normal_dist/output_networks_100\n",
      "78\n",
      "Accessing folder: ../../../../data/pop_1pm_simulations/pop_1pm_policies_combinations_with_normal_dist/output_networks_1000\n",
      "98\n",
      "Accessing folder: ../../../../data/pop_1pm_simulations/pop_1pm_policies_combinations_with_normal_dist/output_networks_1100\n",
      "99\n",
      "Accessing folder: ../../../../data/pop_1pm_simulations/pop_1pm_policies_combinations_with_normal_dist/output_networks_1200\n",
      "99\n",
      "Accessing folder: ../../../../data/pop_1pm_simulations/pop_1pm_policies_combinations_with_normal_dist/output_networks_1300\n",
      "100\n",
      "Accessing folder: ../../../../data/pop_1pm_simulations/pop_1pm_policies_combinations_with_normal_dist/output_networks_1400\n",
      "99\n",
      "Accessing folder: ../../../../data/pop_1pm_simulations/pop_1pm_policies_combinations_with_normal_dist/output_networks_1500\n",
      "99\n",
      "Accessing folder: ../../../../data/pop_1pm_simulations/pop_1pm_policies_combinations_with_normal_dist/output_networks_1600\n",
      "99\n",
      "Accessing folder: ../../../../data/pop_1pm_simulations/pop_1pm_policies_combinations_with_normal_dist/output_networks_1700\n",
      "99\n",
      "Accessing folder: ../../../../data/pop_1pm_simulations/pop_1pm_policies_combinations_with_normal_dist/output_networks_1800\n",
      "96\n",
      "Accessing folder: ../../../../data/pop_1pm_simulations/pop_1pm_policies_combinations_with_normal_dist/output_networks_1900\n",
      "100\n",
      "Accessing folder: ../../../../data/pop_1pm_simulations/pop_1pm_policies_combinations_with_normal_dist/output_networks_200\n",
      "100\n",
      "Accessing folder: ../../../../data/pop_1pm_simulations/pop_1pm_policies_combinations_with_normal_dist/output_networks_300\n",
      "99\n",
      "Accessing folder: ../../../../data/pop_1pm_simulations/pop_1pm_policies_combinations_with_normal_dist/output_networks_400\n",
      "100\n",
      "Accessing folder: ../../../../data/pop_1pm_simulations/pop_1pm_policies_combinations_with_normal_dist/output_networks_500\n",
      "100\n",
      "Accessing folder: ../../../../data/pop_1pm_simulations/pop_1pm_policies_combinations_with_normal_dist/output_networks_5000\n",
      "100\n",
      "Accessing folder: ../../../../data/pop_1pm_simulations/pop_1pm_policies_combinations_with_normal_dist/output_networks_5100\n",
      "100\n",
      "Accessing folder: ../../../../data/pop_1pm_simulations/pop_1pm_policies_combinations_with_normal_dist/output_networks_5200\n",
      "100\n",
      "Accessing folder: ../../../../data/pop_1pm_simulations/pop_1pm_policies_combinations_with_normal_dist/output_networks_5300\n",
      "100\n",
      "Accessing folder: ../../../../data/pop_1pm_simulations/pop_1pm_policies_combinations_with_normal_dist/output_networks_5400\n",
      "100\n",
      "Accessing folder: ../../../../data/pop_1pm_simulations/pop_1pm_policies_combinations_with_normal_dist/output_networks_5500\n",
      "100\n",
      "Accessing folder: ../../../../data/pop_1pm_simulations/pop_1pm_policies_combinations_with_normal_dist/output_networks_5600\n",
      "100\n",
      "Accessing folder: ../../../../data/pop_1pm_simulations/pop_1pm_policies_combinations_with_normal_dist/output_networks_5700\n",
      "100\n",
      "Accessing folder: ../../../../data/pop_1pm_simulations/pop_1pm_policies_combinations_with_normal_dist/output_networks_5800\n",
      "100\n",
      "Accessing folder: ../../../../data/pop_1pm_simulations/pop_1pm_policies_combinations_with_normal_dist/output_networks_5900\n",
      "100\n",
      "Accessing folder: ../../../../data/pop_1pm_simulations/pop_1pm_policies_combinations_with_normal_dist/output_networks_600\n",
      "100\n",
      "Accessing folder: ../../../../data/pop_1pm_simulations/pop_1pm_policies_combinations_with_normal_dist/output_networks_6000\n",
      "100\n",
      "Accessing folder: ../../../../data/pop_1pm_simulations/pop_1pm_policies_combinations_with_normal_dist/output_networks_6100\n",
      "100\n",
      "Accessing folder: ../../../../data/pop_1pm_simulations/pop_1pm_policies_combinations_with_normal_dist/output_networks_6200\n",
      "100\n",
      "Accessing folder: ../../../../data/pop_1pm_simulations/pop_1pm_policies_combinations_with_normal_dist/output_networks_6300\n",
      "100\n",
      "Accessing folder: ../../../../data/pop_1pm_simulations/pop_1pm_policies_combinations_with_normal_dist/output_networks_6400\n",
      "100\n",
      "Accessing folder: ../../../../data/pop_1pm_simulations/pop_1pm_policies_combinations_with_normal_dist/output_networks_6500\n",
      "100\n",
      "Accessing folder: ../../../../data/pop_1pm_simulations/pop_1pm_policies_combinations_with_normal_dist/output_networks_6600\n",
      "100\n",
      "Accessing folder: ../../../../data/pop_1pm_simulations/pop_1pm_policies_combinations_with_normal_dist/output_networks_6700\n",
      "100\n",
      "Accessing folder: ../../../../data/pop_1pm_simulations/pop_1pm_policies_combinations_with_normal_dist/output_networks_6800\n",
      "100\n",
      "Accessing folder: ../../../../data/pop_1pm_simulations/pop_1pm_policies_combinations_with_normal_dist/output_networks_6900\n",
      "100\n",
      "Accessing folder: ../../../../data/pop_1pm_simulations/pop_1pm_policies_combinations_with_normal_dist/output_networks_700\n",
      "90\n",
      "Accessing folder: ../../../../data/pop_1pm_simulations/pop_1pm_policies_combinations_with_normal_dist/output_networks_800\n",
      "94\n",
      "Accessing folder: ../../../../data/pop_1pm_simulations/pop_1pm_policies_combinations_with_normal_dist/output_networks_900\n",
      "98\n"
     ]
    }
   ],
   "source": [
    "# Read all network data into a dictionary of GeoDataFrames\n",
    "result_dic = {}\n",
    "base_network_no_policies = gdf_basecase_output_links\n",
    "result_dic[\"base_network_no_policies\"] = base_network_no_policies\n",
    "counter = 0\n",
    "\n",
    "# Loop through each subdirectory\n",
    "for subdir in subdirs:\n",
    "    print(f'Accessing folder: {subdir}')\n",
    "    print(len(os.listdir(subdir)))\n",
    "    networks = [network for network in os.listdir(subdir) if not network.endswith(\".DS_Store\")]\n",
    "    for network in networks:\n",
    "        file_path = os.path.join(subdir, network)\n",
    "        policy_key = pio.create_policy_key_1pm(network)\n",
    "        gdf_output_links = pio.read_output_links(file_path)\n",
    "        if (gdf_output_links is not None):\n",
    "            gdf_extended = pio.extend_geodataframe(gdf_base=gdf_basecase_output_links, gdf_to_extend=gdf_output_links, column_to_extend='highway', new_column_name='highway')\n",
    "            gdf_extended = pio.extend_geodataframe(gdf_base=gdf_basecase_output_links, gdf_to_extend=gdf_extended, column_to_extend='vol_car', new_column_name='vol_car_base_case')\n",
    "            result_dic[policy_key] = gdf_extended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dic_mode_stats = {}\n",
    "result_dic_mode_stats[\"base_network_no_policies\"] = gdf_basecase_average_mode_stats\n",
    "counter = 0\n",
    "\n",
    "def calculate_averaged_results(trips_df):\n",
    "    \"\"\"Calculate average travel time and routed distance grouped by mode.\"\"\"\n",
    "    return trips_df.groupby('mode').agg(\n",
    "        total_travel_time=('travel_time', 'mean'),\n",
    "        total_routed_distance=('routed_distance', 'mean')\n",
    "    ).reset_index()\n",
    "\n",
    "for subdir in subdirs:\n",
    "    # print(f'Accessing folder: {subdir}')\n",
    "    # print(len(os.listdir(subdir)))\n",
    "    networks = [network for network in os.listdir(subdir) if not network.endswith(\".DS_Store\")]\n",
    "    for network in networks:\n",
    "        file_path = os.path.join(subdir, network)\n",
    "        policy_key = pio.create_policy_key_1pm(network)\n",
    "        df_mode_stats = pd.read_csv(file_path + '/eqasim_trips.csv', delimiter=';')\n",
    "        averaged_results = calculate_averaged_results(df_mode_stats)\n",
    "        if (averaged_results is not None):\n",
    "            result_dic_mode_stats[policy_key] = averaged_results\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze results and plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pio.analyze_geodataframes(result_dic=result_dic, consider_only_highway_edges=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pio.analyze_geodataframes(result_dic=result_dic, consider_only_highway_edges=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_result_dic(result_dic, result_dic_mode_stats):\n",
    "    datalist = []\n",
    "    linegraph_transformation = LineGraph()\n",
    "    base_network_no_policies = result_dic.get(\"base_network_no_policies\")\n",
    "    vol_base_case = base_network_no_policies['vol_car'].values\n",
    "    capacity_base_case = base_network_no_policies['capacity'].values\n",
    "    \n",
    "    # Initialize base edge positions\n",
    "    gdf_base = gpd.GeoDataFrame(base_network_no_policies, geometry='geometry')\n",
    "    gdf_base.crs = \"EPSG:2154\"  # Assuming the original CRS is EPSG:2154\n",
    "    gdf_base.to_crs(\"EPSG:4326\", inplace=True)\n",
    "    edge_positions_base = np.array([((geom.coords[0][0] + geom.coords[-1][0]) / 2, \n",
    "                                     (geom.coords[0][1] + geom.coords[-1][1]) / 2) \n",
    "                                    for geom in gdf_base.geometry])\n",
    "    \n",
    "    nodes = pd.concat([gdf_base['from_node'], gdf_base['to_node']]).unique()\n",
    "    node_to_idx = {node: idx for idx, node in enumerate(nodes)}\n",
    "    gdf_base['from_idx'] = gdf_base['from_node'].map(node_to_idx)\n",
    "    gdf_base['to_idx'] = gdf_base['to_node'].map(node_to_idx)\n",
    "    edges_base = gdf_base[['from_idx', 'to_idx']].values\n",
    "    edge_positions_tensor = torch.tensor(edge_positions_base, dtype=torch.float)\n",
    "    edge_index = torch.tensor(edges_base, dtype=torch.long).t().contiguous()\n",
    "    x = torch.zeros((len(nodes), 1), dtype=torch.float)\n",
    "    data = Data(edge_index=edge_index, x=x, pos=edge_positions_tensor)\n",
    "    linegraph_data = linegraph_transformation(data)\n",
    "\n",
    "    for key, df in result_dic.items():        \n",
    "        if isinstance(df, pd.DataFrame) and key != \"base_network_no_policies\":\n",
    "            gdf = gpd.GeoDataFrame(df, geometry='geometry')\n",
    "            gdf.crs = \"EPSG:2154\"  # Assuming the original CRS is EPSG:2154\n",
    "            gdf.to_crs(\"EPSG:4326\", inplace=True)\n",
    "\n",
    "            capacities_new = gdf['capacity'].values\n",
    "            capacity_reduction = capacities_new - capacity_base_case\n",
    "            \n",
    "            highway = gdf['highway'].apply(lambda x: highway_mapping.get(x, -1)).values\n",
    "            edge_car_volume_difference = gdf['vol_car'].values - vol_base_case\n",
    "            target_values = torch.tensor(edge_car_volume_difference, dtype=torch.float).unsqueeze(1)\n",
    "\n",
    "            linegraph_x = torch.tensor(np.column_stack((vol_base_case, capacity_base_case, capacities_new, capacity_reduction, highway)), dtype=torch.float)\n",
    "            linegraph_data.x = linegraph_x\n",
    "            linegraph_data.y = target_values\n",
    "            \n",
    "            df_mode_stats = result_dic_mode_stats.get(key)\n",
    "            if df_mode_stats is not None:\n",
    "                # Convert numeric columns to float\n",
    "                numeric_cols = df_mode_stats.select_dtypes(include=[np.number]).columns\n",
    "                mode_stats_numeric = df_mode_stats[numeric_cols].astype(float)\n",
    "                \n",
    "                # Convert to tensor\n",
    "                mode_stats_tensor = torch.tensor(mode_stats_numeric.values, dtype=torch.float)\n",
    "                \n",
    "                # Add mode_stats as an attribute to linegraph_data\n",
    "                linegraph_data.mode_stats = mode_stats_tensor\n",
    "                \n",
    "            if linegraph_data.validate(raise_on_error=True):\n",
    "                datalist.append(linegraph_data)\n",
    "            else:\n",
    "                print(\"Invalid line graph data\")\n",
    "    data_dict_list = [{'x': lg_data.x, 'edge_index': lg_data.edge_index, 'pos': lg_data.pos, 'y': lg_data.y, 'graph_attr': lg_data.mode_stats} for lg_data in datalist]\n",
    "    return data_dict_list\n",
    "\n",
    "data_processed = process_result_dic(result_dic=result_dic, result_dic_mode_stats=result_dic_mode_stats)\n",
    "torch.save(data_processed, result_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_processed' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdata_processed\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data_processed' is not defined"
     ]
    }
   ],
   "source": [
    "data_processed[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save for further processing with GNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_processed_single_districts = pio.process_result_dic(result_dic_single_districts)\n",
    "# torch.save(data_processed_single_districts, result_path + '_single_districts.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(data_processed, result_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Paris_Analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
