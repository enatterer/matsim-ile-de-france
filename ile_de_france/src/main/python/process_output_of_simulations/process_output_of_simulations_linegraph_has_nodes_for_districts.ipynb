{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import math\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import torch\n",
    "from collections import defaultdict\n",
    "\n",
    "import processing_io as pio\n",
    "from torch_geometric.transforms import LineGraph\n",
    "\n",
    "from torch_geometric.data import Data, Batch\n",
    "import shapely.wkt as wkt\n",
    "from tqdm import tqdm\n",
    "import fiona\n",
    "import os\n",
    "\n",
    "import alphashape\n",
    "from shapely.geometry import Polygon\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from shapely.geometry import Point\n",
    "import random\n",
    "\n",
    "# result_df_name = 'sim_output_1pm_capacity_reduction_10k_PRELIMINARY'\n",
    "result_df_name = 'sim_output_1pm_capacity_reduction_10k_test'\n",
    "result_path = '../../../../data/datasets_simulation_outputs/' + result_df_name\n",
    "string_is_for_1pm = \"pop_1pm\"\n",
    "\n",
    "base_dir_sample_sim_input = '../../../../data/' + string_is_for_1pm + '_simulations/' + string_is_for_1pm + '_policies_combinations_with_normal_dist/'\n",
    "subdirs_pattern = os.path.join(base_dir_sample_sim_input, 'output_networks_*')\n",
    "subdirs = list(set(glob.glob(subdirs_pattern)))\n",
    "subdirs.sort()\n",
    "\n",
    "gdf_basecase_output_links = gpd.read_file('results/' + string_is_for_1pm + '_basecase_average_output_links.geojson')\n",
    "gdf_basecase_average_mode_stats = pd.read_csv('results/' + string_is_for_1pm + '_basecase_average_mode_stats.csv', delimiter=';')\n",
    "districts = gpd.read_file(\"../../../../data/visualisation/districts_paris.geojson\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abstract\n",
    "\n",
    "This is further than process_output_of_simulations_with_all_output_links_and_eqasim_info.ipynb, as it also includes more input information.\n",
    "\n",
    "Note that there is more than one strategy to deal with the fact that there are more than one district per link. We implement the strategy of stacking the information of all districts together. \n",
    "An alternative strategy would be to use the mean of the information of the districts.\n",
    "\n",
    "Process the districts manually, so that each link belongs to at most 3 districts."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process results\n",
    "\n",
    "Process the outputs of the simulations for further usage by GNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing subdirs:   5%|▌         | 5/100 [00:44<14:07,  8.92s/subdir]\n",
      "/var/folders/m_/fjnjc1sn0ggc7z_2y7n27xfh0000gn/T/ipykernel_46270/3674340099.py:37: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  districts['district_centroid'] = districts['geometry'].centroid\n",
      "/Users/elenanatterer/anaconda3/envs/Paris_Analysis/lib/python3.10/site-packages/IPython/core/interactiveshell.py:3448: FutureWarning: The `op` parameter is deprecated and will be removed in a future release. Please use the `predicate` parameter instead.\n",
      "  if await self.run_code(code, result, async_=asy):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "448\n",
      "449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/elenanatterer/anaconda3/envs/Paris_Analysis/lib/python3.10/site-packages/pandas/core/reshape/merge.py:1203: RuntimeWarning: invalid value encountered in cast\n",
      "  if not (lk == lk.astype(rk.dtype))[~np.isnan(lk)].all():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original number of edges: 31216\n",
      "Number of edges after summarization: 25309\n",
      "Number of remaining duplicate edges: 0\n"
     ]
    }
   ],
   "source": [
    "# Read all network data into a dictionary of GeoDataFrames\n",
    "def compute_result_dic():\n",
    "    result_dic_output_links = {}\n",
    "    result_dic_eqasim_trips = {}\n",
    "    base_network_no_policies = gdf_basecase_output_links\n",
    "    result_dic_output_links[\"base_network_no_policies\"] = base_network_no_policies\n",
    "    counter = 0\n",
    "    for subdir in tqdm(subdirs, desc=\"Processing subdirs\", unit=\"subdir\"):\n",
    "        counter += 1\n",
    "        if counter > 5:\n",
    "            break\n",
    "        # print(f'Accessing folder: {subdir}')\n",
    "        # print(len(os.listdir(subdir)))\n",
    "        networks = [network for network in os.listdir(subdir) if not network.endswith(\".DS_Store\")]\n",
    "        for network in networks:\n",
    "            file_path = os.path.join(subdir, network)\n",
    "            policy_key = pio.create_policy_key_1pm(network)\n",
    "            df_output_links = pio.read_output_links(file_path)\n",
    "            df_eqasim_trips = pio.read_eqasim_trips(file_path)\n",
    "            if (df_output_links is not None and df_eqasim_trips is not None):\n",
    "                df_output_links.drop(columns=['geometry'], inplace=True)\n",
    "                gdf_extended = pio.extend_geodataframe(gdf_base=gdf_basecase_output_links, gdf_to_extend=df_output_links, column_to_extend='highway', new_column_name='highway')\n",
    "                gdf_extended = pio.extend_geodataframe(gdf_base=gdf_basecase_output_links, gdf_to_extend=gdf_extended, column_to_extend='vol_car', new_column_name='vol_car_base_case')\n",
    "                result_dic_output_links[policy_key] = gdf_extended\n",
    "                mode_stats = pio.calculate_averaged_results(df_eqasim_trips)\n",
    "                result_dic_eqasim_trips[policy_key] = mode_stats\n",
    "    return result_dic_output_links, result_dic_eqasim_trips\n",
    "\n",
    "result_dic_output_links, result_dic_eqasim_trips = compute_result_dic()\n",
    "print(len(result_dic_eqasim_trips.keys()))\n",
    "print(len(result_dic_output_links.keys()))\n",
    "\n",
    "base_gdf = result_dic_output_links[\"base_network_no_policies\"]\n",
    "links_gdf_base = gpd.GeoDataFrame(base_gdf, geometry='geometry')\n",
    "links_gdf_base.crs = \"EPSG:2154\"  # Assuming the original CRS is EPSG:2154\n",
    "links_gdf_base.to_crs(\"EPSG:4326\", inplace=True)\n",
    "districts['district_centroid'] = districts['geometry'].centroid\n",
    "links_gdf_with_districts = gpd.sjoin(links_gdf_base, districts, how='left', op='intersects')\n",
    "\n",
    "# Group by edge and aggregate the district names\n",
    "links_gdf_with_districts = links_gdf_with_districts.groupby('link').agg({\n",
    "    'from_node': 'first',\n",
    "    'to_node': 'first',\n",
    "    'length': 'first',\n",
    "    'freespeed': 'first',\n",
    "    'capacity': 'first',\n",
    "    'lanes': 'first',\n",
    "    'modes': 'first',\n",
    "    'vol_car': 'first',\n",
    "    'highway': 'first',\n",
    "    'geometry': 'first',\n",
    "    'c_ar': lambda x: list(x.dropna()),\n",
    "    'district_centroid': lambda x: list(x.dropna()),\n",
    "    'perimetre': lambda x: list(x.dropna()),\n",
    "    'surface': lambda x: list(x.dropna()),\n",
    "}).reset_index()\n",
    "\n",
    "gdf_now = gpd.GeoDataFrame(links_gdf_with_districts, geometry='geometry', crs=links_gdf_base.crs)\n",
    "gdf_now = gdf_now.rename(columns={'c_ar': 'district', 'perimetre': 'district_perimeter', 'surface': 'district_surface'})\n",
    "\n",
    "links_gdf = pio.summarize_duplicate_edges(gdf_now)\n",
    "print(f\"Original number of edges: {len(gdf_now)}\")\n",
    "print(f\"Number of edges after summarization: {len(links_gdf)}\")\n",
    "remaining_duplicates = pio.find_duplicate_edges_in_gdf(links_gdf)\n",
    "print(f\"Number of remaining duplicate edges: {len(remaining_duplicates)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PROCESS LINK GEOMETRIES\n",
    "edge_start_point_tensor, stacked_edge_geometries_tensor, district_centroids_tensor_padded, edges_base, nodes = pio.get_link_geometries(links_gdf, districts)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze results and save to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pio.analyze_geodataframes(result_dic=result_dic, consider_only_highway_edges=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pio.analyze_geodataframes(result_dic=result_dic, consider_only_highway_edges=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing result_dic:   3%|▎         | 13/449 [00:23<12:53,  1.78s/dataframe]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 66\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;66;03m# Call the function\u001b[39;00m\n\u001b[0;32m---> 66\u001b[0m \u001b[43mprocess_result_dic\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult_dic\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresult_dic_output_links\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresult_dic_mode_stats\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresult_dic_eqasim_trips\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresult_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgdf_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlinks_gdf\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[6], line 22\u001b[0m, in \u001b[0;36mprocess_result_dic\u001b[0;34m(result_dic, result_dic_mode_stats, save_path, batch_size, gdf_input)\u001b[0m\n\u001b[1;32m     19\u001b[0m len_edges \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(gdf)\n\u001b[1;32m     21\u001b[0m capacities_new, capacity_reduction, highway, freespeed \u001b[38;5;241m=\u001b[39m  pio\u001b[38;5;241m.\u001b[39mget_basic_edge_attributes(capacity_base_case, gdf)\n\u001b[0;32m---> 22\u001b[0m district_info, combined_tensor \u001b[38;5;241m=\u001b[39m \u001b[43mpio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_combined_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvol_base_case\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcapacity_base_case\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlength\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfreespeed_base_case\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallowed_modes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcapacities_new\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcapacity_reduction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhighway\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfreespeed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m linegraph_data \u001b[38;5;241m=\u001b[39m linegraph_transformation(data)\n\u001b[1;32m     25\u001b[0m linegraph_data\u001b[38;5;241m.\u001b[39mx \u001b[38;5;241m=\u001b[39m combined_tensor\n",
      "File \u001b[0;32m~/Development/MATSim/eqasim-java/ile_de_france/src/main/python/process_output_of_simulations/processing_io.py:867\u001b[0m, in \u001b[0;36mcompute_combined_tensor\u001b[0;34m(vol_base_case, capacity_base_case, length, freespeed_base_case, allowed_modes, gdf, capacities_new, capacity_reduction, highway, freespeed)\u001b[0m\n\u001b[1;32m    849\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_combined_tensor\u001b[39m(vol_base_case, capacity_base_case, length, freespeed_base_case, allowed_modes, gdf, capacities_new, capacity_reduction, highway, freespeed):\n\u001b[1;32m    850\u001b[0m     edge_tensors \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    851\u001b[0m                 torch\u001b[38;5;241m.\u001b[39mtensor(vol_base_case), \n\u001b[1;32m    852\u001b[0m                 torch\u001b[38;5;241m.\u001b[39mtensor(capacity_base_case), \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    864\u001b[0m                 allowed_modes[\u001b[38;5;241m5\u001b[39m],\n\u001b[1;32m    865\u001b[0m             ]\n\u001b[0;32m--> 867\u001b[0m     district_info \u001b[38;5;241m=\u001b[39m \u001b[43maggregate_district_information\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlinks_gdf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensors_edge_information\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43medge_tensors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    868\u001b[0m     district_tensors \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    869\u001b[0m                 district_info[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvol_base_case\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    870\u001b[0m                 district_info[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcapacity_base\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    882\u001b[0m                 district_info[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msubway_allowed\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    883\u001b[0m             ]\n\u001b[1;32m    884\u001b[0m     stacked_tensor1 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack(edge_tensors, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Shape: (25209, 14)\u001b[39;00m\n",
      "File \u001b[0;32m~/Development/MATSim/eqasim-java/ile_de_france/src/main/python/process_output_of_simulations/processing_io.py:785\u001b[0m, in \u001b[0;36maggregate_district_information\u001b[0;34m(links_gdf, tensors_edge_information)\u001b[0m\n\u001b[1;32m    783\u001b[0m district_info[district][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcapacity_reduction\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m capacity_reduction[idx]\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m    784\u001b[0m district_info[district][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfreespeed_sum\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m freespeed[idx]\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m--> 785\u001b[0m district_info[district][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfreespeed_base_sum\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mfreespeed_base\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    786\u001b[0m district_info[district][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfreespeed_base_count\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    787\u001b[0m district_info[district][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfreespeed_count\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def process_result_dic(result_dic, result_dic_mode_stats, save_path=None, batch_size=500, gdf_input=None):\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "    datalist = []\n",
    "    linegraph_transformation = LineGraph()\n",
    "    \n",
    "    vol_base_case = links_gdf['vol_car'].values\n",
    "    capacity_base_case = np.where(links_gdf['modes'].str.contains('car'), links_gdf['capacity'], 0)\n",
    "    length = links_gdf['length'].values\n",
    "    freespeed_base_case = links_gdf['freespeed'].values\n",
    "    allowed_modes = pio.encode_modes(links_gdf)\n",
    "    edge_index = torch.tensor(edges_base, dtype=torch.long).t().contiguous()\n",
    "    x = torch.zeros((len(nodes), 1), dtype=torch.float)\n",
    "    data = Data(edge_index=edge_index, x=x)\n",
    "    \n",
    "    batch_counter = 0\n",
    "    for key, df in tqdm(result_dic.items(), desc=\"Processing result_dic\", unit=\"dataframe\"):   \n",
    "        if isinstance(df, pd.DataFrame) and key != \"base_network_no_policies\":\n",
    "            gdf = pio.prepare_gdf(df, gdf_input)\n",
    "            len_edges = len(gdf)\n",
    "            \n",
    "            capacities_new, capacity_reduction, highway, freespeed =  pio.get_basic_edge_attributes(capacity_base_case, gdf)\n",
    "            district_info, combined_tensor = pio.compute_combined_tensor(vol_base_case, capacity_base_case, length, freespeed_base_case, allowed_modes, gdf, capacities_new, capacity_reduction, highway, freespeed)\n",
    "            \n",
    "            linegraph_data = linegraph_transformation(data)\n",
    "            linegraph_data.x = combined_tensor\n",
    "            linegraph_data.num_nodes = combined_tensor.shape[0]\n",
    "        \n",
    "            # add edge attributes: 1 if edge to district, 0 if edge to edge\n",
    "            edge_to_district_index, edge_to_district_attr = pio.compute_edge_attributes(district_info, linegraph_data, len_edges, gdf)\n",
    "            if linegraph_data.edge_attr is None:\n",
    "                linegraph_data.edge_attr = torch.zeros((linegraph_data.edge_index.shape[1] - edge_to_district_index.shape[1], 1), dtype=torch.long)\n",
    "            linegraph_data.edge_attr = torch.cat([linegraph_data.edge_attr, edge_to_district_attr], dim=0)\n",
    "\n",
    "            # add node attributes: 1 if district, 0 if edge\n",
    "            node_type_feature = pio.compute_node_attributes(district_info, len_edges)\n",
    "            linegraph_data.x = torch.cat([linegraph_data.x, node_type_feature], dim=1)\n",
    "            linegraph_data.pos = torch.cat([stacked_edge_geometries_tensor, district_centroids_tensor_padded], dim=0)\n",
    "            linegraph_data.y = pio.compute_target_tensor(vol_base_case, gdf, district_info)\n",
    "                        \n",
    "            df_mode_stats = result_dic_mode_stats.get(key)\n",
    "            if df_mode_stats is not None:\n",
    "                numeric_cols = df_mode_stats.select_dtypes(include=[np.number]).columns\n",
    "                mode_stats_numeric = df_mode_stats[numeric_cols].astype(float)\n",
    "                mode_stats_tensor = torch.tensor(mode_stats_numeric.values, dtype=torch.float)\n",
    "                linegraph_data.mode_stats = mode_stats_tensor\n",
    "            \n",
    "            if linegraph_data.validate(raise_on_error=True):\n",
    "                datalist.append(linegraph_data)\n",
    "                batch_counter += 1\n",
    "\n",
    "                # Save intermediate result every batch_size data points\n",
    "                if batch_counter % batch_size == 0:\n",
    "                    batch_index = batch_counter // batch_size\n",
    "                    torch.save(datalist, os.path.join(save_path, f'datalist_batch_{batch_index}.pt'))\n",
    "                    datalist = []  # Reset datalist for the next batch\n",
    "            else:\n",
    "                print(\"Invalid line graph data\")\n",
    "    \n",
    "    # Save any remaining data points\n",
    "    if datalist:\n",
    "        batch_index = (batch_counter // batch_size) + 1\n",
    "        torch.save(datalist, os.path.join(save_path, f'datalist_batch_{batch_index}.pt'))\n",
    "    return\n",
    "\n",
    "# Call the function\n",
    "process_result_dic(result_dic=result_dic_output_links, result_dic_mode_stats=result_dic_eqasim_trips, save_path=result_path, batch_size=200, gdf_input=links_gdf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Paris_Analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
