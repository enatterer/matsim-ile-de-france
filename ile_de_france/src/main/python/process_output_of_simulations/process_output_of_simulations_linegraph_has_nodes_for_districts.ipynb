{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import math\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import torch\n",
    "from collections import defaultdict\n",
    "\n",
    "import processing_io as pio\n",
    "from torch_geometric.transforms import LineGraph\n",
    "\n",
    "from torch_geometric.data import Data, Batch\n",
    "import shapely.wkt as wkt\n",
    "from tqdm import tqdm\n",
    "import fiona\n",
    "import os\n",
    "\n",
    "import alphashape\n",
    "from shapely.geometry import Polygon\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from shapely.geometry import Point\n",
    "import random\n",
    "\n",
    "# result_df_name = 'sim_output_1pm_capacity_reduction_10k_PRELIMINARY'\n",
    "result_df_name = 'sim_output_1pm_capacity_reduction_10k_test'\n",
    "result_path = '../../../../data/datasets_simulation_outputs/' + result_df_name\n",
    "string_is_for_1pm = \"pop_1pm\"\n",
    "\n",
    "base_dir_sample_sim_input = '../../../../data/' + string_is_for_1pm + '_simulations/' + string_is_for_1pm + '_policies_combinations_with_normal_dist/'\n",
    "subdirs_pattern = os.path.join(base_dir_sample_sim_input, 'output_networks_*')\n",
    "subdirs = list(set(glob.glob(subdirs_pattern)))\n",
    "subdirs.sort()\n",
    "\n",
    "gdf_basecase_output_links = gpd.read_file('results/' + string_is_for_1pm + '_basecase_average_output_links.geojson')\n",
    "gdf_basecase_average_mode_stats = pd.read_csv('results/' + string_is_for_1pm + '_basecase_average_mode_stats.csv', delimiter=';')\n",
    "districts = gpd.read_file(\"../../../../data/visualisation/districts_paris.geojson\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abstract\n",
    "\n",
    "This is further than process_output_of_simulations_with_all_output_links_and_eqasim_info.ipynb, as it also includes more input information.\n",
    "\n",
    "Note that there is more than one strategy to deal with the fact that there are more than one district per link. We implement the strategy of stacking the information of all districts together. \n",
    "An alternative strategy would be to use the mean of the information of the districts.\n",
    "\n",
    "Process the districts manually, so that each link belongs to at most 3 districts."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process results\n",
    "\n",
    "Process the outputs of the simulations for further usage by GNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing subdirs:   5%|▌         | 5/100 [00:45<14:16,  9.01s/subdir]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "448\n",
      "449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/m_/fjnjc1sn0ggc7z_2y7n27xfh0000gn/T/ipykernel_46626/1202570188.py:37: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  districts['district_centroid'] = districts['geometry'].centroid\n",
      "/Users/elenanatterer/anaconda3/envs/Paris_Analysis/lib/python3.10/site-packages/IPython/core/interactiveshell.py:3448: FutureWarning: The `op` parameter is deprecated and will be removed in a future release. Please use the `predicate` parameter instead.\n",
      "  if await self.run_code(code, result, async_=asy):\n",
      "/Users/elenanatterer/anaconda3/envs/Paris_Analysis/lib/python3.10/site-packages/pandas/core/reshape/merge.py:1203: RuntimeWarning: invalid value encountered in cast\n",
      "  if not (lk == lk.astype(rk.dtype))[~np.isnan(lk)].all():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original number of edges: 31216\n",
      "Number of edges after summarization: 25309\n",
      "Number of remaining duplicate edges: 0\n"
     ]
    }
   ],
   "source": [
    "# Read all network data into a dictionary of GeoDataFrames\n",
    "def compute_result_dic():\n",
    "    result_dic_output_links = {}\n",
    "    result_dic_eqasim_trips = {}\n",
    "    base_network_no_policies = gdf_basecase_output_links\n",
    "    result_dic_output_links[\"base_network_no_policies\"] = base_network_no_policies\n",
    "    counter = 0\n",
    "    for subdir in tqdm(subdirs, desc=\"Processing subdirs\", unit=\"subdir\"):\n",
    "        counter += 1\n",
    "        if counter > 5:\n",
    "            break\n",
    "        # print(f'Accessing folder: {subdir}')\n",
    "        # print(len(os.listdir(subdir)))\n",
    "        networks = [network for network in os.listdir(subdir) if not network.endswith(\".DS_Store\")]\n",
    "        for network in networks:\n",
    "            file_path = os.path.join(subdir, network)\n",
    "            policy_key = pio.create_policy_key_1pm(network)\n",
    "            df_output_links = pio.read_output_links(file_path)\n",
    "            df_eqasim_trips = pio.read_eqasim_trips(file_path)\n",
    "            if (df_output_links is not None and df_eqasim_trips is not None):\n",
    "                df_output_links.drop(columns=['geometry'], inplace=True)\n",
    "                gdf_extended = pio.extend_geodataframe(gdf_base=gdf_basecase_output_links, gdf_to_extend=df_output_links, column_to_extend='highway', new_column_name='highway')\n",
    "                gdf_extended = pio.extend_geodataframe(gdf_base=gdf_basecase_output_links, gdf_to_extend=gdf_extended, column_to_extend='vol_car', new_column_name='vol_car_base_case')\n",
    "                result_dic_output_links[policy_key] = gdf_extended\n",
    "                mode_stats = pio.calculate_averaged_results(df_eqasim_trips)\n",
    "                result_dic_eqasim_trips[policy_key] = mode_stats\n",
    "    return result_dic_output_links, result_dic_eqasim_trips\n",
    "\n",
    "result_dic_output_links, result_dic_eqasim_trips = compute_result_dic()\n",
    "print(len(result_dic_eqasim_trips.keys()))\n",
    "print(len(result_dic_output_links.keys()))\n",
    "\n",
    "base_gdf = result_dic_output_links[\"base_network_no_policies\"]\n",
    "links_gdf_base = gpd.GeoDataFrame(base_gdf, geometry='geometry')\n",
    "links_gdf_base.crs = \"EPSG:2154\"  # Assuming the original CRS is EPSG:2154\n",
    "links_gdf_base.to_crs(\"EPSG:4326\", inplace=True)\n",
    "districts['district_centroid'] = districts['geometry'].centroid\n",
    "links_gdf_with_districts = gpd.sjoin(links_gdf_base, districts, how='left', op='intersects')\n",
    "\n",
    "# Group by edge and aggregate the district names\n",
    "links_gdf_with_districts = links_gdf_with_districts.groupby('link').agg({\n",
    "    'from_node': 'first',\n",
    "    'to_node': 'first',\n",
    "    'length': 'first',\n",
    "    'freespeed': 'first',\n",
    "    'capacity': 'first',\n",
    "    'lanes': 'first',\n",
    "    'modes': 'first',\n",
    "    'vol_car': 'first',\n",
    "    'highway': 'first',\n",
    "    'geometry': 'first',\n",
    "    'osm:way:oneway': 'first',\n",
    "    'c_ar': lambda x: list(x.dropna()),\n",
    "    'district_centroid': lambda x: list(x.dropna()),\n",
    "    'perimetre': lambda x: list(x.dropna()),\n",
    "    'surface': lambda x: list(x.dropna()),\n",
    "}).reset_index()\n",
    "\n",
    "gdf_now = gpd.GeoDataFrame(links_gdf_with_districts, geometry='geometry', crs=links_gdf_base.crs)\n",
    "gdf_now = gdf_now.rename(columns={'c_ar': 'district', 'perimetre': 'district_perimeter', 'surface': 'district_surface'})\n",
    "\n",
    "links_gdf = pio.summarize_duplicate_edges(gdf_now)\n",
    "print(f\"Original number of edges: {len(gdf_now)}\")\n",
    "print(f\"Number of edges after summarization: {len(links_gdf)}\")\n",
    "remaining_duplicates = pio.find_duplicate_edges_in_gdf(links_gdf)\n",
    "print(f\"Number of remaining duplicate edges: {len(remaining_duplicates)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PROCESS LINK GEOMETRIES\n",
    "edge_start_point_tensor, stacked_edge_geometries_tensor, district_centroids_tensor_padded, edges_base, nodes = pio.get_link_geometries(links_gdf, districts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>link</th>\n",
       "      <th>from_node</th>\n",
       "      <th>to_node</th>\n",
       "      <th>length</th>\n",
       "      <th>freespeed</th>\n",
       "      <th>capacity</th>\n",
       "      <th>lanes</th>\n",
       "      <th>modes</th>\n",
       "      <th>vol_car</th>\n",
       "      <th>osm:relation:route_master</th>\n",
       "      <th>...</th>\n",
       "      <th>osm:way:id</th>\n",
       "      <th>osm:way:access</th>\n",
       "      <th>osm:way:oneway</th>\n",
       "      <th>highway</th>\n",
       "      <th>osm:relation:route</th>\n",
       "      <th>osm:way:railway</th>\n",
       "      <th>osm:way:name</th>\n",
       "      <th>storageCapacityUsedInQsim</th>\n",
       "      <th>osm:way:tunnel</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100315</td>\n",
       "      <td>24972409</td>\n",
       "      <td>24972408</td>\n",
       "      <td>16.181257</td>\n",
       "      <td>8.333333</td>\n",
       "      <td>480.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>bus,car,car_passenger</td>\n",
       "      <td>6.627451</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>4216830.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yes</td>\n",
       "      <td>residential</td>\n",
       "      <td>bicycle</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Carrefour de l'Odéon</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LINESTRING (2.33869 48.85181, 2.33847 48.85181)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100316</td>\n",
       "      <td>5904976363</td>\n",
       "      <td>24983651</td>\n",
       "      <td>14.860209</td>\n",
       "      <td>8.333333</td>\n",
       "      <td>480.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>bus,car,car_passenger,pt</td>\n",
       "      <td>9.607843</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>4216831.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>bus</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Carrefour de l'Odéon</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LINESTRING (2.33874 48.85242, 2.33872 48.85229)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100317</td>\n",
       "      <td>24983651</td>\n",
       "      <td>5904976363</td>\n",
       "      <td>14.860209</td>\n",
       "      <td>8.333333</td>\n",
       "      <td>960.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>bus,car,car_passenger,pt</td>\n",
       "      <td>2.490196</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>4216831.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>bus</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Carrefour de l'Odéon</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LINESTRING (2.33872 48.85229, 2.33874 48.85242)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100321</td>\n",
       "      <td>664205947</td>\n",
       "      <td>24972376</td>\n",
       "      <td>22.264540</td>\n",
       "      <td>8.333333</td>\n",
       "      <td>960.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>car,car_passenger</td>\n",
       "      <td>6.941176</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>4216834.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yes</td>\n",
       "      <td>residential</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Boulevard Saint-Germain</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LINESTRING (2.33994 48.85200, 2.33986 48.85181)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100324</td>\n",
       "      <td>24972376</td>\n",
       "      <td>24972375</td>\n",
       "      <td>64.853276</td>\n",
       "      <td>8.333333</td>\n",
       "      <td>480.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>bus,car,car_passenger</td>\n",
       "      <td>7.607843</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>4216833.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yes</td>\n",
       "      <td>residential</td>\n",
       "      <td>bicycle</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rue Dupuytren</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LINESTRING (2.33986 48.85181, 2.33909 48.85152)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     link   from_node     to_node     length  freespeed  capacity  lanes  \\\n",
       "0  100315    24972409    24972408  16.181257   8.333333     480.0    1.0   \n",
       "1  100316  5904976363    24983651  14.860209   8.333333     480.0    1.0   \n",
       "2  100317    24983651  5904976363  14.860209   8.333333     960.0    2.0   \n",
       "3  100321   664205947    24972376  22.264540   8.333333     960.0    2.0   \n",
       "4  100324    24972376    24972375  64.853276   8.333333     480.0    1.0   \n",
       "\n",
       "                      modes   vol_car osm:relation:route_master  ...  \\\n",
       "0     bus,car,car_passenger  6.627451                       NaN  ...   \n",
       "1  bus,car,car_passenger,pt  9.607843                       NaN  ...   \n",
       "2  bus,car,car_passenger,pt  2.490196                       NaN  ...   \n",
       "3         car,car_passenger  6.941176                       NaN  ...   \n",
       "4     bus,car,car_passenger  7.607843                       NaN  ...   \n",
       "\n",
       "  osm:way:id osm:way:access osm:way:oneway      highway osm:relation:route  \\\n",
       "0  4216830.0            NaN            yes  residential            bicycle   \n",
       "1  4216831.0            NaN            NaN     tertiary                bus   \n",
       "2  4216831.0            NaN            NaN     tertiary                bus   \n",
       "3  4216834.0            NaN            yes  residential                NaN   \n",
       "4  4216833.0            NaN            yes  residential            bicycle   \n",
       "\n",
       "   osm:way:railway             osm:way:name storageCapacityUsedInQsim  \\\n",
       "0              NaN     Carrefour de l'Odéon                       NaN   \n",
       "1              NaN     Carrefour de l'Odéon                       NaN   \n",
       "2              NaN     Carrefour de l'Odéon                       NaN   \n",
       "3              NaN  Boulevard Saint-Germain                       NaN   \n",
       "4              NaN            Rue Dupuytren                       NaN   \n",
       "\n",
       "   osm:way:tunnel                                         geometry  \n",
       "0             NaN  LINESTRING (2.33869 48.85181, 2.33847 48.85181)  \n",
       "1             NaN  LINESTRING (2.33874 48.85242, 2.33872 48.85229)  \n",
       "2             NaN  LINESTRING (2.33872 48.85229, 2.33874 48.85242)  \n",
       "3             NaN  LINESTRING (2.33994 48.85200, 2.33986 48.85181)  \n",
       "4             NaN  LINESTRING (2.33986 48.85181, 2.33909 48.85152)  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "links_gdf_base.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts in links_gdf_base['osm:way:oneway']:\n",
      "yes    17589\n",
      "NaN    12466\n",
      "no      1148\n",
      "-1        13\n",
      "Name: osm:way:oneway, dtype: int64\n",
      "Counts in links_gdf['osm:way:oneway']:\n",
      "yes    17537\n",
      "NaN     7154\n",
      "no       610\n",
      "-1         8\n",
      "Name: osm:way:oneway, dtype: int64\n",
      "Comparison of 'osm:way:oneway' counts between links_gdf_base and links_gdf:\n",
      "     links_gdf_base  links_gdf\n",
      "yes           17589      17537\n",
      "NaN           12466       7154\n",
      "no             1148        610\n",
      "-1               13          8\n",
      "Number of edges where 'from_node' is equal to 'to_node': 766\n",
      "Number of edges which exist in both directions: 766\n",
      "Number of edges in links_gdf_base where 'from_node' is equal to 'to_node': 769\n",
      "Number of edges in links_gdf_base which exist in both directions: 12595\n",
      "Number of edges in links_gdf where 'from_node' is equal to 'to_node': 766\n",
      "Number of edges in links_gdf which exist in both directions: 766\n"
     ]
    }
   ],
   "source": [
    "links_gdf_base['osm:way:oneway']\n",
    "# Investigate the 'osm:way:oneway' column in links_gdf_base\n",
    "oneway_counts_base = links_gdf_base['osm:way:oneway'].value_counts(dropna=False)\n",
    "print(\"Counts in links_gdf_base['osm:way:oneway']:\")\n",
    "print(oneway_counts_base)\n",
    "\n",
    "# Investigate the 'osm:way:oneway' column in links_gdf\n",
    "oneway_counts = links_gdf['osm:way:oneway'].value_counts(dropna=False)\n",
    "print(\"Counts in links_gdf['osm:way:oneway']:\")\n",
    "print(oneway_counts)\n",
    "\n",
    "# Compare the counts\n",
    "comparison_df = pd.DataFrame({\n",
    "    'links_gdf_base': oneway_counts_base,\n",
    "    'links_gdf': oneway_counts\n",
    "}).fillna(0)\n",
    "print(\"Comparison of 'osm:way:oneway' counts between links_gdf_base and links_gdf:\")\n",
    "print(comparison_df)\n",
    "\n",
    "# Check for roads where \"from_node\" is equal to \"to_node\"\n",
    "same_node_edges = links_gdf[links_gdf['from_node'] == links_gdf['to_node']]\n",
    "print(f\"Number of edges where 'from_node' is equal to 'to_node': {len(same_node_edges)}\")\n",
    "\n",
    "# Check for edges which exist in both directions\n",
    "reverse_edges = links_gdf.merge(links_gdf, left_on=['from_node', 'to_node'], right_on=['to_node', 'from_node'], suffixes=('_1', '_2'))\n",
    "print(f\"Number of edges which exist in both directions: {len(reverse_edges)}\")\n",
    "\n",
    "# Check for roads where \"from_node\" is equal to \"to_node\" in links_gdf_base\n",
    "same_node_edges_base = links_gdf_base[links_gdf_base['from_node'] == links_gdf_base['to_node']]\n",
    "print(f\"Number of edges in links_gdf_base where 'from_node' is equal to 'to_node': {len(same_node_edges_base)}\")\n",
    "\n",
    "# Check for edges which exist in both directions in links_gdf_base\n",
    "reverse_edges_base = links_gdf_base.merge(links_gdf_base, left_on=['from_node', 'to_node'], right_on=['to_node', 'from_node'], suffixes=('_1', '_2'))\n",
    "print(f\"Number of edges in links_gdf_base which exist in both directions: {len(reverse_edges_base)}\")\n",
    "\n",
    "# Check for roads where \"from_node\" is equal to \"to_node\" in links_gdf\n",
    "same_node_edges = links_gdf[links_gdf['from_node'] == links_gdf['to_node']]\n",
    "print(f\"Number of edges in links_gdf where 'from_node' is equal to 'to_node': {len(same_node_edges)}\")\n",
    "\n",
    "# Check for edges which exist in both directions in links_gdf\n",
    "reverse_edges = links_gdf.merge(links_gdf, left_on=['from_node', 'to_node'], right_on=['to_node', 'from_node'], suffixes=('_1', '_2'))\n",
    "print(f\"Number of edges in links_gdf which exist in both directions: {len(reverse_edges)}\")\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze results and save to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pio.analyze_geodataframes(result_dic=result_dic, consider_only_highway_edges=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pio.analyze_geodataframes(result_dic=result_dic, consider_only_highway_edges=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing result_dic: 100%|██████████| 449/449 [13:52<00:00,  1.86s/dataframe]\n"
     ]
    }
   ],
   "source": [
    "def process_result_dic(result_dic, result_dic_mode_stats, save_path=None, batch_size=500, gdf_input=None):\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "    datalist = []\n",
    "    linegraph_transformation = LineGraph()\n",
    "    \n",
    "    vol_base_case = links_gdf['vol_car'].values\n",
    "    capacity_base_case = np.where(links_gdf['modes'].str.contains('car'), links_gdf['capacity'], 0)\n",
    "    length = links_gdf['length'].values\n",
    "    freespeed_base_case = links_gdf['freespeed'].values\n",
    "    allowed_modes = pio.encode_modes(links_gdf)\n",
    "    edge_index = torch.tensor(edges_base, dtype=torch.long).t().contiguous()\n",
    "    x = torch.zeros((len(nodes), 1), dtype=torch.float)\n",
    "    data = Data(edge_index=edge_index, x=x)\n",
    "    \n",
    "    batch_counter = 0\n",
    "    for key, df in tqdm(result_dic.items(), desc=\"Processing result_dic\", unit=\"dataframe\"):   \n",
    "        if isinstance(df, pd.DataFrame) and key != \"base_network_no_policies\":\n",
    "            gdf = pio.prepare_gdf(df, gdf_input)\n",
    "            len_edges = len(gdf)\n",
    "            \n",
    "            capacities_new, capacity_reduction, highway, freespeed =  pio.get_basic_edge_attributes(capacity_base_case, gdf)\n",
    "            district_info, combined_tensor = pio.compute_combined_tensor(vol_base_case, capacity_base_case, length, freespeed_base_case, allowed_modes, gdf, capacities_new, capacity_reduction, highway, freespeed)\n",
    "            \n",
    "            linegraph_data = linegraph_transformation(data)\n",
    "            linegraph_data.x = combined_tensor\n",
    "            linegraph_data.num_nodes = combined_tensor.shape[0]\n",
    "        \n",
    "            # add edge attributes: 1 if edge to district, 0 if edge to edge\n",
    "            edge_to_district_index, edge_to_district_attr = pio.compute_edge_attributes(district_info, linegraph_data, len_edges, gdf)\n",
    "            if linegraph_data.edge_attr is None:\n",
    "                linegraph_data.edge_attr = torch.zeros((linegraph_data.edge_index.shape[1] - edge_to_district_index.shape[1], 1), dtype=torch.long)\n",
    "            linegraph_data.edge_attr = torch.cat([linegraph_data.edge_attr, edge_to_district_attr], dim=0)\n",
    "\n",
    "            # add node attributes: 1 if district, 0 if edge\n",
    "            node_type_feature = pio.compute_node_attributes(district_info, len_edges)\n",
    "            linegraph_data.x = torch.cat([linegraph_data.x, node_type_feature], dim=1)\n",
    "            linegraph_data.pos = torch.cat([stacked_edge_geometries_tensor, district_centroids_tensor_padded], dim=0)\n",
    "            linegraph_data.y = pio.compute_target_tensor(vol_base_case, gdf, district_info)\n",
    "                        \n",
    "            df_mode_stats = result_dic_mode_stats.get(key)\n",
    "            if df_mode_stats is not None:\n",
    "                numeric_cols = df_mode_stats.select_dtypes(include=[np.number]).columns\n",
    "                mode_stats_numeric = df_mode_stats[numeric_cols].astype(float)\n",
    "                mode_stats_tensor = torch.tensor(mode_stats_numeric.values, dtype=torch.float)\n",
    "                linegraph_data.mode_stats = mode_stats_tensor\n",
    "            \n",
    "            if linegraph_data.validate(raise_on_error=True):\n",
    "                datalist.append(linegraph_data)\n",
    "                batch_counter += 1\n",
    "\n",
    "                # Save intermediate result every batch_size data points\n",
    "                if batch_counter % batch_size == 0:\n",
    "                    batch_index = batch_counter // batch_size\n",
    "                    torch.save(datalist, os.path.join(save_path, f'datalist_batch_{batch_index}.pt'))\n",
    "                    datalist = []  # Reset datalist for the next batch\n",
    "            else:\n",
    "                print(\"Invalid line graph data\")\n",
    "    \n",
    "    # Save any remaining data points\n",
    "    if datalist:\n",
    "        batch_index = (batch_counter // batch_size) + 1\n",
    "        torch.save(datalist, os.path.join(save_path, f'datalist_batch_{batch_index}.pt'))\n",
    "    return\n",
    "\n",
    "# Call the function\n",
    "process_result_dic(result_dic=result_dic_output_links, result_dic_mode_stats=result_dic_eqasim_trips, save_path=result_path, batch_size=200, gdf_input=links_gdf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Paris_Analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
