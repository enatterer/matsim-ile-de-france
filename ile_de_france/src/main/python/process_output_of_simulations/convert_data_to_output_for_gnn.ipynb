{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import tqdm\n",
    "import wandb\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "from torch.utils.data import DataLoader, Dataset, Subset\n",
    "\n",
    "import torch_geometric\n",
    "from torch_geometric.data import Data, Batch\n",
    "from torch_geometric.transforms import LineGraph\n",
    "\n",
    "from shapely.geometry import LineString"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abstract\n",
    "\n",
    "Here we generate the data, and in the notebook gnn_for_policy_traffic_prediction_2 we do the model."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load data and create the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m../results/results_pop_1pm_first_1400.pkl\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m f:\n\u001b[0;32m----> 2\u001b[0m     results_dict \u001b[39m=\u001b[39m pickle\u001b[39m.\u001b[39;49mload(f)\n",
      "File \u001b[0;32m~/anaconda3/envs/Paris_Analysis/lib/python3.10/site-packages/geopandas/array.py:447\u001b[0m, in \u001b[0;36mGeometryArray.__setstate__\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m    444\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__setstate__\u001b[39m(\u001b[39mself\u001b[39m, state):\n\u001b[1;32m    445\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(state, \u001b[39mdict\u001b[39m):\n\u001b[1;32m    446\u001b[0m         \u001b[39m# pickle file saved with pygeos\u001b[39;00m\n\u001b[0;32m--> 447\u001b[0m         geoms \u001b[39m=\u001b[39m vectorized\u001b[39m.\u001b[39;49mfrom_wkb(state[\u001b[39m0\u001b[39;49m])\n\u001b[1;32m    448\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_crs \u001b[39m=\u001b[39m state[\u001b[39m1\u001b[39m]\n\u001b[1;32m    449\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sindex \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m  \u001b[39m# pygeos.STRtree could not be pickled yet\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/Paris_Analysis/lib/python3.10/site-packages/geopandas/_vectorized.py:176\u001b[0m, in \u001b[0;36mfrom_wkb\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    173\u001b[0m \u001b[39mConvert a list or array of WKB objects to a np.ndarray[geoms].\u001b[39;00m\n\u001b[1;32m    174\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    175\u001b[0m \u001b[39mif\u001b[39;00m compat\u001b[39m.\u001b[39mUSE_SHAPELY_20:\n\u001b[0;32m--> 176\u001b[0m     \u001b[39mreturn\u001b[39;00m shapely\u001b[39m.\u001b[39;49mfrom_wkb(data)\n\u001b[1;32m    177\u001b[0m \u001b[39mif\u001b[39;00m compat\u001b[39m.\u001b[39mUSE_PYGEOS:\n\u001b[1;32m    178\u001b[0m     \u001b[39mreturn\u001b[39;00m pygeos\u001b[39m.\u001b[39mfrom_wkb(data)\n",
      "File \u001b[0;32m~/anaconda3/envs/Paris_Analysis/lib/python3.10/site-packages/shapely/io.py:325\u001b[0m, in \u001b[0;36mfrom_wkb\u001b[0;34m(geometry, on_invalid, **kwargs)\u001b[0m\n\u001b[1;32m    321\u001b[0m \u001b[39m# ensure the input has object dtype, to avoid numpy inferring it as a\u001b[39;00m\n\u001b[1;32m    322\u001b[0m \u001b[39m# fixed-length string dtype (which removes trailing null bytes upon access\u001b[39;00m\n\u001b[1;32m    323\u001b[0m \u001b[39m# of array elements)\u001b[39;00m\n\u001b[1;32m    324\u001b[0m geometry \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masarray(geometry, dtype\u001b[39m=\u001b[39m\u001b[39mobject\u001b[39m)\n\u001b[0;32m--> 325\u001b[0m \u001b[39mreturn\u001b[39;00m lib\u001b[39m.\u001b[39;49mfrom_wkb(geometry, invalid_handler, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with open('../results/results_pop_1pm_first_1400.pkl', 'rb') as f:\n",
    "    results_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a dictionary to map each mode to an integer\n",
    "mode_mapping = {\n",
    "    'bus': 0,\n",
    "    'car': 1,\n",
    "    'car_passenger': 2,\n",
    "    'pt': 3,\n",
    "    'bus,car,car_passenger': 4,\n",
    "    'bus,car,car_passenger,pt': 5,\n",
    "    'car,car_passenger': 6,\n",
    "    'pt,rail,train': 7,\n",
    "    'bus,pt': 8,\n",
    "    'rail': 9,\n",
    "    'pt,subway': 10,\n",
    "    'artificial,bus': 11,\n",
    "    'artificial,rail': 12,\n",
    "    'artificial,stopFacilityLink,subway': 13,\n",
    "    'artificial,subway': 14,\n",
    "    'artificial,stopFacilityLink,tram': 15,\n",
    "    'artificial,tram': 16,\n",
    "    'artificial,bus,stopFacilityLink': 17,\n",
    "    'artificial,funicular,stopFacilityLink': 18,\n",
    "    'artificial,funicular': 19\n",
    "}\n",
    "\n",
    "# Function to encode modes into integer format\n",
    "def encode_modes(modes):\n",
    "    return mode_mapping.get(modes, -1)  # Use -1 for any unknown modes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data objects\n",
    "datalist = []\n",
    "counter = 0\n",
    "linegraph_transformation = LineGraph()\n",
    "\n",
    "for key, df in results_dict.items():\n",
    "    counter += 1\n",
    "    if isinstance(df, pd.DataFrame):\n",
    "        gdf = gpd.GeoDataFrame(df, geometry='geometry')\n",
    "        gdf.crs = \"EPSG:2154\"  # Assuming the original CRS is EPSG:2154\n",
    "        gdf.to_crs(\"EPSG:4326\", inplace=True)\n",
    "        \n",
    "        # Create dictionaries for nodes and edges\n",
    "        nodes = pd.concat([gdf['from_node'], gdf['to_node']]).unique()\n",
    "        node_to_idx = {node: idx for idx, node in enumerate(nodes)}\n",
    "        \n",
    "        gdf['from_idx'] = gdf['from_node'].map(node_to_idx)\n",
    "        gdf['to_idx'] = gdf['to_node'].map(node_to_idx)\n",
    "        \n",
    "        edges = gdf[['from_idx', 'to_idx']].values\n",
    "        edge_car_volumes = gdf['vol_car'].values\n",
    "        capacities = gdf['capacity'].values\n",
    "        freespeeds = gdf['freespeed'].values  \n",
    "        lengths = gdf['length'].values  \n",
    "        modes = gdf['modes'].values\n",
    "        modes_encoded = np.vectorize(encode_modes)(modes)\n",
    "        \n",
    "        edge_positions = np.array([((geom.coords[0][0] + geom.coords[-1][0]) / 2, \n",
    "                                    (geom.coords[0][1] + geom.coords[-1][1]) / 2) \n",
    "                                   for geom in gdf.geometry])\n",
    "\n",
    "        # Convert lists to tensors\n",
    "        edge_index = torch.tensor(edges, dtype=torch.long).t().contiguous()\n",
    "        edge_positions_tensor = torch.tensor(edge_positions, dtype=torch.float)\n",
    "        x = torch.zeros((len(nodes), 1), dtype=torch.float)\n",
    "        \n",
    "        # Create Data object\n",
    "        target_values = torch.tensor(edge_car_volumes, dtype=torch.float).unsqueeze(1)\n",
    "        data = Data(edge_index=edge_index, x=x, pos=edge_positions_tensor)\n",
    "        \n",
    "        # Transform to line graph\n",
    "        linegraph_data = linegraph_transformation(data)\n",
    "        \n",
    "        # Prepare the x for line graph: index and capacity\n",
    "        linegraph_x = torch.tensor(np.column_stack((capacities, freespeeds, lengths, modes_encoded)), dtype=torch.float)\n",
    "\n",
    "        linegraph_data.x = linegraph_x\n",
    "        \n",
    "        # Target tensor for car volumes\n",
    "        linegraph_data.y = target_values\n",
    "        \n",
    "        if linegraph_data.validate(raise_on_error=True):\n",
    "            datalist.append(linegraph_data)\n",
    "        else:\n",
    "            print(\"Invalid line graph data\")\n",
    "            \n",
    "# Convert dataset to a list of dictionaries\n",
    "data_dict_list = [{'x': lg_data.x, 'edge_index': lg_data.edge_index, 'pos': lg_data.pos, 'y': lg_data.y} for lg_data in datalist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4.8000e+02, 8.3333e+00, 1.6181e+01, 4.0000e+00],\n",
       "        [2.4000e+02, 8.3333e+00, 1.4860e+01, 5.0000e+00],\n",
       "        [4.8000e+02, 8.3333e+00, 1.4860e+01, 5.0000e+00],\n",
       "        ...,\n",
       "        [7.9992e+03, 1.2000e+01, 6.9989e+02, 1.4000e+01],\n",
       "        [7.9992e+03, 2.0000e+01, 2.0000e+01, 1.5000e+01],\n",
       "        [7.9992e+03, 6.0000e+00, 6.1189e+02, 1.6000e+01]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dict_list[0]['x']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the list of dictionaries\n",
    "# torch.save(data_dict_list, 'dataset_1pm_0-1382_with_more_infos.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Paris_Analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
